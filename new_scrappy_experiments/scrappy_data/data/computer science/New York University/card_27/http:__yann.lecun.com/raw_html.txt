"<html><head>\n<title>Yann LeCun's Home Page</title>\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n</script>\n\n<style type=\"text/css\">\n</style>\n<meta name=\"keywords\" content=\"Yann, LeCun, Le Cun, DjVu, neural networks, convolutional neural nets, machine learning, pattern recognition, OCR, handwriting recognition, computer vision, visual learning, invariance, invariant perception, graph transformer networks, document imaging, image compression, image processing, digital library\"><meta name=\"description\" content=\"Yann LeCun's Home Page\"><script type=\"text/javascript\">\nvar gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\");\ndocument.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E\"));\n</script><script src=\"http://www.google-analytics.com/ga.js\" type=\"text/javascript\"></script><script type=\"text/javascript\">\nvar pageTracker = _gat._getTracker(\"UA-6178702-1\");\npageTracker._trackPageview();\n</script></head>\n\n\n\n\n\n\n\n\n<body bgcolor=\"#ffffff\" text=\"#40556b\" link=\"#124a9c\" vlink=\"#2c7aa4\">\n<style type=\"text/css\">\n</style>\n<font face=\"\" arial,helvetica\"=\"\" size=\"3\">\n\n\n\n\n\n<table width=\"100%\" border=\"0\" cellpadding=\"0\" cellspacing=\"5\">\n<tbody><tr>\n\n<td width=\"140\" valign=\"top\">\n<table border=\"0\" cellpadding=\"1\" cellspacing=\"0\" width=\"140\" bgcolor=\"#f4e8d1\">\n<tbody><tr><td align=\"center\"><img src=\"./ex/images/ylc-thumb.jpeg\" nosave=\"\" height=\"161\" width=\"122\"></td></tr>\n<tr><td><img src=\"./ex/images/menuhline.gif\" height=\"13\" width=\"140\"></td></tr>\n<tr><td><a href=\"./ex/index.html\">HOME</a></td></tr>\n<tr><td><a href=\"https://www.facebook.com/yann.lecun\">Facebook Feed</a></td></tr>\n<tr><td><a href=\"https://drive.google.com/open?id=1liH9utlyETxvywBQAaXWRcK-l-qV9SCFTEVG0QJLktI\">BIO</a></td></tr>\n<tr><td><a href=\"./exdb/publis/index.html\">PUBLICATIONS</a></td></tr>\n<tr><td><a href=\"http://arxiv.org/find/all/1/all:+AND+yann+lecun/0/1/0/all/0/1\">arXiv Papers</a></td></tr>\n<tr><td><a href=\"http://scholar.google.com/citations?hl=en&amp;user=WLN3QrAAAAAJ&amp;pagesize=100&amp;view_op=list_works\">G-Scholar Profile</a></td></tr>\n<tr><td><a href=\"./ex/downloads/index.html\">SOFTWARE</a></td></tr>\n<tr><td><a href=\"http://www.cs.nyu.edu/~yann/index.html\">CBLL</a></td></tr>\n<tr><td><a href=\"./ex/research/index.html\">RESEARCH</a></td></tr>\n<tr><td><a href=\"http://www.cs.nyu.edu/~yann/courses.html\">TEACHING</a></td></tr>\n<tr><td><a href=\"./ex/news/index.html\">WHAT's NEW</a></td></tr>\n<tr><td><img src=\"./ex/images/menuhline.gif\" height=\"13\" width=\"140\"></td></tr>\n<tr><td><a href=\"./ex/djvu/index.html\">DjVu</a></td></tr>\n<tr><td><a href=\"./exdb/lenet/index.html\">LENET</a></td></tr>\n<tr><td><a href=\"./exdb/mnist/index.html\">MNIST OCR DATA</a></td></tr>\n<tr><td><a href=\"http://www.cs.nyu.edu/~ylclab/data/norb-v1.0/index.html\">NORB DATASET</a></td></tr>\n<tr><td><img src=\"./ex/images/menuhline.gif\" height=\"13\" width=\"140\"></td></tr>\n<tr><td><a href=\"./ex/music/index.html\">MUSIC</a></td></tr>\n<tr><td><a href=\"./ex/index.html#photos\">PHOTOS</a></td></tr>\n<tr><td><a href=\"./ex/hobbies/index.html\">HOBBIES</a></td></tr>\n<tr><td><a href=\"./ex/fun/index.html\">FUN STUFF</a></td></tr>\n<tr><td><img src=\"./ex/images/menuhline.gif\" height=\"13\" width=\"140\"></td></tr>\n<tr><td><a href=\"./ex/links/index.html\">LINKS</a></td></tr>\n<tr><td><img src=\"./ex/images/menuhline.gif\" height=\"13\" width=\"140\"></td></tr>\n<tr><td><a href=\"http://cilvr.nyu.edu\">CILVR</a></td></tr>\n<tr><td><a href=\"http://cds.nyu.edu\">CDS</a></td></tr>\n<tr><td><a href=\"http://www.cs.nyu.edu\">CS Dept</a></td></tr>\n<tr><td><a href=\"http://www.cims.nyu.edu\">Courant</a></td></tr>\n<tr><td><a href=\"http://www.nyu.edu\">NYU</a></td></tr>\n<tr><td><a href=\"http://lush.sourceforge.net\"><img src=\"./ex/images/lush-logo-02-88x31.png\" width=\"88\" height=\"31\" alt=\"Lush\"></a></td></tr>\n<tr><td><a href=\"http://www.djvu.com/download.html\"><img src=\"./ex/images/get_djvu2.gif\" width=\"88\" height=\"31\" alt=\"DjVu Plugin for Win/Mac\"></a></td></tr>\n<tr><td><a href=\"http://djvu.sourceforge.net\"><img src=\"./ex/images/plugin-88x31.gif\" width=\"88\" height=\"31\" alt=\"DjVu Plugin for Unix\"></a></td></tr>\n<tr><td><img src=\"./ex/images/menuhline.gif\" height=\"13\" width=\"140\"></td></tr>\n<tr><td>Websites that I maintain</td></tr>\n<tr><td><a href=\"http://lush.sourceforge.net\"><img src=\"./ex/images/lush-logo-02-138x54.png\" width=\"138\" height=\"54\" alt=\"Lush\"></a></td></tr>\n<tr><td><a href=\"http://nips.djvuzone.org\"><img src=\"./ex/images/nips-online-128x64.gif\" width=\"128\" height=\"64\" alt=\"NIPS Online\"></a></td></tr>\n<tr><td><a href=\"http://www.djvuzone.org\"><img src=\"./ex/images/djvuzone-138x69.gif\" width=\"138\" height=\"69\" alt=\"DjVuZone\"></a></td></tr>\n<tr><td><a href=\"http://any2djvu.djvuzone.org\"><img src=\"./ex/images/a2d-138x50.gif\" width=\"138\" height=\"50\" alt=\"Any2DjVu\"></a></td></tr>\n<tr><td><a href=\"http://bib2web.djvuzone.org\"><img src=\"./ex/images/b2w-80x40.gif\" width=\"80\" height=\"40\" alt=\"Bib2Web\"></a></td></tr>\n<tr><td><a href=\"http://djvu.sourceforge.net\"><img src=\"./ex/images/djvu_badge-140x49.gif\" width=\"140\" height=\"49\" alt=\"DjVuLibre\"></a></td></tr>\n<tr><td>&nbsp;</td></tr>\n<tr><td><img src=\"./ex/images/menuhline.gif\" height=\"13\" width=\"140\"></td></tr>\n<tr><td><a href=\"http://eldred.cc/\"><img src=\"./ex/images/freeculture.gif\" width=\"88\" height=\"31\"></a></td></tr>\n<tr><td><a href=\"http://www.catb.org/hacker-emblem/\"><img src=\"http://www.catb.org/hacker-emblem/glider.png\"></a></td></tr>\n\n<tr><td><img src=\"./ex/images/menuhline.gif\" height=\"13\" width=\"140\"></td></tr>\n</tbody></table>\n</td>\n\n<td width=\"95%\" valign=\"top\">\n<center>\n<img src=\"./ex/images/banner.gif\" nosave=\"\" height=\"114\" width=\"492\"><br>\n<img src=\"./ex/images/name.gif\" alt=\"Yann LeCun's Home Page\" nosave=\"\" height=\"90\" width=\"492\">\n</center>\n<p>\n<font face=\"Arial,Helvetica\" size=\"2\" color=\"#2c7aa4\">\n</font></p><center><font face=\"Arial,Helvetica\" size=\"2\" color=\"#2c7aa4\">Welcome to Yann's home page.</font></center><font face=\"Arial,Helvetica\" size=\"2\" color=\"#2c7aa4\">\n</font>\n<p></p><p>\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"blog\"></a><a href=\"https://www.facebook.com/yann.lecun\">Blog/News (Facebook Feed)</a></b></font></td></tr></tbody></table></p><p>\n\n\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"contact\"></a><a href=\"#\">Contact Information</a></b></font></td></tr></tbody></table></p><p>\n\n<a href=\"http://yann.lecun.com\"><b>Yann LeCun</b></a>, <br>\nVP and Chief AI Scientist, Facebook<br>\nSilver Professor of Computer Science, Data Science, Neural Science, and Electrical and Computer Engineering, <a href=\"http://www.nyu.edu\">New York University</a>.<br>\nACM Turing Award Laureate, (sounds like I'm bragging, but a condition of accepting the award is to write this next to you name)<br>\nMember, National Academy of Engineering<br>\n</p><p>\n\n<b>NYU Affiliations:</b><br>\n<a href=\"https://wp.nyu.edu/cilvr/\">CILVR Lab</a><br>\n<a href=\"http://www.cs.nyu.edu\">Computer Science Department</a>, part of the <a href=\"http://www.cims.nyu.edu\">Courant Institute of Mathematical Sciences</a>,<br>\n<a href=\"http://cds.nyu.edu/\">Center for Data Science</a><br>\n<a href=\"http://www.cns.nyu.edu/\">Center for Neural Science</a><br>\n<a href=\"http://engineering.nyu.edu/academics/departments/electrical\">Department of Electrical and Computer Engineering</a>,<br>\n</p><p>\n<b>Facebook Affiliations:</b><br>\n<a href=\"https://research.fb.com/category/facebook-ai-research/\">Facebook AI Research</a><br>\n<a href=\"https://ai.facebook.com/\">Facebook AI</a><br>\n</p><p>\n\n<b>NYU coordinates:</b><br>\nAddress: Room 516, <a href=\"https://goo.gl/maps/oFEVEAvHsTBzHrVZ9\" target=\"map\">60 Fifth Avenue, New York,</a> NY 10011, USA.<br>\nEmail: yann [ a t ] cs.nyu.edu (I may not respond right away)<br>\nPhone: +1-212-998-3283 (I am very unlikely to respond or listen to voice mail in a timely manner)<br>\nAdministrative aide: Hong Tam +1-212-998-3374 &nbsp;&nbsp;&nbsp; hongtam [ a t ] cs.nyu.edu<br>\n</p><p>\n\n<b>Facebook Coordinates:</b><br>\nAddress: <a href=\"https://goo.gl/maps/R7DDe39w2FtPkK6v7\" target=\"map\">770 Broadway, New York, NY 10003</a><br>\nEmail: yann [ a t ] fb.com (I may not respond right away)<br>\nExecutive assistant: Rocio Araujo: rocio [ a t ] fb.com<br>\n<br>\n<b>FOR INVITATIONS TO SPEAK</b>: please send email to <b>lecuninvites[at]gmail.com</b><br>\n(I really can't handle invitations sent to other email addresses)<br>\n</p><p>\n<b>IF YOU REALLY NEED ME TO DO SOMETHING FOR YOU</b>: (e.g. a review, a letter...) please send email to Rocio Araujo <b>rocio[at]fb.com</b><br>\n</p><p>\n\n<b>Publications</b>:<br>\n <a href=\"https://scholar.google.com/citations?user=WLN3QrAAAAAJ&amp;hl=fr\">Google Scholar</a><br>\n <a href=\"./exdb/publis/index.html\">slightly out of date list of publications with PDFs and DjVu</a><br>\n</p><p>\n\n<b>News/Blogs on Social Networks</b> (I'm quite active there):\n</p><ul>\n  <li> Facebook Page: <a href=\"https://www.facebook.com/yann.lecun\">https://www.facebook.com/yann.lecun</a> (it's my blog)\n  </li><li> Twitter Handle: <a href=\"https://twitter.com/ylecun\">@ylecun</a> (my FB posts are automatically tweeted after truncation)\n</li></ul>\n<p>\n\n<b>Talks / Slide Decks</b>:<br>\n<a href=\"https://drive.google.com/drive/folders/0BxKBnD5y2M8NUXhZaXBCNXE4QlE\">Slides of (most of my) talks: </a><br>\n</p><p>\n\n<b>Videos:</b>\nPlaylists on YouTube:\n</p><ul>\n  <li><a href=\"https://www.youtube.com/playlist?list=PL80I41oVxglK--is17UhoHVosOLFEJzKQ\">Talks by Yann LeCun</a>\n  </li><li><a href=\"https://www.youtube.com/playlist?list=PL80I41oVxglJ0kTDV7i3aHBIXe65nTxE7\">Lectures Series by Yann LeCun</a>\n  </li><li><a href=\"https://www.youtube.com/playlist?list=PL80I41oVxglJ2TJzOJtnPZthD5mj8kfZX\">Debates and Panels with Yann LeCun</a>\n  </li><li><a href=\"https://www.youtube.com/playlist?list=PL80I41oVxglJOokgsaIKw4ZJORQC0Qc_5\">Interviews of Yann LeCun</a>\n  </li><li><a href=\"https://www.youtube.com/playlist?list=PL80I41oVxglKKxF1OBbKHdOEX2VZVNzAR\">Demos by Yann LeCun</a>\n  </li><li><a href=\"https://code.fb.com/ai-research/ai-revealed/\">Six short videos to explain AI, Machine Learning, Deep Learning and Convolutional Nets</a>\n</li></ul>\n\n<p>\n<b>Biographies:</b><br>\n<a href=\"https://drive.google.com/open?id=1liH9utlyETxvywBQAaXWRcK-l-qV9SCFTEVG0QJLktI\">bios of various lengths in English and French</a><br>\n</p><p>\n\n<b>Main Research Interests</b>:<br>\nAI, Machine Learning, Computer Vision,\nRobotics, and Computational Neuroscience.  I am also interested\nPhysics of Computation, and many applications of machine learning.\n</p><p>\n\n[stuff below this line is badly out of date]\n</p><p>  \n</p><hr>\n<p>\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"quicklinks\"></a><a href=\"#quicklinks\">Quick Links</a></b></font></td></tr></tbody></table></p><p>\n</p><ul>\n<li><a href=\"http://cds.nyu.edu\">Center for Data Science</a>, and the <a href=\"http://nyu.edu/datascience\">NYU Data Science Portal</a>.\n</li><li><a href=\"./ex/bio.html\">Short bio</a>: if you want to know more about me.\n</li><li><a href=\"http://www.cs.nyu.edu/~yann\">Computational and\n  Biological Learning Lab</a>, my research group at the Courant Institute, NYU.\n</li><li><a href=\"http://cilvr.nyu.edu\">CILVR Lab: Computational Intelligence, Vision Robotics Lab</a>: a 20-person lab consisting of my colleagues Rob Fergus, Savid Sontag and me, together with our students and postdocs.\n</li><li><a href=\"http://vlg.cs.nyu.edu\">VLG: The Vision-Learning-Graphics Group</a> consisting of the CILVR Lab, plus our colleagues in computer graphics, movement analysis, and human-computer interfaces.\n</li><li><a href=\"./ex/research/index.html\">Research</a>: descriptions\n    of my projects and contributions, past and present.\n</li><li><a href=\"./exdb/publis/index.html\">Publications</a>: (almost) all of my\n    publications, available in PDF and DjVu formats.\n</li><li><a href=\"http://scholar.google.com/citations?hl=en&amp;user=WLN3QrAAAAAJ&amp;pagesize=100&amp;view_op=list_works\">Google\n   Scholar Profile</a>: all my publications with number of citations,\n   harvested by Google.\n</li><li><a href=\"http://arxiv.org/find/all/1/all:+AND+yann+lecun/0/1/0/all/0/1\">Preprints on ArXiv.org</a>: \n   where you will find our latest results, before they may receive a stamp of approval.\n</li></ul>\n<p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"cbll\"></a><a href=\"http://www.cs.nyu.edu/~yann\">Computational and Biological Learning Lab</a></b></font></td></tr></tbody></table></p><p>\n\n<table>\n<tbody><tr><td> My lab at the Courant Institute of New york University is\ncalled the <a href=\"http://www.cs.nyu.edu/~yann\">Computational and Biological Learning\nLab</a>. It is part of <a href=\"http://vlg.cs.nyu.edu\">VLG: the\nVision-Learning-Graphics Group</a>, an informal group of researcher\ninterested in pixels (in analyzing them or in producing them).\n</td>\n<td><a href=\"http://www.cs.nyu.edu/~yann\"><img src=\"./ex/images/banner-cbll-small.jpg\"></a></td>\n</tr></tbody></table>\n</p><p>\nSee <a href=\"http://www.cs.nyu.edu/~yann/research\">research projects\ndescriptions</a>, lab member pages, events, demos, datasets...\n</p><p>\nWe are working on a class of learning systems called <a href=\"http://www.cs.nyu.edu/~yann/research/ebm/\"><b>Energy-Based\nModels</b></a>, and <a href=\"http://www.cs.nyu.edu/~yann/research/deep\"><b>Deep Belief Networks</b></a>. \nWe are also working on convolutional nets for visual recognition , and a type \nof graphical models known as factor graphs.\n</p><p>\nWe have projects in computer vision, object detection, object\nrecognition, mobile robotics, bio-informatics, biological image\nanalysis, medical signal processing, signal processing, \nand financial prediction,....\n</p><p>\n<a href=\"http://www.cs.nyu.edu/~yann/research\"><img src=\"./ex/images/cbllresearch-01.png\"></a>\n</p><p>\n\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"teaching\"></a><a href=\"http://www.cs.nyu.edu/~yann/courses.html\">Teaching</a></b></font></td></tr></tbody></table></p><p>\n\nJump to\n<a href=\"http://www.cs.nyu.edu/~yann/courses.html\">my course page at NYU</a>,\nand see course descriptions, slides, course material...\n</p><p>\n\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"talks\"></a><a href=\"http://www.cs.nyu.edu/~yann/talks/\">Talks and Tutorials</a></b></font></td></tr></tbody></table></p><p>\n\nSee, watch and hear <a href=\"http://www.cs.nyu.edu/~yann/talks/\">talks and tutorial</a>.\n</p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"pamphlets\"></a><a href=\"http://www.cs.nyu.edu/~yann/pamphlets/\">Pamphlets and opinions</a></b></font></td></tr></tbody></table></p><p>\n</p><p>\n</p><h3><a href=\"./ex/pamphlets/publishing-models.html\">Proposal for a new publishing model in Computer Science</a></h3>\n<p>\nMany computer Science researchers are complaining that our emphasis on\nhighly selective conference publications, and our double-blind\nreviewing system stifles innovation and slow the rate of progress\nof Science and technology.\n</p><p>\nThis pamphlet proposes a new publishing model based on an open repository\nand open (but anonymous) reviews which creates a \"market\" between papers\nand reviewing entities.\n</p><p>\n<a href=\"./ex/pamphlets/publishing-models.html\"><b>MORE INFORMATION &gt;&gt;&gt;&gt;&gt;</b></a>\n</p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"norb\"></a><a href=\"http://www.cs.nyu.edu/~yann/research/deep\">Deep Learning</a></b></font></td></tr></tbody></table></p><p>\n\nAnimals and humans can learn to see, perceive, act, and communicate\nwith an efficiency that no Machine Learning method can approach.  The\nbrains of humans and animals are \"deep\", in the sense that each action\nis the result of a long chain of synaptic communications (many layers\nof processing).  We are currently researching efficient learning\nalgorithms for such \"deep architectures\". We are currently\nconcentrating on unsupervised learning algorithms that can be used to\nproduce deep hierarchies of features for visual recognition. We\nsurmise that understanding deep learning will not only enable us to\nbuild more intelligent machines, but will also help us understand\nhuman intelligence and the mechanisms of human learning.\n</p><p>\n<a href=\"http://www.cs.nyu.edu/~yann/research/deep\"><b>MORE INFORMATION &gt;&gt;&gt;&gt;&gt;</b></a>.\n\n</p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"relreg\"></a><a href=\"http://www.cs.nyu.edu/~yann/research/relreg\">Relational Regression</a></b></font></td></tr></tbody></table></p><p>\n\nWe are developing a new type of relational graphical models that can\nbe applied to \"structured regression problem\".  A prime example of\nstructured regression problem is the prediction of house prices. The\nprice of a house depends not only on the characteristics of the house,\nbut also of the prices of similar houses in the neighborhood, or\nperhaps on hidden features of the neighborhood that influence\nthem. Our relational regression model infers a hidden \"desirability\nsruface\" from which house prices are predicted.\n</p><p>\n<a href=\"http://www.cs.nyu.edu/~yann/research/relreg\"><b>MORE INFORMATION &gt;&gt;&gt;&gt;&gt;</b></a>.\n\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"norb\"></a><a href=\"http://www.cs.nyu.edu/~yann/research/lagr\">Mobile Robotics</a></b></font></td></tr></tbody></table></p><p>\n\n<table><tbody><tr><td>\nThe purpose of the <a href=\"http://www.darpa.mil/ipto/programs/lagr/\">LAGR project</a>,\nfunded by the US government, is to design vision and learning algorithms\nto allow mobile robots to navigate in complex outdoors \nenvironment solely from camera input.\n<p>\n<a href=\"http://www.cs.nyu.edu/~yann\">My Lab</a>, collaboration with \n<a href=\"http://www.net-scale.com\">Net-Scale\nTechnologies</a> is one of 8 participants in the program\n(Applied Perception Inc., Georgia Tech, JPL, NIST, NYU/Net-Scale, \nSRI, U. Penn, Stanford).\n</p><p>\nEach LAGR team received identical copies of the \n<a href=\"http://www.rec.ri.cmu.edu/projects/lagr/index.htm\">LAGR robot</a>, \nbuilt be the <a href=\"http://www.rec.ri.cmu.edu/\">CMU/NREC</a>.\n</p><p>\n</p></td><td>\n<img src=\"./ex/images/lagr-vehicle-small.jpg\" align=\"right\">\n</td></tr>\n<tr><td>\nThe government periodically runs competitions between the teams.\nThe software from each team is loaded and run by the goverment team\non their robot. \n<p>\nThe robot is given the GPS coordinates of a goal to which it must\ndrive as fast as possible.  The terrain is unknown in advance.\nThe robot is run three times through the test course.\n</p><p>\nThe software can use the knowledge acquired during the early \nruns to improve the performance on the latter runs.\n</p><p>\n</p></td><td>\n<img src=\"./ex/images/lagr-stereo.png\" align=\"right\">\n</td></tr></tbody></table>\n</p><p>\n<a href=\"http://www.cs.nyu.edu/~yann/research/lagr\"><b>CLICK HERE FOR MORE INFORMATION, VIDEOS, PICTURES &gt;&gt;&gt;&gt;&gt;</b></a>.\n</p><p>\nPrior to the LAGR project, we worked on the \n<a href=\"http://www.cs.nyu.edu/~yann/research/dave\">DAVE project</a>, \nan attempt to train a small mobile robot to drive autonomously in \noff-road  environments by looking over the shoulder of a human operator.\n</p><p>\n<a href=\"http://www.cs.nyu.edu/~yann/research/dave\">CLICK HERE FOR INFORMATION ON THE DAVE PROJECT &gt;&gt;&gt;&gt;&gt;</a>.\n</p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"ebm\"></a><a href=\"http://www.cs.nyu.edu/~yann/research/ebm\">Energy-Based Models</a></b></font></td></tr></tbody></table></p><p>\n\n<table><tbody><tr><td>\nEnergy-Based Models (EBMs) capture dependencies between variables by\nassociating a scalar energy to each configuration of the\nvariables. Inference consists in clamping the value of observed\nvariables and finding configurations of the remaining variables that\nminimize the energy. Learning consists in finding an energy\nfunction in which observed configurations of the variables are given\nlower energies than unobserved ones. The EBM approach provides a\ncommon theoretical framework for many learning models, including\ntraditional discriminative and generative approaches, as well as\ngraph-transformer networks, conditional random fields, maximum margin\nMarkov networks, and several manifold learning methods.\n<p>\nProbabilistic models must be properly normalized, which sometimes\nrequires evaluating intractable integrals over the space of all\npossible variable configurations. Since EBMs have no requirement for\nproper normalization, this problem is naturally circumvented.  EBMs\ncan be viewed as a form of non-probabilistic factor graphs, and they\nprovide considerably more flexibility in the design of architectures\nand training criteria than probabilistic approaches.\n</p></td><td>\n <table>\n  <tbody><tr><td><img src=\"./ex/images/demo03-anim.gif\" align=\"right\"></td></tr>\n </tbody></table>\n</td></tr></tbody></table>\n</p><p>\n<a href=\"http://www.cs.nyu.edu/~yann/research/ebm\"><b>CLICK HERE FOR\nMORE INFORMATION, PICTURES, PAPERS &gt;&gt;&gt;&gt;&gt;</b></a>.\n</p><p>\n\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"norb\"></a><a href=\"http://www.cs.nyu.edu/~yann/research/norb\">Invariant Object Recognition</a></b></font></td></tr></tbody></table></p><p>\n\n<table border=\"0\"><tbody><tr>\n<td><img src=\"./ex/images/lenet7-norb.jpg\" width=\"445\" height=\"195\" alt=\"Lenet7-NORB\"></td>\n<td><img src=\"./ex/images/norb.jpg\" width=\"278\" height=\"225\" alt=\"NORB\"></td>\n</tr></tbody></table>\n</p><p>\n<table>\n<tbody><tr><td>\nThe recognition of generic object categories with invariance to pose,\nlighting, diverse backgrounds, and the presence of clutter is one of\nthe major challenges of Computer Vision. \n<p>\nI am developing learning systems that can recognize generic object\npurely from their shape, independently of pose and lighting.\n</p><p>\nSee \n</p><p>\nThe NORB dataset for generic object recognition is \n<a href=\"http://www.cs.nyu.edu/~ylclab/data/norb-v1.0\">available for download</a>.\n</p></td><td>\n<img src=\"./ex/images/norb-sample-01.png\">\n</td></tr>\n</tbody></table>\n</p><p>\n<a href=\"http://www.cs.nyu.edu/~yann/research/norb\"><b>CLICK HERE FOR MORE INFORMATION, PICTURES, PAPERS &gt;&gt;&gt;&gt;&gt;</b></a>.\n</p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"lush\"></a><a href=\"http://lush.sourceforge.net\">Lush: A Programming Language for Research</a></b></font></td></tr></tbody></table></p><p>\n\n</p><div align=\"justify\">\nTired of Matlab? <a href=\"http://lush.sourceforge.net\">Lush</a> is an\neasy-to-learn, open-source <b>object-oriented programming language</b>\ndesigned for researchers, experimenters, and engineers working in\n<b>large-scale numerical and graphic applications</b>.  \n<p>\nLush combines three languages in one: a very simple to use,\nloosely-typed interpreted language, a strongly-typed compiled language\nwith the same syntax, and the C language, which can be freely mixed\nwith the other languages within a single source file, and even\nwithin a single function.\n</p><p>\n<a href=\"http://lush.sourceforge.net\">\n<img src=\"./ex/images/lush-logo-03-138x102.png\" align=\"right\" width=\"138\" height=\"102\" border=\"0\"></a>\nLush has a library of over 14,000 functions and classes, \nsome of which are simple interfaces to popular libraries: \nvector/matrix/tensor algebra, linear algebra (LAPACK, BLAS), \nnumerical function (GSL), 2D and 3D graphics (X, SDL, OpenGL, \nOpenRM, PostScipt), image processing, computer vision (OpenCV),\nmachine learning (gblearning, Torch), regular expressions,\naudio processing (ALSA), and video grabbing (Video4linux).\n</p><p>\nIf you do research and development in <b>signal processing, image\nprocessing, machine learning, computer vision, bio-informatics, data\nmining, statistics, or artificial intelligence</b>, and feel limited by\nMatlab and other existing tools, <b>Lush</b> is for you. If you want a \nsimple environment to experiment with <b>graphics, video, and sound</b>, \nLush is for you. Lush is Free Software (GPL) and runs under GNU/Linux,\nSolaris, and Irix.\n</p><p>\n<a href=\"http://lush.sourceforge.net\"><b>VISIT THE LUSH HOME PAGE &gt;&gt;&gt;&gt;</b></a>\n</p><p>\n</p></div>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"djvu\"></a><a href=\"./ex/djvu/index.html\">DjVu: The Document Format for Digital Libraries</a></b></font></td></tr></tbody></table><p>\n\n<img src=\"./ex/images/djvu_badge-140x49.gif\" border=\"0\" align=\"left\" height=\"49\" width=\"140\">\n<img src=\"./ex/images/pharm-thumb.jpeg\" border=\"0\" align=\"right\" height=\"140\" width=\"103\">\nMy main research topic until I left AT&amp;T was the\n<a href=\"http://www.djvuzone.org/home.html\">DjVu</a> project.\nDjVu is a document format, a set of compression methods and a software\nplatform for distributing scanned and digitally produced documents on the Web.\nDjVu image files of scanned documents are typically 3-8 times \nsmaller than PDF or TIFF-groupIV for bitonal and 5-10 times \nsmaller than PDF or JPEG for color (at 300 DPI). DjVu versions\nof digitally produced documents are more compact and render \nmuch faster than the PDF or PostScript versions.\n</p><p>\n<a href=\"http://www.djvuzone.org/links/index.html\">Hundreds of websites\naround the world</a> are using DjVu for Web-based and CDROM-based\ndocument repositories and digital libraries. \n</p><ul>\n<li><a href=\"./ex/djvu/index.html\">Yann's DjVu page</a>: \n    a description of DjVu, and a set of useful links.\n</li><li><a href=\"http://www.cs.uiuc.edu/news/dls/distlectpst.html\">Technical talk on DjVu</a>:\n    watch a streaming video of Yann's Distinguished Lecture\n    at the University of Illinois at Urbana-Champaign, October 22 2001.\n    <a href=\"http://a.cs.uiuc.edu/dls/dls0102/dls0102-lecun-high.asx\">(100K Windows Streaming Media)</a>.\n    <a href=\"http://a.cs.uiuc.edu/dls/dls0102/dls0102-lecun-low.asx\">(56K Windows Streaming Media)</a>,\n</li><li><a href=\"http://www.djvuzone.org/index.html\">DjVuZone.org</a>: \n    samples, demos, technical information, papers, and tutorials on DjVu....\n    DjVuZone hosts several digital libraries, including \n    <a href=\"http://nips.djvuzone.org\">NIPS Online</a>.\n</li><li><a href=\"http://djvu.sourceforge.net\">DjVuLibre for Unix</a>: free/open-source\n    browser plug-ins, viewers, utilites, and libraries for Unix.\n</li><li><a href=\"http://www.djvu.com\">Commercial DjVu Software</a>:\n    free plug-ins for Windows and Mac, free and commercial applications\n    for Windows and some Unix platforms (hosted at\n    <a href=\"http://www.lizardtech.com\">LizardTech</a>, the company \n    that distributes and supports DjVu under license from AT&amp;T).\n</li><li><a href=\"http://any2djvu.djvuzone.org\">Any2DjVu</a> and \n    <a href=\"http://bib2web.djvuzone.org\">Bib2Web</a>: Upload\n    your documents and get them converted to DjVu. Bib2Web automates\n    the creation of <a href=\"http://bib2web.djvuzone.org/sample-output/publis.html\">\n    publication pages</a> for researchers.\n</li></ul>\n<p>\n</p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"lenet\"></a><a href=\"./exdb/lenet/index.html\">Learning and Visual Perception</a></b></font></td></tr></tbody></table></p><p>\n\n<img src=\"./ex/images/a23-small.gif\" border=\"0\" align=\"right\" height=\"100\" width=\"160\">\nMy main research interest is machine learning, particularly how it applies\nto perception, and more particularly to visual perception.\n</p><p>\nI am currently working on two architectures for gradient-based perceptual\nlearning: <b>graph transformer networks</b> and <b>convolutional networks.</b>\n</p><p>\nConvolutional Nets are a special kind of neural net architecture designed \nto recognize images directly from pixel data. Convolutional Nets can be\ntrained to detect, segment and recognize objects with excellent robustness\nto noise, and variations of position, scale, angle, and shape.\n</p><p>\nHave a look at the animated \n<a href=\"./exdb/lenet/index.html\">demonstrations of LeNet-5</a>, \na Convolutional Nets trained to recognize handwritten digit strings.\n</p><p>\nConvolutional nets and graph transformer networks are embedded in \nseveral high speed scanners used by banks to read checks.\nA system I helped develop reads an estimated <b>10 percent of\nall the checks written in the US</b>.\n</p><p>\nCheck out <a href=\"./exdb/lenet/index.html\">this page</a>, and/or \nread <a href=\"./exdb/publis/index.html#lecun-98\">this paper</a>\nto learn more about Convolutional Nets and graph transformer networks.\n</p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"mnist\"></a><a href=\"/exdb/mnist/index.html\">MNIST Handwritten Digit Database</a></b></font></td></tr></tbody></table></p><p>\n\nThe <a href=\"/exdb/mnist/index.html\">MNIST database</a> contains \n60,000 training samples and 10,000 test samples of size-normalized\nhandwritten digits. This database was derived from the original\nNIST databases.\n</p><p>\nMNIST is widely used by researchers as a benchmark for testing \npattern recognition methods, and by students for class projects\nin pattern recognition, machine learning, and statistics.\n</p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"music\"></a><a href=\"./ex/hobbies/index.html\">Music and Hobbies</a></b></font></td></tr></tbody></table></p><p>\n\nI have several interests beside my family (my wife and three sons)\nand my research: \n</p><ul>\n<li><a href=\"./ex/music/index.html\">Playing Music</a>: particularly Jazz, Renaissance\n    and Baroque music. A few MP3 and MIDI files of Renaissance music are \n    <a href=\"./ex/music/index.html\">available here</a>. \n</li><li><a href=\"http://www.lecun.org/hobby/planes.html\">Building and flying miniature flying contraptions</a>:\n    preferably battery powered, radio controled, and unconventional in their design.\n    <img src=\"./ex/images/plane01-thumb.jpg\" border=\"0\" align=\"right\" height=\"96\" width=\"128\">\n</li><li>Building robots: particularly Lego robots (before the days of the Lego Mindstorms)\n</li><li>Hacking various computing equipment:\n    I have owned 5 computers between 1978 and 1992: SYM-1, OSI C2-4P, Commodore 64, \n    Amiga 1000, Amiga 4000. then I lost interest in personal computing when the only thing\n    you could get was a boring Wintel box. Then, Linux appeared and I came back to life.....\n</li><li>Sailing: I own two sport catamarans, a Nacra 5.8 and a Prindle 19. I also sail \n    and race larger boats with friends.\n</li><li>Graphic Design: I designed the DjVu logo and much of the AT&amp;T DjVu web site.\n</li><li>Reading European comics. Comics in certain European countries (France, Belgium, Italy,\n   Spain) are considered a true art form (\"le 8-ieme art\"), and not just a business with\n   products targeted at teenagers like on this side of the pond. Although I don't have\n   a shred of evidence to support it, I claim to have the largest private collection \n   of French-language comics in the Eastern US. \n</li><li>making bad puns in French, but I don't \n    have much of an audience this side of the pond.\n</li><li>Sipping wine, particularly red, particularly French,\n    particularly Bordeaux, particularly Saint-Julien.\n</li></ul>\n<p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"bib2web\"></a><a href=\"http://bib2web.djvuzone.org\">Bib2Web: Automatic Creation of Publication Pages</a></b></font></td></tr></tbody></table></p><p>\n</p><div align=\"justify\">\n<a href=\"http://bib2web.djvuzone.org\"><img align=\"right\" src=\"./ex/images/b2w-80x40.gif\" width=\"80\" height=\"40\" alt=\"Bib2Web\"></a>\nNo deep science here, but if you are looking for a simple/automatic way to make all your \npublications (digital or paper-based) available on your web page, \nvisit <a href=\"http://bib2web.djvuzone.org\">Bib2Web</a>.\n<p>\n</p></div>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"photos\"></a><a href=\"#photos\">Photos Galleries</a></b></font></td></tr></tbody></table><p>\n\n</p><ul>\n<li><a href=\"http://www.lecun.org/gallery/libpro/index.html\">Photos taken at various conferences,\n     workshops, trade shows and other professional events</a>. Includes\n     pictures from CVPR, NIPS, Learning@Snowbird, ICDAR, CIFED, etc.\n</li><li><a href=\"http://www.lecun.org/gallery/libhob/index.html\">A photo and movie gallery of various \n    radio-controled airplanes</a>, other miniature flying objects,\n    lego robots, and other techno toys. Check out also my \n    <a href=\"http://www.lecun.org/hobby/planes.html\">model airplane page</a>.\n</li><li><a href=\"http://www.lecun.org/gallery/libart/index.html\">Miscellaneous artsy and nature picture</a>,\n    including garden-variety wild animals, landscapes, etc.\n</li><li><a href=\"http://www.lecun.org/gallery/libart/20000816-lebourget/index.html\">Vintage airplanes</a> at\n    the national air and space museum in Le Bourget, near Paris.\n</li></ul>\n<p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"fun\"></a><a href=\"./ex/fun/index.html\">Fun Stuff</a></b></font></td></tr></tbody></table></p><p>\n\n</p><ul>\n<li>No, <a href=\"./ex/fun/index.html#kahn.html\">Yann is NOT Philippe Kahn's evil brother</a>\n</li><li><a href=\"./ex/fun/index.html#gellman\">Your Name can't possibly be pronounced that way</a>: \nor how a Nobel prize winner tried to tell me how to pronounce my own name.\n</li><li><a href=\"./ex/fun/index.html#tex\">Who is Tex Avery anyway?</a>\n</li><li><a href=\"./ex/fun/index.html#steep\">Steep Learning Curves and other \nerroneous metaphores</a>\n</li><li><a href=\"./ex/fun/index.html#allyourbayes\">Vladimir Vapnik meets the \nvideo game sub-culture</a>\n</li><li><a href=\"./ex/fun/index.html#philo\">Cheap Philosophy (42 cents)</a>\n</li><li><a href=\"./ex/fun/index.html#disclaim\">A Mathematical Theory of Empty Disclaimers</a>\n</li><li><a href=\"./ex/fun/index.html#weasel\">The Axis of Rivals</a>\n</li></ul>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"group\"></a><a href=\"./ex/group/index.html\">Previous Life</a></b></font></td></tr></tbody></table><p>\n\nMy former group at AT&amp;T (the Image Processing Research Department)\nand its ancestor (Larry Jackel's Adaptive Systems Research Department)\nmade numerous contributions to Machine Learning, Image Compression,\nPattern Recognition, Synthetic Persons (talking heads), and Neural-Net\nHardware. Specific contributions not mentioned elsewhere on this site\ninclude the ever so popular Support Vector Machine, the PlayMail and \nVirt2Elle synthetic talking heads, the Net32K and ANNA neural net chips, \nand many others. \nVisit <a href=\"./ex/group/index.html\">my former group's home page</a> \nfor more details.  </p><p>\n\n<table border=\"0\" cellpadding=\"4\" cellspacing=\"0\" width=\"100%\"><tbody><tr bgcolor=\"#d8d8d8\"><td align=\"left\"><font face=\"Arial,Helvetica\" size=\"3\" color=\"\" #8da9ca\"=\"\"><b><a name=\"links\"></a><a href=\"./ex/links/index.html\">Links</a></b></font></td></tr></tbody></table></p><p>\n\nLinks to interesting places on the web, friends'\nhome pages, etc <a href=\"elloww.html\">.</a>\n\n\n\n</p></td>\n</tr>\n</tbody></table>\n<p>\n</p><center>\n\n<br><br>\n<hr width=\"15%\">\n<br>\n\n<!--Text-Navigation-->\n<center>\n<table border=\"0\" cellpadding=\"1\" cellspacing=\"1\">\n<tbody><tr>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./ex/ex/index.html\">[HOME]</a></span></font></td>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./ex/news/index.html\">[NEWS]</a></span></font></td>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./exdb/publis/index.html\">[PUBLICATIONS]</a></span></font></td>\n</tr>\n<tr>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./ex/research/index.html\">[RESEARCH]</a></span></font></td>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./ex/downloads/index.html\">[DOWNLOADS]</a></span></font></td>\n</tr>\n<tr>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./exdb/lenet/index.html\">[LENET]</a></span></font></td>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./ex/music/index.html\">[MUSIC]</a></span></font></td>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./exdb/photos/index.html\">[PHOTOS]</a></span></font></td>\n</tr>\n<tr>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./ex/hobbies/index.html\">[HOBBIES]</a></span></font></td>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./ex/fun/index.html\">[FUN]</a></span></font></td>\n  <td class=\"footertextmenu\" valign=\"top\"><font face=\"arial, helvetica, sans-serif\" size=\"2\"><span class=\"footertextmenu\"><a href=\"./ex/links/index.html\">[LINKS]</a></span></font></td>\n</tr>\n\n</tbody></table>\n\n<p>\n<font size=\"-1\" face=\"arial,helvetica\">\n<a href=\"http://yann.lecun.com\">Yann LeCun</a>, Professor<br>\n<a href=\"http://www.cims.nyu.edu\">The Courant Institute of Mathematical Sciences</a><br>\n<img src=\"./ex/images/email.gif\">\n</font>\n</p><p>\n<font face=\"arial, helvetica\" color=\"#808080\" size=\"-2\">\nCopyright \u00a9 2000-2018 Yann LeCun.</font>\n</p></center>\n\n<!-- This text is just for giving more info to robots -->\n<font size=\"0\" color=\"#ffffff\">\nYann LeCun, Le Cun, deep learning, ConvNet, CNN, LeNet, DjVu, \nconvolutional neural networks, machine learning, computer vision, \npattern recognition, document imaging, image compression, \ndigital libraries,</font>\n\n\n\n\n\n\n</center></font></body></html>"