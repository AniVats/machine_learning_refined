"<html><head>\n    <meta charset=\"utf-8\">\n    <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n    <title>Andrew Gordon Wilson</title>\n    <script async=\"\" src=\"https://www.google-analytics.com/analytics.js\"></script><script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-81945202-2', 'auto');\n  ga('send', 'pageview');\n\n</script>\n    <meta id=\"viewport\" name=\"viewport\" content=\"width=500\">\n    <link rel=\"stylesheet\" href=\"normalize.css\" type=\"text/css\">\n    <link rel=\"stylesheet\" href=\"base.css\" type=\"text/css\">\n    <link rel=\"stylesheet\" href=\"code.css\" type=\"text/css\">\n    <link rel=\"icon\" type=\"image/png\" href=\"http://www.cs.cmu.edu/%7Eandrewgw/andrewavatar.png\" sizes=\"940x1641\">\n    <link rel=\"icon\" type=\"image/png\" href=\"http://www.cs.cmu.edu/%7Eandrewgw/andrewavatar.png\" sizes=\"32x32\">\n  </head>\n  <body>\n    <div class=\"content\">\n      <header> <img src=\"andrewcropfast.jpg\" alt=\"andrewphoto\" height=\"1471\" width=\"1094\"><br>\n        <h1><a href=\"https://cims.nyu.edu/~andrewgw\">Andrew\n            Gordon Wilson<br>\n          </a></h1>\n        <ul>\n          <li><a href=\"andrewcv.pdf\">CV</a></li>\n          <li><a href=\"#highlights\">News</a></li>\n          <!--  <li><a href=\"#thesis\">PhD Thesis</a></li> -->\n          <li><a href=\"#papers\">Papers</a></li>\n          <li><a href=\"https://cims.nyu.edu/~andrewgw/talks\">Talks</a></li>\n          <li><a href=\"https://cims.nyu.edu/~andrewgw/group\">Group</a></li>\n          <li><a href=\"https://cims.nyu.edu/~andrewgw/teaching\">Teaching</a></li>\n          <li><a href=\"https://cims.nyu.edu/~andrewgw/code\">Code<br>\n            </a></li>\n          <!--   <li><a href=\"mailto:%20andrew@cornell.edu\">Contact</a></li> -->\n        </ul>\n      </header>\n      <section id=\"bio\">\n        <meta http-equiv=\"content-type\" content=\"text/html;\n          charset=UTF-8\">\n        <div align=\"justify\"> \n\n<b>UPDATE: I have moved to NYU. If you are a student wanting to work with me, I encourage you to apply to NYU Courant CS, Math, or the Center for Data Science (CDS), and to list me in your application.</b><br><br>\n\n<b>I <a href=\"https://cims.nyu.edu/~andrewgw/group\">lead a\n              machine learning group</a> at NYU. You\n            can check out some of <a href=\"https://cims.nyu.edu/~andrewgw/code\">our\n              work here</a>. I also <a href=\"https://cims.nyu.edu/~andrewgw/teaching\">teach\n\n\n              classes</a> on Bayesian machine learning and information\n            theory.&nbsp; I organized the NIPS 2017 symposium on <a href=\"https://nips.cc/Conferences/2017/Schedule?showEvent=8744\">Interpretable\n              Machine Learning</a>. The PyTorch blog <a href=\"https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/\">recently featured some of our work</a> developing geometrically inspired methods for predictive distributions, uncertainty representation, and better generalization in deep learning.</b><br>\n          <b> </b><br>\n          <b> </b>I am interested in developing flexible,\n          interpretable, and scalable machine learning models, often\n          involving deep learning, Gaussian\n          processes, and kernel learning. I care about developing practically impactful methods, while at the same understanding why the methods work, and the foundations for building models that learn and generalize.\n I am particularly excited about loss surfaces, generalization, probabilistic generative models, and Bayesian methods in deep learning. My work has been applied to time series, vision,\n          NLP, spatial statistics, public policy, medicine, and physics.<br>\n          &nbsp;<br>\n          Outside of work, I am a classical pianist who particularly\n          enjoys Glenn Gould's playing of Bach.<br>\n        </div>\n        <!-- <b>I have recently moved to Cornell University as an assistant\n          professor.&nbsp; <br> --> <br>\n        I can be reached at <a href=\"mailto:andrewgw@cims.nyu.edu\">andrewgw@cims.nyu.edu</a>,\n        and on Twitter <a href=\"https://twitter.com/andrewgwils\">@andrewgwils</a>.<br>\n        <br>\n        Andrew Gordon Wilson<br>\n        Assistant Professor<br>\n        Courant Institute of Mathematical Sciences and Center for Data Science<br>\n        60 Fifth Ave<br>\n        New York University<br>\n      </section>\n      <section id=\"highlights\">\n        <div align=\"center\"><big><b>News</b></big><br>\n        </div>\n        <br>\n       <a href=\"https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/\">Blog explaining SWA, SWAG, and SWALP in PyTorch!</a> Improved generalization, semi-supervised learning, deep RL, uncertainty representation, Bayesian deep learning, calibration, low precision training... I encourage you try it out! It's easy, and also works on pre-trained models.<br><br> \n\n \n        I received an <a href=\"https://ara.amazon-ml.com/recipients/#2018\">Amazon Research Award</a> for \"New Directions in Non-Convex Optimization for Deep Learning\". Thank you for the support, Amazon!<br>\n        <br>Check out our new <a href=\"https://cims.nyu.edu/~andrewgw/code\">code</a>\n        and <a href=\"https://cims.nyu.edu/~andrewgw/group\">group</a>\n        pages!<br>\n        <br>\n        Three new papers appearing at NeurIPS 2019!<br>\n        <br>\n        I am an Area Chair/SPC for AAAI 2018, AISTATS 2018, UAI 2018,\n        NeurIPS 2018, AISTATS 2019, ICML 2019, UAI 2019, NeurIPS 2019, AAAI 2020, ICLR 2020.<br>\n        <br>\nI am an EXPO Chair for ICML 2019, 2020.<br><br>\n        <div align=\"justify\"> Upcoming talks: I am giving invited talks\n          at CMStatistics 2017, MSR Cambridge, Cambridge University, UCL\n          Gatsby, Banff International Research Centre (Interface of\n          Statistics and Machine Learning) 2018, DALI 2018, and SIAM ALA\n          (Applied Linear Algebra) 2018, Allerton 2018, and the Toronto\n          Deep Learning Summer School!<br>\n        </div>\n        <!-- <br>\n        A video overviewing some of my research interests:<br>\n        <a href=\"https://slideshot.epfl.ch/play/k5FuJcUA0L0c\">Scalable\n          Gaussian Processes for Scientific Discovery</a><br>\n        EPFL, Lausanne, Swizterland, February 2016<br>\n        <br>\n        A video to watch for a succinct introduction to some of my\n        research interests:<br>\n        <a\n          href=\"http://videolectures.net/icml2015_wilson_kernel_interpolation/\">Video\n          lecture on KISS-GP (Scalable Gaussian Processes)</a>, Lille,\n        France, July 2015<br>\n        <br> --> </section>\n      <section id=\"thesis\">\n        <div align=\"center\"><big><b>Thesis</b></big><br>\n          <br>\n        </div>\n        <div align=\"justify\"> My thesis provides an introduction to\n          probabilistic non-parametric model construction, Gaussian\n          processes and kernel design, and a vision for scalable and\n          automatic kernel learning, with ideas for future directions.<br>\n        </div>\n        <br>\n        <b>Covariance kernels for fast automatic pattern discovery and\n          extrapolation with Gaussian processes</b><br>\n        Andrew Gordon Wilson<br>\n        PhD Thesis, January 2014.<br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/andrewgwthesis.pdf\">PDF</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/agwthesis.bib\">BibTeX</a>]<br>\n      </section>\n      <section id=\"papers\">\n        <div align=\"center\"><big><b>Papers<br>\n              <br>\n            </b></big></div>\n        <b><b><a href=\"https://scholar.google.com/citations?user=twWX2LIAAAAJ&amp;hl=en&amp;oi=ao\">Google scholar page</a><br>\n            <br>\n          </b></b>\n<br>\n\n<b>The Case for Bayesian Deep Learning</b><br>\nAndrew Gordon Wilson<br><i>Technical Report, NYU Courant</i>, 2019<br>[<a href=\"https://cims.nyu.edu/~andrewgw/caseforbdl.pdf\">PDF</a>, <a href=\"https://cims.nyu.edu/~andrewgw/caseforbdl\">Web Version</a>, <a href=\"https://cims.nyu.edu/~andrewgw/caseforbdl.bib\">BibTeX</a>]<br><br>\n\n<b>Randomly Projected Additive Gaussian Processes for Regression</b><br>\nIan Delbridge, David S. Bindel, Andrew Gordon Wilson<br>\n<i>arXiv pre-print</i>, 2019<br>[<a href=\"https://arxiv.org/pdf/1912.12834\">PDF</a>, <a href=\"https://arxiv.org/abs/1912.12834\">arXiv</a>, <a href=\"https://github.com/idelbrid/Randomly-Projected-Additive-GPs\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/dpagp.bib\">BibTeX</a>]<br><br>\n\n\n<b>Semi-Supervised learning with Normalizing Flows</b><br>\nPavel Izmailov, Polina Kirichenko, Marc Finzi, Andrew Gordon Wilson<br>\n<i>arXiv pre-print</i>, 2019<br>[<a href=\"https://arxiv.org/pdf/1912.13025\">PDF</a>, <a href=\"https://arxiv.org/abs/1912.13025\">arXiv</a>, <a href=\"https://github.com/izmailovpavel/flowgmm\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/flowgmm.bib\">BibTeX</a>]<br><br>\n\n\n<b>A Simple Baseline for Bayesian Uncertainty in Deep Learning</b><br>\n        Wesley Maddox, Timur Garipov, Pavel Izmailov, Andrew Gordon Wilson<br>\n        To appear in <i>Advances in Neural Information Processing Systems</i> (NeurIPS), 2019<br>\n        [<a href=\"https://arxiv.org/pdf/1902.02476\">PDF</a>, <a href=\"https://arxiv.org/abs/1902.02476\">arXiv</a>, <a href=\"https://github.com/wjmaddox/swa_gaussian\">code</a>, <a href=\"swag.bib\">BibTeX</a>]<br>\n<br>\n\n<b>Function-Space Distributions over Kernels</b>\n<br>\nGreg Benton, Jayson Salkey, Wesley Maddox, Julio Albinati, Andrew Gordon Wilson\n<br>\nTo appear in <i>Advances in Neural Information Processing Systems</i> (NeurIPS), 2019. \n[<a href=\"https://arxiv.org/pdf/1910.13565\">PDF</a>,<a href=\"https://arxiv.org/abs/1910.13565\"> arXiv</a>, <a href=\"https://github.com/wjmaddox/spectralgp\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/fkl.bib\">BibTeX</a>] <br>\n<br>\n\n\n<b>Exact Gaussian Processes on a Million Data Points</b><br>\nKe Alexander Wang, Geoff Pleiss, Jake Gardner, Stephen Tyree, Kilian Weinberger, Andrew Gordon Wilson<br>\nTo appear in <i>Advances in Neural Information Processing Systems</i> (NeurIPS), 2019<br>[<a href=\"https://arxiv.org/pdf/1903.08114\">PDF</a>, <a href=\"https://arxiv.org/abs/1903.08114\">arXiv</a>, <a href=\"https://gpytorch.ai\">code</a>, <a href=\"https://github.com/cornellius-gp/gpytorch/blob/master/examples/01_Simple_GP_Regression/Simple_MultiGPU_GP_Regression.ipynb\">example \nnotebook</a>, <a href=\"https://cims.nyu.edu/~andrewgw/amillion.bib\">BibTeX</a>]<br><br>\n\n\n<b>Subspace Inference for Bayesian Deep Learning</b><br>\nPavel Izmailov*, Wesley Maddox*, Polina Kirichenko*, Timur Garipov*, Dmitry Vetrov, Andrew Gordon Wilson<br>\n<i>Uncertainty in Artificial Intelligence</i> (UAI), 2019<br>\n[<a href=\"https://arxiv.org/pdf/1907.07504.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1907.07504\">arXiv</a>, <a href=\"https://github.com/wjmaddox/drbayes\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/subspace.bib\">BibTeX</a>]<br><br>\n\n<b>Practical Multi-fidelity Bayesian Optimization for Hyperparameter Tuning</b><br>\nJian Wu, Saul Toscano-Palmerin, Peter I. Frazier, Andrew Gordon Wilson<br>\n<i>Uncertainty in Artificial Intelligence</i> (UAI), 2019<br>\n[<a href=\"https://arxiv.org/pdf/1903.04703\">PDF</a>, <a href=\"https://arxiv.org/abs/1903.04703\">arXiv</a>, <a href=\"https://cims.nyu.edu/~andrewgw/takg.bib\">BibTeX</a>]<br><br>\n\n\n<b>SWALP: Stochastic Weight Averaging in Low Precision Training</b><br>\nGuandao Yang, Tianyi Zhang, Polina Kirichenko, Junwen Bai, Andrew Gordon Wilson, Christopher De Sa<br>\n<i>International Conference on Machine Learning</i> (ICML), 2019<br>\n[<a href=\"https://arxiv.org/pdf/1904.11943.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1904.11943\">arXiv</a>, <a href=\"https://github.com/stevenygd/SWALP\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/swalp.bib\">BibTeX</a>]<br><br>\n<b>SysML: The New Frontier of Machine Learning Systems</b><br>\nA. Ratner et. al, 2019 <br>\n[<a href=\"https://arxiv.org/pdf/1904.03257.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1904.03257\">arXiv</a>, <a href=\"https://cims.nyu.edu/~andrewgw/sysml.bib\">BibTeX</a>]<br><br>\n<b>Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning</b><br>\nRuqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, Andrew Gordon Wilson<br>\n<i>arXiv pre-print</i>, 2019<br>\n[<a href=\"https://arxiv.org/pdf/1902.03932\">PDF</a>, <a href=\"https://arxiv.org/abs/1902.03932\">arXiv</a>, <a href=\"https://github.com/ruqizhang/csgmcmc\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/csgmcmc.bib\">BibTeX</a>]<br>        <br><b>\nThere Are Many Consistent Explanations of Unlabeled Data:<br> Why You Should Average<br>\n        </b>Ben Athiwaratkun, Marc Finzi, Pavel Izmailov, Andrew Gordon\n        Wilson<br>\n        <i>International Conference on Learning Representations</i> (ICLR), 2019<br>\n        [<a href=\"https://arxiv.org/pdf/1806.05594.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1806.05594\">arXiv</a>, <a href=\"https://github.com/benathi/fastswa-semi-sup\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/fastswa.bib\">BibTeX</a>]<br><br>\n<b>Change Surfaces for Expressive Multidimensional Changepoints and Counterfactual Prediction</b><br>\nWilliam Herlands, Daniel B. Neill, Hannes Nickisch, Andrew Gordon Wilson<br>\n<i>To appear in the Journal of Machine Learning Research</i> (JMLR), 2019<br>\n[<a href=\"https://arxiv.org/pdf/1810.11861\">PDF</a>, <a href=\"https://arxiv.org/abs/1810.11861\">arXiv</a>, <a href=\"https://cims.nyu.edu/~andrewgw/gpcs.bib\">BibTeX</a>]<br><br>\n        <b>GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference\n          with GPU Acceleration</b><br>\n        Jake Gardner, Geoff Pleiss, David Bindel, Kilian Weinberger,\n        Andrew Gordon Wilson<br>\n        <i>Neural Information Processing Systems</i> (NIPS), 2018<br>\n        <b>Spotlight</b><br>\n        [<a href=\"https://arxiv.org/pdf/1809.11165.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1809.11165\">arXiv</a>, <a href=\"https://gpytorch.ai/\">GPyTorch website</a>, <a href=\"https://github.com/cornellius-gp/gpytorch\">GPyTorch\n          repository</a>, <a href=\"gpytorch.bib\">BibTeX</a>]<br>\n        <br>\n        <b><b>Loss Surfaces, Mode Connectivity, and Fast Ensembling of\n            DNNs<br>\n          </b></b>Timur Garipov*, Pavel Izmailov*, Dmitrii Podoprikhin*,\n        Dmitry Vetrov, Andrew Gordon Wilson<br>\n        <i>Neural Information Processing Systems</i> (NIPS), 2018<br>\n        <b>Spotlight</b><br>\n        [<a href=\"https://arxiv.org/pdf/1802.10026.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1802.10026\">arXiv</a>, <a href=\"https://github.com/timgaripov/dnn-mode-connectivity\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/fge.bib\">BibTeX</a>]<br>\n        <br>\n         <b>Scaling Gaussian Process Regression with Derivatives<br>\n        </b>\n        <meta charset=\"utf-8\">\n        David Eriksson, Kun Dong, Eric Lee, David Bindel, Andrew Gordon\n        Wilson<br>\n        <i>Neural Information Processing Systems</i> (NIPS), 2018<br>\n        [<a href=\"https://arxiv.org/pdf/1810.12283.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1810.12283\">arXiv</a>, <a href=\"https://github.com/ericlee0803/GP_Derivatives\">code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/sgpderiv.bib\">BibTeX</a>]<br>\n        <br>\n        <!-- <b>Change Surfaces for Expressive Multidimensional Changepoints\n          and Counterfactual Prediction</b><br>\n        William Herlands, Daniel B. Neill, Hannes Nickisch, Andrew\n        Gordon Wilson<br>\n        <i>arXiv pre-print, </i>2018<br>\n        [PDF, arXiv, BibTeX]\n        <title></title>\n        <br>\n        <br>--> <b>Probabilistic FastText for Multisense Word\n          Embeddings<br>\n        </b>Ben Athiwaratkun, Andrew Gordon Wilson, Anima Anandkumar<br>\n        <i>Association for Computational Linguistics</i> (ACL), 2018<br>\n        <b>Oral presentation</b><br>\n        [<a href=\"https://arxiv.org/pdf/1806.02901.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1806.02901\">arXiv</a>, <a href=\"https://github.com/benathi/multisense-prob-fasttext\">code</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/pfast.bib\">BibTeX</a>]<br>\n        <b><b><br>\n          </b>Averaging Weights Leads to Wider Optima and Better\n          Generalization<br>\n        </b>Pavel Izmailov*, Dmitrii Podoprikhin*, Timur Garipov*,\n        Dmitry Vetrov, Andrew Gordon Wilson<br>\n        <i>Uncertainty in Artificial Intelligence </i>(UAI), 2018.<br>\n        <b>Oral presentation</b><br>\n        [<a href=\"https://arxiv.org/pdf/1803.05407.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1803.05407\">arXiv</a>, <a href=\"https://github.com/timgaripov/swa/\">code</a>, <a href=\"swa.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Automated Local Regression Discontinuity Design Discovery</b><br>\n        William Herlands, Ed McFowland III, Andrew Gordon Wilson, Daniel\n        B. Neill<br>\n        <i>Knowledge Discovery and Data Mining</i> (KDD), 2018<br>\n        [<a href=\"https://cims.nyu.edu/~andrewgw/p1512-herlands.pdf\">PDF</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/rddvideo.mp4\">Video</a>, <a href=\"https://cims.nyu.edu/~andrewgw/arddd.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Constant-Time Predictive Distributions for Gaussian Processes<br>\n        </b>Geoff Pleiss, Jacob Gardner, Kilian Q. Weinberger, Andrew\n        Gordon Wilson<br>\n        <i>International Conference on Machine Learning </i>(ICML),\n        2018<br>\n        [<a href=\"https://arxiv.org/pdf/1803.06058.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1803.06058\">arXiv</a>, <a href=\"https://github.com/cornellius-gp/gpytorch\">code</a>, <a href=\"love.bib\">BibTeX</a>]<br>\n        <b><b><br>\n          </b></b><b>Hierarchical Density Order Embeddings<br>\n        </b>Ben Athiwaratkun, Andrew Gordon Wilson<br>\n        <i>International Conference on Learning Representations </i>(ICLR),\n\n        2018.<br>\n        [<a href=\"https://arxiv.org/pdf/1804.09843.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1804.09843\">arXiv</a>, <a href=\"https://github.com/benathi/density-order-emb\">code</a>,\n        <a href=\"hdoe.bib\">BibTeX</a>]<b><b><br>\n            <br>\n            Product Kernel Interpolation for Scalable Gaussian Processes<br>\n          </b></b>Jacob Gardner, Geoff Pleiss, Ruihan Wu, Kilian\n        Weinberger, Andrew Gordon Wilson<b><br>\n        </b><i>Artificial Intelligence and Statistics </i>(AISTATS),\n        2018.<br>\n        [<a href=\"https://arxiv.org/pdf/1802.08903.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1802.08903\">arXiv</a>, <a href=\"https://github.com/cornellius-gp/gpytorch\">code</a>, <a href=\"skip.bib\">BibTeX</a>]<br>\n        <br>\n        <b><b>Gaussian Process Subset Scanning for Anomalous Pattern\n            Detection in Non-iid Data<br>\n          </b></b>William Herlands, Ed McFowland, Andrew Gordon Wilson,\n        Daniel B. Neill<br>\n        <i>Artificial Intelligence and Statistics </i>(AISTATS), 2018.<br>\n        [<a href=\"https://arxiv.org/pdf/1804.01466.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1804.01466\">arXiv</a>, <a href=\"gpss.bib\">BibTeX</a>]<b><br>\n          <br>\n          Bayesian GAN<br>\n        </b>Yunus Saatchi and Andrew Gordon Wilson<br>\n        <i>Neural Information Processing Systems</i> (NIPS), 2017 <br>\n        <b>Spotlight</b><br>\n        [<a href=\"https://cims.nyu.edu/~andrewgw/bayesganready.pdf\">PDF,</a>\n        <a href=\"https://arxiv.org/abs/1705.09558\">arXiv</a>, <a href=\"https://github.com/andrewgordonwilson/bayesgan\">code</a>,\n        <a href=\"https://www.youtube.com/watch?v=24A8tWs6aug\">Short\n          Video</a>, <a href=\"https://cims.nyu.edu/~andrewgw/bayesgan.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Bayesian Optimization with Gradients<br>\n        </b>Jian Wu, Matthias Poloczek, Andrew Gordon Wilson, Peter I\n        Frazier<br>\n        <i>Neural Information Processing Systems </i>(NIPS), 2017<i><br>\n        </i> <b>Oral Presentation</b><br>\n        [<a href=\"https://arxiv.org/pdf/1703.04389.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1703.04389\">arXiv</a>, <a href=\"https://github.com/wujian16/Cornell-MOE\">Code</a>, <a href=\"https://www.youtube.com/watch?v=mpIlAl_pw_k\">NIPS Oral\n          Presentation</a>, <a href=\"https://cims.nyu.edu/~andrewgw/bayesoptgrad.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Scalable Log Determinants for Gaussian Process Kernel\n          Learning</b><br>\n        Kun Dong, David Eriksson, Hannes Nickisch, David Bindel, Andrew\n        Gordon Wilson<br>\n        <i>Neural Information Processing Systems </i>(NIPS), 2017<i><br>\n        </i>[<a href=\"https://papers.nips.cc/paper/7212-scalable-log-determinants-for-gaussian-process-kernel-learning.pdf\">PDF</a>,\n        <a href=\"https://arxiv.org/abs/1711.03481\">arXiv</a>, <a href=\"https://github.com/jrg365/gpytorch\">Code</a>, <a href=\"https://www.youtube.com/watch?v=Y9U_nlu7-og\">Video (from\n          David E)</a>, <a href=\"logdet.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Scalable Levy Process Priors for Spectral Kernel Learning</b><br>\n        Andrew Loeb, Phillip Jang, Matthew Davidow, and Andrew Gordon\n        Wilson<br>\n        <i>Neural Information Processing Systems </i>(NIPS), 2017<i><br>\n        </i>[<a href=\"https://papers.nips.cc/paper/6983-scalable-levy-process-priors-for-spectral-kernel-learning.pdf\">PDF,</a>\n        <a href=\"https://arxiv.org/abs/1802.00530\">arXiv</a>, <a href=\"https://github.com/pjang23/levy-spectral-kernel-learning\">Code</a>,\n        <a href=\"https://www.youtube.com/watch?v=C4ZLupAbszM\">Video\n          (from Phillip J)</a>, <a href=\"levy.bib\">BibTeX</a>]<br>\n        <b><br>\n          Multimodal Word Distributions<br>\n        </b>Ben Athiwaratkun and Andrew Gordon Wilson<br>\n        <i>Association for Computational Linguistics</i> (ACL), 2017<br>\n        [<a href=\"https://arxiv.org/pdf/1704.08424.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1704.08424\">arXiv</a>, <a href=\"https://github.com/benathi/word2gm\">Code</a>, <a href=\"https://cims.nyu.edu/~andrewgw/multimodal.bib\">BibTeX</a>]\n        <br>\n        <br>\n        <b><b>Learning Scalable Deep Kernels with Recurrent Structure<br>\n          </b></b>Maruan Al-Shedivat, Andrew Gordon Wilson, Yunus\n        Saatchi, Zhiting Hu, Eric P. Xing<b><br>\n        </b> To appear in the <i>Journal of Machine</i> <i>Learning\n          Research </i>(JMLR)<i>, </i>2017.<b><br>\n        </b>[<a href=\"http://jmlr.org/papers/volume18/16-498/16-498.pdf\">PDF</a>,\n        <a href=\"https://arxiv.org/abs/1610.08936\">arXiv</a>, <a href=\"https://github.com/alshedivat/kgp\">code</a> [PyTorch,\n        more recent], <a href=\"https://github.com/alshedivat/kgp\">code</a>\n        [Keras+Matlab], <a href=\"https://cims.nyu.edu/~andrewgw/gplstm.bib\">BibTeX</a>]<b><br>\n          <br>\n          Stochastic Variational Deep Kernel Learning<br>\n        </b>Andrew Gordon Wilson*, Zhiting Hu*, Ruslan Salakhutdinov,\n        and Eric P. Xing<br>\n        <i>Neural Information Processing Systems</i> (NIPS), 2016<br>\n        [<a href=\"https://arxiv.org/pdf/1611.00336v2.pdf\">PDF</a>, <a href=\"https://arxiv.org/abs/1611.00336\">arXiv</a>, <a href=\"https://www.youtube.com/watch?v=dZQ82qBW7tk\">Video</a>,\n        <a href=\"https://github.com/cornellius-gp/gpytorch\">code</a>\n        (GPyTorch, more recent), <a href=\"https://cims.nyu.edu/~andrewgw/pattern\">code</a>\n        (Caffe+Matlab), <a href=\"https://cims.nyu.edu/~andrewgw/svdkl.bib\">BibTeX</a>]<br>\n        <br>\n        <b> Deep Kernel Learning<br>\n        </b>Andrew Gordon Wilson*, Zhiting Hu*, Ruslan Salakhutdinov,\n        and Eric P. Xing<br>\n        <i>Artificial Intelligence</i> <i>and Statistics</i> (AISTATS),\n        2016<br>\n        [<a href=\"http://jmlr.org/proceedings/papers/v51/wilson16.pdf\">PDF</a>,\n        <a href=\"https://arxiv.org/abs/1511.02222\">arXiv</a>, <a href=\"https://github.com/cornellius-gp/gpytorch\">code</a>\n        (GPyTorch, more recent), <a href=\"https://github.com/alshedivat/kgp\">code</a>\n        (Keras+Matlab), <a href=\"https://cims.nyu.edu/~andrewgw/pattern\">code</a>\n        (Caffe+Matlab), <a href=\"https://cims.nyu.edu/~andrewgw/dkl.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Thoughts on Massively Scalable Gaussian Processes<br>\n        </b>Andrew Gordon Wilson, Christoph Dann, and Hannes Nickisch<br>\n        arXiv pre-print, 2015<br>\n        (See <a href=\"http://jmlr.org/proceedings/papers/v37/wilson15.pdf\">KISS-GP</a>\n        and <a href=\"http://arxiv.org/abs/1511.02222\">Deep Kernel\n          Learning</a> for more empirical demonstrations).<br>\n        [<a href=\"http://arxiv.org/pdf/1511.01870v1.pdf\">PDF</a>, <a href=\"http://arxiv.org/abs/1511.01870\">arXiv</a>, <a href=\"https://github.com/cornellius-gp/gpytorch\">code</a>\n        (GPyTorch, more recent), <a href=\"https://cims.nyu.edu/~andrewgw/pattern\">code</a>\n        (older tutorials), <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/msgp.bib\">BibTeX</a>,\n        <a href=\"https://www.youtube.com/watch?v=aSiU1T_w0-8\">Music</a>]<br>\n        <b><br>\n          Scalable Gaussian Processes for Characterizing\n          Multidimensional Change Surfaces</b><br>\n        William Herlands, Andrew Gordon Wilson, Seth Flaxman, Daniel\n        Neill, Wilbert van Panhuis, and Eric P. Xing<br>\n        <i>Artificial Intelligence</i> <i>and Statistics</i> (AISTATS),\n        2016<br>\n        [<a href=\"http://jmlr.org/proceedings/papers/v51/herlands16.pdf\">PDF</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/changesurface.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Bayesian nonparametric kernel learning</b><br>\n        Junier Oliva*, Avinava Dubey*, Andrew Gordon Wilson, Barnabas\n        Poczos, Jeff Schneider, and Eric P. Xing.&nbsp; <br>\n        <i>Artificial Intelligence and Statistics</i> (AISTATS), 2016<br>\n        [<a href=\"http://jmlr.org/proceedings/papers/v51/oliva16.pdf\">PDF</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/bnpkernel.bib\">BibTeX</a>]<br>\n        <br>\n        <b>The human kernel<br>\n        </b>Andrew Gordon Wilson, Christoph Dann, Christopher G. Lucas,\n        and Eric P. Xing<br>\n        <i>Neural Information Processing Systems </i>(NIPS), 2015<br>\n        <i><b>Spotlight</b></i><br>\n        [<a href=\"https://papers.nips.cc/paper/5765-the-human-kernel.pdf\">PDF</a>,\n        <a href=\"http://arxiv.org/abs/1510.07389\">arXiv</a>, <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/humansupp.pdf\">Supplement</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/human.bib\">BibTeX</a>]<br>\n        <b><br>\n          Kernel interpolation for scalable structured Gaussian\n          processes (KISS-GP)<br>\n        </b>Andrew Gordon Wilson and Hannes Nickisch<br>\n        <i>International Conference on Machine Learning </i>(ICML),\n        2015<br>\n        <i><b>Oral Presentation</b></i><br>\n        [<a href=\"http://jmlr.org/proceedings/papers/v37/wilson15.pdf\">PDF</a>,\n        <a href=\"http://jmlr.org/proceedings/papers/v37/wilson15-supp.pdf\">Supplement</a>,\n        <a href=\"http://arxiv.org/abs/1503.01057\">arXiv</a>, <a href=\"https://github.com/cornellius-gp/gpytorch\">code</a>\n        (GPyTorch, newer), <a href=\"https://cims.nyu.edu/~andrewgw/pattern\">code</a>\n        (tutorials, older), <a href=\"https://cims.nyu.edu/~andrewgw/kiss.bib\">BibTeX</a>,\n        <a href=\"https://www.youtube.com/watch?v=U7NmUS7UWNQ\">Theme Song</a>,\n        <a href=\"http://videolectures.net/icml2015_wilson_kernel_interpolation/\">Video\n\n          Lecture</a>]<br>\n        <b><br>\n          Fast kronecker inference in Gaussian processes with\n          non-Gaussian likelihoods<br>\n        </b>Seth Flaxman, Andrew Gordon Wilson, Daniel Neill, Hannes\n        Nickisch, and Alexander J. Smola<b><br>\n        </b><i>International Conference on Machine Learning </i>(ICML),\n        2015<br>\n        <i><b>Oral Presentation</b></i><br>\n        [<a href=\"http://jmlr.org/proceedings/papers/v37/flaxman15.pdf\">PDF</a>,\n        <a href=\"http://jmlr.org/proceedings/papers/v37/flaxman15-supp.pdf\">Supplement</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/kroneckergeneral.bib\">BibTeX</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/pattern\">Code</a>,\n        <a href=\"http://videolectures.net/icml2015_flaxman_fast_kronecker_inference/\">Video\n\n          Lecture</a>]<br>\n        <b><br>\n        </b><b>\u00c0 la carte - learning fast kernels<br>\n        </b>Zichao Yang, Alexander J. Smola, Le Song, and Andrew Gordon\n        Wilson<br>\n        <i>Artificial Intelligence and Statistics </i>(AISTATS), 2015<br>\n        <b><i>Oral Presentation</i></b><br>\n        [<a href=\"http://arxiv.org/abs/1412.6493\">PDF</a>, <a href=\"https://cims.nyu.edu/~andrewgw/alacarte.bib\">BibTeX</a>]<br>\n        <b><br>\n          Fast kernel learning for multidimensional pattern\n          extrapolation <br>\n        </b>Andrew Gordon Wilson*, Elad Gilboa*, Arye Nehorai, and John\n        P. Cunningham<br>\n        <i>Advances in Neural Information Processing Systems </i>(NIPS)\n        2014<br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/manet.pdf\">PDF</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/manet.bib\">BibTeX</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/pattern\">Code</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/manetslides.pdf\">Slides</a>]<br>\n        <b> <br>\n          Variational inference for latent variable modelling of\n          correlation structure<br>\n        </b>Mark van der Wilk, Andrew Gordon Wilson, Carl Edward\n        Rasmussen<br>\n        <i>NIPS Workshop on </i><i>Advances in Variational Inference, </i>2014<br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/wplvm.pdf\">PDF</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/wplvm.bib\">BibTeX</a>]<br>\n        <b><br>\n          A Bayesian method to quantifying chemical composition using\n          NMR: application to porous media systems<br>\n        </b>Yuting Wu, Daniel J. Holland, Mick D. Mantle, Andrew Gordon\n        Wilson, Sebastian Nowozin, Andrew Blake, and Lynn F. Gladden<br>\n        European Signal Processing Conference (EUSIPCO), 2014<br>\n        [<a href=\"http://www.nowozin.net/sebastian/papers/wu2014porousmedia.pdf\">PDF</a>]<br>\n        <b> <br>\n          Bayesian inference for NMR spectroscopy with applications to\n          chemical quantification<br>\n        </b>Andrew Gordon Wilson, Yuting Wu, Daniel J. Holland,\n        Sebastian Nowozin, Mick D. Mantle, Lynn F. Gladden, and Andrew\n        Blake<i><br>\n          In Submission</i>. February 14, 2014<br>\n        [<a href=\"http://arxiv.org/abs/1402.3580\">arXiv</a>, <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/nmrspectroscopy.pdf\">PDF</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/nmrspectroscopy.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Covariance kernels for fast automatic pattern discovery and\n          extrapolation with Gaussian processes</b><br>\n        Andrew Gordon Wilson<br>\n        PhD Thesis, January 2014<br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/andrewgwthesis.pdf\">PDF</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/agwthesis.bib\">BibTeX</a>]<br>\n        <b><br>\n          Student-<i>t</i></b><i> </i><b>processes as alternatives to\n          Gaussian processes</b><br>\n        Amar Shah, Andrew Gordon Wilson, and Zoubin Ghahramani<br>\n        <i>Artificial Intelligence and Statistics</i>, 2014<br>\n        [<a href=\"http://arxiv.org/abs/1402.4306\">arXiv</a>, <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/tprocess.pdf\">PDF</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/tprocsupp.pdf\">Supplementary</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/tproc.bib\">BibTeX</a>]<br>\n        <br>\n        <b>The change point kernel<br>\n        </b>Andrew Gordon Wilson<br>\n        Technical Report (Note), University of Cambridge.<br>\n        November 2013.<br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/changepoints.pdf\">PDF,</a>\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/wilsonchangepoints.bib\">BibTeX</a>]<br>\n        <br>\n        <b><b>GPatt: Fast multidimensional pattern extrapolation with\n            Gaussian processes<br>\n          </b></b>Andrew Gordon Wilson, Elad Gilboa, Arye Nehorai, and\n        John P. Cunningham<br>\n        October 21, 2013.&nbsp;&nbsp; <i>In Submission</i>.<br>\n        [<a href=\"http://arxiv.org/abs/1310.5288\">arXiv</a>, <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/GPatt.pdf\">PDF</a>, <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/gpatt.bib\">BibTeX</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/pattern\">Resources\n\n\n\n          and Tutorial</a>]<b><br>\n          <br>\n          Bayesian optimization using Student-<i>t</i> processes<br>\n        </b>Amar Shah, Andrew Gordon Wilson, and Zoubin Ghahramani<br>\n        <i>NIPS Workshop on Bayesian Optimisation</i>, 2013.<br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/tpoptimisation.pdf\">PDF</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/tprocop.bib\">BibTeX</a>]<br>\n        <b><br>\n          Gaussian process kernels for pattern discovery and\n          extrapolation<br>\n        </b>Andrew Gordon Wilson and Ryan Prescott Adams<br>\n        <i>International Conference on Machine Learning </i>(ICML),\n        2013.<br>\n        <b><i>Oral Presentation</i></b><br>\n        [<a href=\"http://arxiv.org/abs/1302.4245\">arXiv</a>, <a href=\"http://jmlr.org/proceedings/papers/v28/wilson13.pdf\">PDF</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/typo.pdf\">Correction</a>,\n        <a href=\"http://jmlr.org/proceedings/papers/v28/wilson13-supp.pdf\">Supplementary</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/smkernel.bib\">BibTeX</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/patternwilson.pdf\">Slides</a>,\n        <a href=\"https://cims.nyu.edu/~andrewgw/pattern\">Resources\n\n\n\n          and Tutorial</a>, <a href=\"https://github.com/cornellius-gp/gpytorch\">GPyTorch\n          implementation</a>, <a href=\"http://techtalks.tv/talks/gaussian-process-kernels-for-pattern-discovery-and-extrapolation/58204/\">Video\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Lecture</a>]<br>\n        <br>\n        <b>Modelling input varying correlations between multiple\n          responses<br>\n        </b>Andrew Gordon Wilson and Zoubin Ghahramani<br>\n        <i>European Conference on Machine Learning</i> (ECML), 2012<br>\n        <a href=\"http://www.ecmlpkdd2012.net/calls/call-for-nectar-talks\"><i><b>Nectar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n              Track</b></i></a>&nbsp; <i>for \"significant machine\n          learning results\"<br>\n          <b>Oral Presentation</b></i><br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/agwnectarecml.pdf\">PDF</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/agwnectar.bib\">BibTeX</a>]<br>\n        <br>\n        <b>A process over all stationary covariance kernels<br>\n        </b>Andrew Gordon Wilson<br>\n        Technical Report, University of Cambridge.<br>\n        June 2012.<br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/spectralkernel.pdf\">PDF,</a>\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/spectralkernel.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Gaussian process regression networks</b><br>\n        Andrew Gordon Wilson, David A. Knowles, and Zoubin Ghahramani<br>\n        <i>International Conference on Machine Learning</i> (ICML),\n        2012.<br>\n        <i><b>Oral Presentation</b></i><br>\n        [<a href=\"http://icml.cc/2012/papers/329.pdf\">PDF</a>, <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/gprn.bib\">BibTeX</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/gprnslidesicml.pdf\">Slides</a>,\n        <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/gprnsupp.pdf\">Supplementary</a>,\n        <a href=\"http://techtalks.tv/talks/gaussian-process-regression-networks/57326/\">Video\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Lecture</a>, <a href=\"https://github.com/davidaknowles/gprn\">Original\n\n\n\n\n\n\n\n\n\n\n\n\n          Code</a>, <a href=\"https://github.com/trungngv/gprn\">New Code</a>]<br>\n        <br>\n        <b>Generalised Wishart processes</b><br>\n        Andrew Gordon Wilson and Zoubin Ghahramani<br>\n        <i>Uncertainty in Artificial Intelligence</i> (UAI), 2011.<br>\n        <b><i>Best Student Paper Award</i></b><br>\n        [<a href=\"http://www.cs.cmu.edu/%7Eandrewgw/gwp.pdf\">PDF</a>, <a href=\"http://mlg.eng.cam.ac.uk/andrew/gwp/gwp.bib\">BibTeX</a>]<br>\n        <br>\n        <b>Copula processes<br>\n        </b>Andrew Gordon Wilson and Zoubin Ghahramani<br>\n        <i>Advances in Neural Information Processing Systems</i> (NIPS),\n        2010.<i><b><br>\n            Spotlight</b></i><br>\n        [<a href=\"http://papers.nips.cc/paper/4082-copula-processes\">PDF</a>,\n        <a href=\"http://papers.nips.cc/paper/4082-copula-processes\">\n          BibTeX</a>, <a href=\"http://www.cs.cmu.edu/%7Eandrewgw/cpslides.pdf\"> Slides</a>,\n        <a href=\"http://videolectures.net/nips2010_wilson_cp\">Video\n          Lecture</a>]</section>\n      <footer> Find me on <a href=\"https://twitter.com/andrewgwils\">Twitter</a>\n        <br>\n        Theme Inspired by Dan Foreman-Mackey<br>\n      </footer>\n    </div>\n  \n\n</body></html>"