{"email": ["jjcorso@eecs.umich.edu\n", "jjcorso@eecs.umich.edu\n", "jjcorso@eecs.umich.edu\n"], "image": ["https://cse.engin.umich.edu/~jjcorso/U-M_2color-HorizontalReversed.png", "https://cse.engin.umich.edu/people/faculty/pic-jcorso.jpg", "http://twitter-badges.s3.amazonaws.com/t_small-a.png", "https://cse.engin.umich.edu/people/faculty/r/career/files/rep-figure-CAREER.png", "http://twitter-badges.s3.amazonaws.com/follow_me-b.png"], "research_blurb": ["bioinformaticsbiomarkersbiometrics\n <div class=bioblock style=\"background-color:#ee2222; font-weight: bolder; padding: 8px;\">\n \n <font color=\"#ffffff\">\n Prof. Corso is in the process of transferring his website to the new \n Michigan domain; please disregard broken links if you comes across \n them.\n </font>\n \n </div>\n \n \n \n \n His main research thrust is high-level computer vision and its\n relationship to human language, robotics and data science.  He\n primarily focuses on problems in .  From\n biomedicine to recreational video, imaging data is ubiquitous.  Yet,\n imaging scientists and intelligence analysts are without an adequate\n language and set of tools to fully tap the information-rich image and\n video.  He works to provide such a language;  specifically, he\n primarily studies the coupled problems of segmentation and recognition\n from a Bayesian perspective emphasizing the role of statistical models\n in efficient visual inference.  His long-term goal is a comprehensive\n and robust methodology of automatically mining, quantifying, and\n generalizing information in large sets of projective and volumetric\n images and video.\n \n \n   88 challenging \n     videos of various cooking (third-person viewpoint, different \n     backgrounds, dynamic camera and person movement) with natural \n     language annotations (about 8 per video) and object and action \n     annotations.  Includes a benchmark ROUGE scoring evaluation.  The \n     data set was published with "]}