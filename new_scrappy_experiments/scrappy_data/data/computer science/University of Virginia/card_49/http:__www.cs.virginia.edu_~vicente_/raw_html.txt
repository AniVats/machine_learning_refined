"<html><head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<title>Vicente Ordonez Homepage</title>\n<link href=\"css/bootstrap.min.css\" rel=\"stylesheet\">\n<link href=\"css/font-awesome.min.css\" rel=\"stylesheet\">\n<link href=\"css/stylesheet.css\" rel=\"stylesheet\" type=\"text/css\">\n<!--link href='http://fonts.googleapis.com/css?family=Lato:300,400,900' rel='stylesheet' type='text/css'-->\n</head>\n<body>\n\n<div id=\"page\">\n<div id=\"inner-page\">\n\n<div id=\"main\"> \n\n<div id=\"title\">\n\n<a href=\"images/vicente_2019x.png\"><img id=\"photo\" src=\"images/vicente_2019x.jpg\" width=\"170\" alt=\"Vicente\" style=\"border:1px solid #ddd\"></a>\n\n<div style=\"float:left;width:800px\">\n\n\n\n<div class=\"x-badge\" style=\"float:left;width:260px\">\n<h1 id=\"name\">Vicente Ord\u00f3\u00f1ez Rom\u00e1n</h1> \nAssistant Professor <span style=\"color:#888\"></span><br>\nDepartment of Computer Science<br>\n<a href=\"http://www.virginia.edu\">University of Virginia</a><br>\nvicente@virginia.edu\n</div>\n\n<!--div class=\"x-badge\" style=\"float:left;width:320px\">\n<h1 id=\"name\">&nbsp;</h1> \nVisiting Professor <span style=\"color:#888\"></span><br/>\n<a href=\"https://research.adobe.com/\">Adobe Research</a><br>\n</div-->\n\n<div class=\"x-badge\" style=\"float:right\">\n\t<img src=\"images/uvalogo.png\" width=\"152\" style=\"margin-top:2px;margin-right:0px\">\n</div>\n\n\n\n<!--div class=\"badge\" style=\"float:left;width:300px\">\nVisiting Research Fellow<br/>\n<a href=\"http://allenai.org\" style=\"font-weight:bold\">Allen Institute for Artificial Intelligence (<img src=\"images/ai2.png\" height=\"16\"/>)</a><br/>\nSeattle, Washington <br/>\n</div-->\n\n<div id=\"intro\" style=\"clear:both;padding-top:0px\">\nMy research lies at the intersection of Computer Vision, Natural Language Processing and Machine Learning. I am especially interested\nin analyzing, and mining useful human insights from enormous amounts of images with associated text to improve visual recognition.\nI am also interested in building efficient visual recognition models that can perform high-level perceptual tasks for applications\nin social media, urban computing, and everyday activities. More recently, I am also involved in research on fairness and accountability in machine learning applications.</div>\n\n</div>\n\n\n<div style=\"clear:both\"> \n\n<!--div style=\"float:left;width:580px;padding:14px;position:relative\" id=\"about\"-->\n<div style=\"padding:10px;position:relative\" id=\"about\">\n<!--div id=\"borderRight\" style=\"position:absolute;border-right:1px solid #ccc;top:20%;left:100%;bottom:20%\"></div-->\n\t<span class=\"heading-main\">About me</span>\n<p style=\"padding-bottom:0;margin-bottom:0;margin-top:8px\">\nI'm a tenure-track Assistant Professor in the Department of Computer Science at the University of Virginia. I have also spent time as visiting professor at <a href=\"https://research.adobe.com/\">Adobe Research</a> and as visiting researcher at the <a href=\"http://allenai.org\">Allen Institute for Artificial Intelligence (AI2)</a>. I received my PhD in Computer Science at the <a href=\"http://www.unc.edu\">University of North Carolina at Chapel Hill</a> in 2015 advised by Prof. <a href=\"http://tamaraberg.com\">Tamara Berg</a>.\nPreviously, I obtained an MS in Computer Science at <a href=\"http://www.stonybrook.edu\">Stony Brook University (SUNY)</a> and an engineering degree at the <a href=\"http://www.espol.edu.ec\">Escuela Superior Polit\u00e9cnica del Litoral</a> in Ecuador.\nI'm a recipient of a Best -Long- Paper Award at the 2017 Conference on Empirical Methods in Natural Language Processing (<a href=\"http://emnlp2017.net/\">EMNLP</a>), and the Best Paper -<a href=\"http://www.pamitc.org/iccv13/awards.php\">Marr Prize</a>- Award at the 2013 International Conference in Computer Vision (ICCV). I have also been awarded an IBM Faculty Award and a Google Faculty Research Award. Here is a link to an official <a href=\"bio.txt\">bio</a>, and my <a href=\"cv_vicente.pdf\">curriculum vitae</a>. <!--I'm also the mysterious juggler in page fourteen in <a href =\"http://arxiv.org/pdf/1605.06863v1.pdf\">this paper</a>.-->\n</p>\n</div> <!--  about  -->\n\n</div>\n\n\n<div style=\"clear:both\"> \n\t<div style=\"padding:5px 40px 0 10px;float:left;width:560px\" id=\"news\">\n\t<span class=\"heading-main\">News and updates</span>\n\t\t<ul style=\"padding:10px;margin:0\">\n\t\t\t<li>Serving as Area Chair for <a href=\"http://cvpr2020.thecvf.com/\">CVPR 2020</a>, <a href=\"https://eccv2020.eu/\">ECCV 2020</a>, <a href=\"https://acl2020.org/\">ACL 2020</a>.</li>\n\t\t\t<li>10/2019. Invited Speaker at ICCV 2019 <a href=\"https://sites.google.com/view/lingir\">Workshop on Linguistics Meets Image and Video Retrieval</a>. Seoul, South Korea.</li>\n\t\t\t<li> Posts from NVIDIA [<a href=\"https://news.developer.nvidia.com/ai-model-can-generate-images-from-natural-language-descriptions/\">link</a>] and IBM Research [<a href=\"https://www.ibm.com/blogs/research/2019/06/text2scene-textual-descriptions/\">link</a>] about <a href=\"https://arxiv.org/abs/1809.01110\">Text2Scene</a></li>\n\t\t\t<li>06/2019. <a href=\"https://arxiv.org/abs/1809.01110\">Text2Scene</a> gets named among 45 Best CVPR Paper Finalists among 1,294 accepted papers (top 1% of all submissions) [<a href=\"http://cvpr2019.thecvf.com/files/CVPR%202019%20-%20Welcome%20Slides%20Final.pdf\">link</a>]</li>\n\t\t\t<li>05/2019. Invited Panelist at Ethics in AI Panel at <a href=\"https://escapevelocity.events/\">Escape Velocity 2019</a>, Washington DC's National Harbor.</li>\n\t\t\t<!--li>04/2019. PhD Student <a href=\"http://www.cs.virginia.edu/~tw8cb\">Tianlu Wang</a> speaking at the <a href=\"https://tomtomfest.com/machine-learning/amlc-speakers/\">TomTom Applied Machine Learning Conference</a>.</li>\n\t\t\t<li>09/2018. Panelist and co-organizer. <a href=\"http://tapiaconference.org/schedule/friday-september-21-2018/1030am-1200pm/dealing-with-bias-and-unfairness-in-machine-learning-algorithms/\"> Dealing with Bias and Unfairness in ML</a> at ACM Richard Tapia Celebration of Diversity in Computing, Orlando, FL.</li--s>\n\t\t    <!--li>09/2018. Invited Speaker, <a href=\"https://sites.google.com/view/sivl/\">ECCV Workshop on Shortcomings in Vision and Language (SiVL)</a>, Munich, Germany.</li-->\n\t\t\t<!--li>03/2018. Keynote Speaker, <a href=\"http://ivl.ut.ee/index.php/Main/Programme\">Integrating Vision and Language (iV&amp;L)</a> Conference, Tartu, Estonia.</li-->\n\t\t\t<!--li>02/2018. Received a <a href=\"https://research.googleblog.com/2018/03/google-faculty-research-awards-2017.html\">Google Faculty Research Award 2017</a>. Thanks Google!</li>\n\t\t\t<li>01/2018. Received an <a href=\"https://www.research.ibm.com/university/awards/faculty_innovation_2017.shtml\">IBM Faculty Award 2017</a>. Thanks IBM!</li-->\n\t\t\t<!--li>Quoted in The Cavalier Daily [<a href=\"http://www.cavalierdaily.com/article/2017/09/apples-face-id-recognizing-a-promising-future\">1</a>] [<a href=\"http://www.cavalierdaily.com/article/2017/10/audio-manipulation-technology-has-the-potential-for-creating-fake-news\">2</a>] and WIRED [<a href=\"https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/\">3</a>].</li-->\n\t\t\t<!--li>08/2017. Our work at UVA with UCLA's NLP Group gets coverage in <a href=\"https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/\">WIRED</a>, <a href=\"http://www.dailymail.co.uk/sciencetech/article-4810982/AIs-learn-photos-sexist.html\">Daily Mail</a>, <a href=\"https://www.thetimes.co.uk/article/home-robots-will-turn-into-crude-sexists-experts-warn-gnmj09rgq\">The Times of London</a>, <a href=\"https://www.glamour.com/story/even-artificial-intelligence-is-sexist\">Glamour</a>, <a href=\"https://www.bloomberg.com/news/articles/2017-12-04/researchers-combat-gender-and-racial-bias-in-artificial-intelligence\">Bloomberg</a>.</li-->\n\t\t\t<!--li>09/2017. Best --Long-- Paper Award at <a href=\"http://emnlp2017.net/\">EMNLP 2017</a>~!</li-->\n\t\t\t<!--li>2 long papers accepted to EMNLP 2017, 1 paper accepted to CVPR 2017</li-->\n\t\t    <!--li>10/30/2016. Our work at the Allen Institute on accelerating neural networks gets featured in the <a href=\"http://www.nytimes.com/2016/10/31/technology/beyond-silicon-squeezing-more-out-of-chips.html\">New York Times</a> and <a href=\"https://news.cs.washington.edu/2016/10/31/uw-cse-and-ai2-in-the-new-york-times-artificial-intelligence-at-your-fingertips/\">UW CSE News</a>.</li-->\n\t\t\t<!--li>October 14th, 2016 - Presented at the <a href=\"https://pages.shanti.virginia.edu/DHUVA_Conference_9-16/schedule-registration/\">DH@UVA Digital Humanities Conference</a>, and our group also got featured in <a href=\"https://www.news.virginia.edu/content/powerful-legacy-and-bright-future-digital-humanities\">UVA Today</a> in a related note.</li>\n\t\t\t<li>Oct. 14th, 2016 - Our group's research gets a mention in <a href=\"https://www.news.virginia.edu/content/powerful-legacy-and-bright-future-digital-humanities\">UVA Today</a>.</li>\n\t\t\t<li>July 1st, 2016 - Organized the <a href=\"http://www.cs.virginia.edu/~vicente/bigvision2016\">BigVision</a> workshop at CVPR 2016.</li>\n\t\t\t<li>Advice to prospective graduate students interested in our group [<a href=\"note.html\">here</a>]</li-->\n\t\t</ul>\n\t</div>\n\n\t<div style=\"padding:5px 10px 0 16px;float:left;width:440px\" id=\"news\">\n\t<span class=\"heading-main\">Teaching</span>\n\t\t<ul style=\"padding:10px;margin:0\">\n\t\t\t<li><a href=\"http://vicenteordonez.com/deeplearning\">Deep Learning for Visual Recognition</a> [<a href=\"http://vicenteordonez.com/deeplearning\">Spring 2020</a>]</li>\n\t\t\t<li>Introduction to Computer Vision [<a href=\"http://vicenteordonez.com/vision/\">Fall 2019</a>] [<a href=\"http://vicenteordonez.com/vision/2018\">Spring 2018</a>]</li>\n\t\t\t<li>Deep Learning for Visual Recognition [<a href=\"http://vicenteordonez.com/deeplearning/2019\">Spring 2019</a>]</li>\n\t\t\t<li>Computational Visual Recognition [<a href=\"http://www.cs.virginia.edu/~vicente/recognition/\">Fall 2017</a>] [<a href=\"http://www.cs.virginia.edu/~vicente/recognition/2016\">Fall 2016</a>]</li>\n\t\t\t<li>Vision &amp; Language [<a href=\"http://www.cs.virginia.edu/~vicente/vislang/\">Spring 2017</a>]</li>\n\t\t</ul>\n\t\t<div style=\"font-size:0.9em\">I'm also co-organizing with students in my group the <br><a href=\"http://vision.cs.virginia.edu/seminar\">UVA Computer Vision seminar</a>. I also co-direct with Paul Humphreys the <a href=\"http://hmi.virginia.edu\">Human and Machine Intelligence seminar</a>.</div>\n\t</div>\n\n</div>\n\n<div style=\"padding:10px;position:relative;clear:both\" id=\"about\">\n<!--div id=\"borderRight\" style=\"position:absolute;border-right:1px solid #ccc;top:20%;left:100%;bottom:20%\"></div-->\n\t<span class=\"heading-main\">Research Group</span>\n<p style=\"padding-bottom:0;margin-bottom:0;margin-top:8px\">\n<a href=\"http://www.cs.virginia.edu/~tw8cb/\">Tianlu Wang</a> <span class=\"stitle\">(PhD Student)</span>, <a href=\"http://www.cs.virginia.edu/~ft3ex/\">Fuwen Tan</a> <span class=\"stitle\">(PhD Student)</span>, Ziyan Yang <span class=\"stitle\">(PhD Student)</span>, <a href=\"http://www.cs.virginia.edu/~pc9za/\">Paola Cascante-Bonilla</a> <span class=\"stitle\">(PhD Student)</span>, Leticia Pinto <span class=\"stitle\">(Visiting Student)</span>, <!--Brandon Peck <span class=\"stitle\">(Undergraduate student)</span-->Lindsey Shavers <span class=\"stitle\">(Undergraduate Student)</span>, <!-- MengJia Luo <span class=\"stitle\">(Undergraduate Student)</span>, --> Jeffrey Tan <span class=\"stitle\">(Undergraduate Student)</span>.\n</p>\n</div>\n\n<!--div style=\"padding:10px;position:relative;clear:both\" id=\"about\">\n<div id=\"borderRight\" style=\"position:absolute;border-right:1px solid #ccc;top:20%;left:100%;bottom:20%\"></div>\n\t<span class=\"heading-main\"><strong>Former Students</strong></span>\n<p style=\"padding-bottom:0;margin-bottom:0\">\nDivya Bhaskhara <span class=\"stitle\">(B.Sc. Capstone Project, 2016)</span>, Nova Zhang <span class=\"stitle\">(Undergraduate Student, Spring 2017)</span>\n</p>\n</div-->\n\n\n\n</div> <!-- title -->\n\n\n<div id=\"publications\" style=\"clear:both;padding:16px 10px 10px 10px\">\n\n<span class=\"heading-main\">Research and Publications</span>\n\n<ul class=\"pub_table\">\n\n<li class=\"pub_item\">\n<img src=\"images/self-paced.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<span style=\"color:#e53333\">NEW!</span> <a class=\"blue_link\" href=\"https://arxiv.org/abs/2001.06001\">Curriculum Labeling: Self-paced Pseudo-Labeling for Semi-Supervised Learning</a> <br>\n<span class=\"pub_authors\">Paola Cascante-Bonilla, Fuwen Tan, <a href=\"https://www.cs.virginia.edu/yanjun/\">Yanjun Qi</a>, <a href=\"index.html\">Vicente Ordonez</a>.  </span>\n<br><span class=\"pub_info\">arxiv:2001.06001. January 2020.</span><br>\n[<a href=\"https://arxiv.org/abs/2001.06001\">arxiv</a>] [<a href=\"files/self-paced.txt\">bibtex</a>]\n</p>\n</div>\n\n</li><li class=\"pub_item\">\n<img src=\"images/testing.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<span style=\"color:#e53333\">NEW!</span> <a class=\"blue_link\" href=\"https://arxiv.org/abs/1905.07831\">Testing DNN Image Classifiers for Confusion &amp; Bias Errors</a> <br>\n<span class=\"pub_authors\">Yuchi Tian, Ziyuan Zhong, <a href=\"index.html\">Vicente Ordonez</a>, Gail Kaiser, <a href=\"http://rayb.info/\">Baishakhi Ray</a>.  </span>\n<br><span class=\"pub_info\">arXiv:1905.07831. December 2019.<br>\n[<a href=\"https://arxiv.org/abs/1905.07831\">arxiv</a>] [<a href=\"files/testing_bib.txt\">bibtex</a>]\n</span></p>\n</div>\n</li>\n\n\n\n<li class=\"pub_item\">\n<img src=\"images/drilldown.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1911.03826\">Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries</a> <br>\n<span class=\"pub_authors\">Fuwen Tan, Paola Cascante-Bonilla, Xiaoxiao Guo, <a href=\"https://www.spacewu.com/\">Hui Wu</a>, <a href=\"https://researcher.watson.ibm.com/researcher/view.php?person=us-sfeng\">Song Feng</a>, <a href=\"index.html\">Vicente Ordonez</a>.  </span>\n<br><span class=\"pub_info\">Conf. on Neural Information Processing Systems. <strong>NeurIPS 2019</strong>. Vancouver, Canada. December 2019.<br>\n[<a href=\"https://arxiv.org/abs/1911.03826\">arxiv</a>] [<a href=\"https://github.com/uvavision/DrillDown\">code</a>] [<a href=\"files/drilldown.txt\">bibtex</a>]\n</span></p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/debias.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1811.08489\">Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations</a> <br>\n<span class=\"pub_authors\">Tianlu Wang, Jieyu Zhao, <a href=\"http://markyatskar.com/\">Mark Yatskar</a>, <a href=\"http://www.cs.virginia.edu/~kc2wc/\">Kai-Wei Chang</a>, <a href=\"index.html\">Vicente Ordonez</a>.  </span>\n<br><span class=\"pub_info\">International Conference on Computer Vision. <strong>ICCV 2019</strong>. Seoul, South Korea. October 2019.<br>\n[<a href=\"https://arxiv.org/abs/1811.08489\">arxiv</a>] [<a href=\"files/gendervision.txt\">bibtex</a>]\n</span></p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/moviescope.jpeg\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p style=\"padding-bottom: 5px\">\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1908.03180\">Moviescope: Large-scale Analysis of Movies using Multiple Modalities</a> <br>\n<span class=\"pub_authors\">Paola Cascante-Bonilla, Kalpathy Sitaraman, Mengjia Luo<a href=\"index.html\">Vicente Ordonez</a>.  </span>\n<br><span class=\"pub_info\">arXiv:1908.03180. August 2019.<br>\n[<a href=\"https://arxiv.org/abs/1908.03180\">arxiv</a>] [<a href=\"http://www.cs.virginia.edu/~pc9za/research/moviescope.html\">project page</a>] [<a href=\"files/moviescope.txt\">bibtex</a>]<br>\n<span style=\"font-weight:bold;padding-left:20px\"><a href=\"https://techxplore.com/news/2019-08-features-movie-genre.html?fbclid=IwAR1oJnZw5WxkcDfaIMOmxZ4Oj9xyuXbkybQhep-aJgcTrRRNwYcooVSGOsA\">- TechXplore News Coverage</a></span>\n</span></p>\n</div>\n</li>\n\n\n<li class=\"pub_item\">\n<img src=\"images/text2scene.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p style=\"padding-bottom:5px\">\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1809.01110\">Text2Scene: Generating Compositional Scenes from Textual Descriptions</a> <br>\n<span class=\"pub_authors\">Fuwen Tan, <a href=\"https://researcher.watson.ibm.com/researcher/view.php?person=us-sfeng\">Song Feng</a>, <a href=\"http://vicenteordonez.com\">Vicente Ordonez</a></span>. <br><span class=\"pub_info\">Intl. Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2019</strong>. <br> Long Beach, California. June 2019.</span> [<a href=\"https://arxiv.org/abs/1809.01110\">arxiv</a>] [<a href=\"https://github.com/uvavision/Text2Scene\">code</a>] [<a href=\"http://vision.cs.virginia.edu:5000\">demo</a>] [<a href=\"files/text2scene_bib.txt\">bibtex</a>] <em style=\"color:#a00\">(~Oral presentation + Best Paper Finalist <span style=\"font-size:0.8em;font-weight:lighter;\"> -- top 1% of submissions</span>)</em><br>\n<span style=\"font-weight:bold;padding-left:20px\"><a href=\"https://www.ibm.com/blogs/research/2019/06/text2scene-textual-descriptions/\">- IBM Research Blog Coverage</a></span><br>\n<span style=\"font-weight:bold;padding-left:20px\"><a href=\"https://news.developer.nvidia.com/ai-model-can-generate-images-from-natural-language-descriptions/\">- NVIDIA News Coverage</a>\n</span></p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/bias-nlp.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n <a class=\"blue_link\" href=\"#\">Gender Bias in Contextualized Word Embeddings</a> <br>\n<span class=\"pub_authors\">Jieyu Zhao, Tianlu Wang, <a href=\"http://markyatskar.com/\">Mark Yatskar</a>, <a href=\"https://ryancotterell.github.io/\">Ryan Cotterell</a>, <a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://www.cs.virginia.edu/~kc2wc/\">Kai-Wei Chang</a>.  </span>\n<br><span class=\"pub_info\">North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2019</strong>. short. <br>Minneapolis, Minnesota. June 2019.</span> [<a href=\"https://arxiv.org/abs/1904.03310\">arxiv</a>] [<a href=\"files/genderbiaselmo_bib.txt\">bibtex</a>] <em style=\"color:#a00\">(~Oral presentation)</em>\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/chatcrowd3.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n <a class=\"blue_link\" href=\"https://chatcrowd.github.io/\">Chat-crowd: A Dialog-based Platform for Visual Layout Composition</a> <br>\n<span class=\"pub_authors\">Paola Cascante-Bonilla, Xuwang Yin, <a href=\"index.html\">Vicente Ordonez</a>, <a href=\"https://researcher.watson.ibm.com/researcher/view.php?person=us-sfeng\">Song Feng</a>.  </span>\n<br><span class=\"pub_info\">North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2019</strong>. System Demonstrations. <br>Minneapolis, Minnesota. June 2019.</span>\n[<a href=\"https://arxiv.org/abs/1812.04081\">arxiv</a>] [<a href=\"https://chatcrowd.github.io/\">project page</a>] [<a href=\"https://github.com/uvavision/chat-crowd\">code</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/multimedia.png\" width=\"100\" height=\"68\" alt=\"composition\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1805.08587\">Deep Feature Aggregation and Image Re-ranking with Heat Diffusion for Image Retrieval</a> <br>\n<span class=\"pub_authors\">Shanmin Pang, Jin Ma, Jianru Xue, Jihua Zhu, Vicente Ordonez.  </span>\n<br><span class=\"pub_info\"><strong>IEEE Transactions on Multimedia 2019</strong> (Journal). [Accepted October 2018].</span><br>\n[<a href=\"https://arxiv.org/abs/1805.08587\">arxiv</a>] [<a href=\"files/multimedia.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n\n<li class=\"pub_item\">\n<img src=\"images/feedbackprop.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1710.08049\">Feedback-prop: Convolutional Neural Network Inference under Partial Evidence</a> <br>\n<span class=\"pub_authors\"><a href=\"http://www.cs.virginia.edu/~tw8cb/\">Tianlu Wang</a>, <a href=\"http://vision.is.tohoku.ac.jp/~kyamagu/\">Kota Yamaguchi</a>, <a href=\"index.html\">Vicente Ordonez</a></span>. <br><span class=\"pub_info\">Intl. Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2018</strong>. Salt Lake City, Utah. June 2018.</span><br>\n[<a href=\"https://arxiv.org/pdf/1710.08049.pdf\">pdf</a>] [<a href=\"https://arxiv.org/abs/1710.08049\">arXiv</a>] [<a href=\"https://github.com/uvavision/feedbackprop\">code</a>] [<a href=\"files/feedbackprop_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/bias-nlp.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1804.06876\">Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods</a> <br>\n<span class=\"pub_authors\">Jieyu Zhao, Tianlu Wang, <a href=\"http://markyatskar.com/\">Mark Yatskar</a>, <a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://www.cs.virginia.edu/~kc2wc/\">Kai-Wei Chang</a>.  </span>\n<br><span class=\"pub_info\">North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2018</strong>. short. <br>New Orleans, Louisiana. June 2018.</span>\n[<a href=\"files/winobias.pdf\">pdf</a>] [<a href=\"https://arxiv.org/abs/1804.06876\">arXiv</a>] [<a href=\"https://github.com/uclanlp/corefBias\">code</a>] [<a href=\"files/coref_bias.txt\">bibtex</a>] \n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/pr2018.png\" width=\"100\" height=\"68\" alt=\"composition\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"https://www.sciencedirect.com/science/article/pii/S0031320318301808\">Building Discriminative CNN Image Representations for Object Retrieval using the Replicator Equation</a> <br>\n<span class=\"pub_authors\">Shanmin Pang, Jihua Zhu, Jiaxing Wang, Vicente Ordonez, Jianru Xue.  </span>\n<br><span class=\"pub_info\"><strong>Pattern Recognition 2018</strong> (Journal). Volume 83. Pages 150-160. [Accepted April 2018].</span><br>\n[<a href=\"https://www.sciencedirect.com/science/article/pii/S0031320318301808\">link</a>] [<a href=\"https://github.com/pangsm0415/ReSW\">code</a>] [<a href=\"files/pr2018.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/composition.png\" width=\"100\" height=\"68\" alt=\"composition\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1706.01021\">Where and Who? Automatic Semantic-Aware Person Composition</a> <br>\n<span class=\"pub_authors\">Fuwen Tan, Crispin Bernier, Benjamin Cohen, <a href=\"index.html\">Vicente Ordonez</a>, Connelly Barnes.  </span>\n<br><span class=\"pub_info\">Winter Conference on Applications of Computer Vision. <strong>WACV 2018</strong>. Lake Tahoe, Nevada. March 2018.</span><br>\n[<a href=\"files/wacv18.pdf\">pdf</a>] [<a href=\"https://arxiv.org/abs/1706.01021\">arXiv</a>]  [<a href=\"files/wacv18_supp.pdf\">supp. material</a>] [<a href=\"https://github.com/fwtan/who_where\">code</a>] [<a href=\"files/TanBCOB17.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n\n\n<li class=\"pub_item\">\n<img src=\"images/bias.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p style=\"padding-bottom:5px;\">\n<a class=\"blue_link\" href=\"files/bias.pdf\">Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints</a> <br>\n<span class=\"pub_authors\">Jieyu Zhao, Tianlu Wang, <a href=\"http://markyatskar.com/\">Mark Yatskar</a>, <a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://www.cs.virginia.edu/~kc2wc/\">Kai-Wei Chang</a>.  </span>\n<br><span class=\"pub_info\">Empirical Methods in Natural Language Processing. <strong>EMNLP 2017</strong>. Copenhagen, Denmark. September 2017.</span><br>\n[<a href=\"files/bias.pdf\">pdf</a>] [<a href=\"https://github.com/uclanlp/reducingbias\">code</a>] [<a href=\"files/biasemnlp.txt\">bibtex</a>]\n<em style=\"color:#a00\">(~Oral presentation + Best Long Paper Award!)</em><br>\n<span style=\"font-weight:bold;padding-left:20px\"><a href=\"https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/\">- WIRED News Coverage</a></span><br>\n<span style=\"font-weight:bold;padding-left:20px\"><a href=\"http://www.dailymail.co.uk/sciencetech/article-4810982/AIs-learn-photos-sexist.html\">- Daily Mail News Coverage</a></span><br>\n<span style=\"font-weight:bold;padding-left:20px\"><a href=\"https://www.thetimes.co.uk/article/home-robots-will-turn-into-crude-sexists-experts-warn-gnmj09rgq\">- Times of London News Coverage</a></span>\n</p>\n</div>\n</li>\n\n\n<li class=\"pub_item\">\n<img src=\"images/obj2text.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"http://vision.cs.virginia.edu/obj2text\">Obj2Text: Generating Visually Descriptive Language from Object Layouts</a> <br>\n<span class=\"pub_authors\">Xuwang Yin, <a href=\"index.html\">Vicente Ordonez</a>.  </span>\n<br><span class=\"pub_info\">Empirical Methods in Natural Language Processing. <strong>EMNLP 2017</strong>. Copenhagen, Denmark. September 2017.</span><br>\n[<a href=\"files/obj2text.pdf\">pdf</a>] [<a href=\"https://arxiv.org/abs/1707.07102\">arxiv</a>] [<a href=\"https://github.com/uvavision/obj2text-neuraltalk2\">code</a>] [<a href=\"files/obj2text.txt\">bibtex</a>]\n<em style=\"color:#a00\">(~Oral presentation)</em>\n</p>\n</div>\n</li>\n\n\n\n<li class=\"pub_item\">\n<img src=\"images/imsitu.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"https://arxiv.org/abs/1612.00901\">Commonly Uncommon: Semantic Sparsity in Situation Recognition</a> <br>\n<span class=\"pub_authors\"><a href=\"http://markyatskar.com/\">Mark Yatskar</a>, <a href=\"index.html\">Vicente Ordonez</a>, <a href=\"https://www.cs.washington.edu/people/faculty/lsz\">Luke Zettlemoyer</a>, <a href=\"https://homes.cs.washington.edu/~ali/\">Ali Farhadi</a></span>.  \n<br><span class=\"pub_info\">Intl. Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2017</strong>. Honolulu, Hawaii. July 2017.</span><br>\n[<a href=\"http://openaccess.thecvf.com/content_cvpr_2017/papers/Yatskar_Commonly_Uncommon_Semantic_CVPR_2017_paper.pdf\">pdf</a>] [<a href=\"https://arxiv.org/abs/1612.00901\">arXiv</a>] [<a href=\"files/commonly_uncommon_bib.txt\">bibtex</a>] [<a href=\"http://imsitu.org/demo\">demo</a>] \n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/xnornet.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p style=\"padding-bottom: 5px\">\n<a class=\"blue_link\" href=\"http://arxiv.org/abs/1603.05279\">XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</a> <br>\n<span class=\"pub_authors\"><a href=\"http://www.umiacs.umd.edu/~mrastega/\">Mohammad Rastegari</a>, <a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://pjreddie.com/\">Joseph Redmon</a>, <a href=\"https://homes.cs.washington.edu/~ali/\">Ali Farhadi</a></span>. \n<br><span class=\"pub_info\">European Conference on Computer Vision. <strong>ECCV 2016</strong>. Amsterdam, The Netherlands. October 2016.</span><br>\n[<a href=\"http://arxiv.org/abs/1603.05279\">arXiv</a>] [<a href=\"http://allenai.org/plato/xnornet/\">project page</a>] [<a href=\"https://github.com/allenai/XNOR-Net\">code</a>] [<a href=\"files/xnornet_bib.txt\">bibtex</a>]\n<em style=\"color:#a00\">(~Oral presentation)</em><br>\n<span style=\"font-weight:bold;padding-left:20px\"><a href=\"http://www.nytimes.com/2016/10/31/technology/beyond-silicon-squeezing-more-out-of-chips.html\">- New York Times News Coverage</a></span><br>\n<span style=\"font-weight:bold;padding-left:20px\"><a href=\"https://news.cs.washington.edu/2016/10/31/uw-cse-and-ai2-in-the-new-york-times-artificial-intelligence-at-your-fingertips/\">- Article on University of Washington News</a></span>\n</p>\n</div>\n</li>\n\n\n<li class=\"pub_item\">\n<img src=\"images/commonsense.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"files/naacl2016.pdf\">Stating the Obvious: Extracting Visual Common Sense Knowledge</a> <br>\n<span class=\"pub_authors\"><a href=\"http://markyatskar.com/\">Mark Yatskar</a>, <a href=\"index.html\">Vicente Ordonez</a>,  <a href=\"https://homes.cs.washington.edu/~ali/\">Ali Farhadi</a></span>. \n<br><span class=\"pub_info\"> North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2016</strong>. short. <br>San Diego, CA. June 2016.</span>\n[<a href=\"files/naacl2016.pdf\">pdf</a>] [<a href=\"files/naacl2016_bib.txt\">bibtex</a>]\n<em style=\"color:#a00\">(~Oral presentation)</em>\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/cacm.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n <a class=\"blue_link\" href=\"files/cacm2016.pdf\">Learning to Name Objects</a> <br>\n<span class=\"pub_authors\"><a href=\"index.html\">Vicente Ordonez</a>, Wei Liu, <a href=\"http://web.eecs.umich.edu/~jiadeng/\">Jia Deng</a>, <a href=\"http://homes.cs.washington.edu/~yejin/\">Yejin Choi</a>, <a href=\"http://acberg.com\">Alexander C. Berg</a>, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a></span>. \n<br><span class=\"pub_info\"> Communications of the ACM. March 2016 (Vol. 59, No. 3).</span> <em style=\"color:#a00\">(~Research Highlight)</em>\n<br>[<a href=\"files/cacm2016.pdf\">pdf</a>] [<a href=\"http://cacm.acm.org/magazines/2016/3/198851-learning-to-name-objects/fulltext\">link</a>] [<a href=\"http://cacm.acm.org/magazines/2016/3/198875-technical-perspective-taming-the-name-game/fulltext\">technical perspective</a>] [<a href=\"files/cacm_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/whatshouldicallit.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"files/ijcv_entrylevel.pdf\">Predicting Entry-Level Categories</a> <br>\n<span class=\"pub_authors\"><a href=\"index.html\">Vicente Ordonez</a>, Wei Liu, <a href=\"http://web.eecs.umich.edu/~jiadeng/\">Jia Deng</a>, <a href=\"http://homes.cs.washington.edu/~yejin/\">Yejin Choi</a>, <a href=\"http://acberg.com\">Alexander C. Berg</a>, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a></span>. \n<br><span class=\"pub_info\"> International Journal of Computer Vision - Marr Prize Special Issue. <strong>IJCV 2015</strong>.</span>\n<br>[<a href=\"files/ijcv_entrylevel.pdf\">pdf</a>] [<a href=\"http://link.springer.com/article/10.1007/s11263-015-0815-z\">link</a>]\n[<a href=\"files/ijcv_entrylevel_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/generation.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"files/ijcv_bigdata.pdf\">Large Scale Retrieval and Generation of Image Descriptions</a><br>\n<span class=\"pub_authors\"><a href=\"index.html\">V. Ordonez</a>, X. Han, P. Kuznetsova, G. Kulkarni, M. Mitchell, K. Yamaguchi, K. Stratos, <br>A. Goyal, J. Dodge, A. Mensch, H. Daume III, A.C. Berg, Y. Choi, T.L. Berg</span>. \n<br><span class=\"pub_info\"> International Journal of Computer Vision. <strong>IJCV 2015</strong>. [August 2016 Issue].</span>\n[<a href=\"files/ijcv_bigdata.pdf\">pdf</a>] [<a href=\"http://dx.doi.org/10.1007/s11263-015-0840-y\">link</a>]\n[<a href=\"files/ijcv_bigdata_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img style=\"margin-left:20px;margin-top:10px\" src=\"images/unc_seal_blue.jpg\" width=\"80\" height=\"80\" alt=\"generation\" class=\"x\">\n<div>\n<p>\nPh.D. Thesis. [<a href=\"files/thesis_4-24-2015.pdf\">pdf</a>] [<a href=\"files/thesis_4-24-2015_bib.txt\">bibtex</a>]\n<br> Language and Perceptual Categorization in Computational Visual Recognition.<br>\n<span class=\"pub_authors\"><a href=\"index.html\">Vicente Ord\u00f3\u00f1ez Rom\u00e1n</a>. April 2015.</span>\n<br>Department of Computer Science. The University of North Carolina at Chapel Hill. \n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/referitgame.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"http://tamaraberg.com/referitgame/\">ReferItGame: Referring to Objects in Photographs of Natural Scenes</a><br>\n<span class=\"pub_authors\">Sahar Kazemzadeh, <a href=\"index.html\">Vicente Ordonez</a>, Mark Matten, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a></span>. \n<br><span class=\"pub_info\"> Empirical Methods on Natural Language Processing. <strong>EMNLP 2014</strong>. Doha, Qatar. October 2014.</span>\n<br>[<a href=\"files/referit.pdf\">pdf</a>] [<a href=\"http://www.cs.virginia.edu/~vicente/referit/\">project page</a>] [<a href=\"http://referitgame.com\">game</a>]\n[<a href=\"files/referit_bib.txt\">bibtex</a>] \n<em style=\"color:#a00\">(~Oral presentation)</em>\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/urban.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"http://www.cs.virginia.edu/~vicente/urban/index.html\">Learning High-level Judgments of Urban Perception</a><br>\n<span class=\"pub_authors\"><a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a></span>. \n<br><span class=\"pub_info\"> European Conference on Computer Vision. <strong>ECCV 2014</strong>. Zurich, Switzerland. September 2014.</span>\n<br>[<a href=\"urban/vicente_eccv14.pdf\">pdf</a>][<a href=\"http://www.cs.virginia.edu/~vicente/urban/index.html\">project page</a>]\n[<a href=\"files/vicente_eccv14_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/treetalk.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"files/treetalk_camera_ready.pdf\">TreeTalk: Composition and Compression of Trees for Image Descriptions</a><br>\n<span class=\"pub_authors\"><a href=\"http://www.cs.stonybrook.edu/~pkuznetsova\">Polina Kuznetsova, </a><a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a>, <a href=\"http://homes.cs.washington.edu/~yejin/\">Yejin Choi</a></span>. \n<br><span class=\"pub_info\"> Transactions of the Association for Computational Linguistics. <strong>TACL 2014</strong>. <br>To be presented at EMNLP 2014 in Doha, Qatar. October 2014.</span> [<a href=\"files/treetalk_camera_ready.pdf\">pdf</a>]\n[<a href=\"files/treetalk_camera_ready_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/furniture2.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<span style=\"color:#e53333;font-family:Helvetica\"></span> <a class=\"blue_link\" href=\"files/furnituregeek.pdf\">Furniture-Geek: Understanding Fine-Grained Furniture Attributes\nfrom Freely Associated Text and Tags</a><br>\n<span class=\"pub_authors\"><a href=\"index.html\">Vicente Ordonez, </a><a href=\"http://labs.ebay.com/people/vignesh-jagadeesh/\">Vignesh Jagadeesh</a>, <a href=\"#\">Wei Di</a>, <a href=\"#\">Anurag Bhardwaj</a>, <a href=\"http://labs.ebay.com/people/robinson-piramuthu/\">Robinson Piramuthu</a></span>. \n<br><span class=\"pub_info\">IEEE Winter Conference on Applications of Computer Vision. <strong>WACV 2014</strong>. Steamboat Springs, CO. March 2014.</span><br>\n[<a href=\"files/furnituregeek.pdf\">pdf</a>] [<a href=\"files/furnituregeek_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/whatshouldicallit.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"http://www.cs.virginia.edu/~vicente/entrylevel/index.html\">From Large Scale Image Categorization to Entry-Level Categories</a> <br>\n<span class=\"pub_authors\"><a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://ai.stanford.edu/~jiadeng/\">Jia Deng</a>, <a href=\"http://homes.cs.washington.edu/~yejin/\">Yejin Choi</a>, <a href=\"http://acberg.com\">Alexander C. Berg</a>, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a></span>. \n<br><span class=\"pub_info\">IEEE International Conference on Computer Vision. <strong>ICCV 2013</strong>. Sydney, Australia. December 2013.</span>\n<br>[<a href=\"files/entrylevel.pdf\">pdf</a>] [<a href=\"files/entrylevel_supplemental.pdf\">supplemental material</a>] [<a href=\"entrylevel/iccv2013_slides.pptx\">slides</a>] [<a href=\"http://www.cs.virginia.edu/~vicente/entrylevel/index.html\">project page</a>] [<a href=\"files/entrylevel_bib.txt\">bibtex</a>] <em style=\"color:#a00\">(~Oral Presentation + Best Paper Award - Marr Prize!)</em>\n</p>\n</div>\n</li>\n\n\n<li class=\"pub_item\">\n<img src=\"images/generalizing.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"files/acl13_generalization.pdf\">Generalizing Image Captions for Image-Text Parallel Corpus</a><br>\n<span class=\"pub_authors\"><a href=\"http://www.cs.stonybrook.edu/~pkuznetsova\">Polina Kuznetsova, </a><a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://acberg.com\">Alexander C. Berg</a>, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a>, <a href=\"http://homes.cs.washington.edu/~yejin/\">Yejin Choi</a></span>. \n<br><span class=\"pub_info\">Association for Computational Linguistics. <strong>ACL 2013</strong>. short. Sofia, Bulgaria. August 2013.</span>\n<br>[<a href=\"files/acl13_generalization.pdf\">pdf</a>] [<a href=\"http://www.cs.stonybrook.edu/~pkuznetsova/imgcaption/\">data+results</a>]\n[<a href=\"files/acl13_generalization_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/babytalk2.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"files/babytalk_pami13.pdf\">Baby Talk: Understanding and Generating Simple Image Descriptions</a><br>\n<span class=\"pub_authors\">G. Kulkarni, V. Premraj, <a href=\"index.html\">V. Ordonez</a>, S. Dhar, S. Li, <a href=\"http://homes.cs.washington.edu/~yejin/\">Y. Choi</a>, <a href=\"http://acberg.com\">A. C. Berg</a>, <a href=\"http://tamaraberg.com\">T. L. Berg</a></span>. \n<br><span class=\"pub_info\"> IEEE Transactions on Pattern Analysis and Machine Intelligence. <strong>PAMI 2013</strong></span>\n<br>[<a href=\"files/babytalk_pami13.pdf\">pdf</a>] [<a href=\"http://dx.doi.org/10.1109/TPAMI.2012.162\">link</a>] \n[<a href=\"files/babytalk_pami13_bib.txt\">bibtex</a>]\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/acl.png\" width=\"100\" height=\"68\" alt=\"generation\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"files/acl12_generation.pdf\">Collective Generation of Natural Image Descriptions</a><br>\n<span class=\"pub_authors\"><a href=\"http://www.cs.stonybrook.edu/~pkuznetsova\">Polina Kuznetsova, </a><a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://acberg.com\">Alexander C. Berg</a>, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a>, <a href=\"http://homes.cs.washington.edu/~yejin/\">Yejin Choi</a></span>. \n<br><span class=\"pub_info\"> Association for Computational Linguistics. <strong>ACL 2012</strong>. Jeju, South Korea. July 2012.</span>\n<br>[<a href=\"files/acl12_generation.pdf\">pdf</a>] [<a href=\"http://tlberg.cs.unc.edu/~vicente/clsp11/SBU_Captioned_Photo_Dataset_v1.1.tgz\">data</a>]\n[<a href=\"files/acl12_generation_bib.txt\">bibtex</a>]\n<em style=\"color:#a00\">(~Oral presentation)</em>\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/im2text.png\" width=\"100\" height=\"68\" alt=\"im2text\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"http://www.cs.virginia.edu/~vicente/sbucaptions\">Im2Text: Describing Images Using 1 Million Captioned Photographs</a><br>\n<span class=\"pub_authors\"><a href=\"index.html\">Vicente Ordonez</a>, Girish Kulkarni, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a></span>.\n<br><span class=\"pub_info\">Conf. in Neural Information Processing Systems. <strong>NeurIPS 2011</strong>. Granada, Spain. December 2011.</span>\n<br>[<a href=\"files/generation_nips2011.pdf\">pdf</a>][<a href=\"sbucaptions\">code+dataset</a>] [<a href=\"files/im2text_nips11_poster.pdf\">poster</a>] [<a href=\"http://tlberg.cs.unc.edu/vicente/python_server_files/py/website/search.py\">search tool</a>] [<a href=\"files/generation_nips2011_bib.txt\">bibtex</a>]\n<em style=\"color:#a00\">(~Spotlight presentation)</em>\n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/aesthetics.png\" width=\"100\" height=\"68\" alt=\"attributes\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"files/aesthetics_cvpr11.pdf\">High Level Describable Attributes for Predicting Aesthetics and Interestingness</a><br>\n<span class=\"pub_authors\">Sagnik Dhar, <a href=\"index.html\">Vicente Ordonez</a>, <a href=\"http://tamaraberg.com\">Tamara L. Berg</a></span>. \n<br><span class=\"pub_info\">IEEE Computer Vision and Pattern Recognition. <strong>CVPR 2011</strong>. Colorado Springs, CO. June 2011.</span> \n<br>[<a href=\"files/aesthetics_cvpr11.pdf\">pdf</a>] [<a href=\"code.html\">related code for saliency + low DoF attributes</a>]\n[<a href=\"files/aesthetics_cvpr11_bib.txt\">bibtex</a>] \n</p>\n</div>\n</li>\n\n<li class=\"pub_item\">\n<img src=\"images/ariadne.jpg\" width=\"100\" height=\"68\" alt=\"ariadne\" class=\"shadow\">\n<div>\n<p>\n<a class=\"blue_link\" href=\"http://dx.doi.org/10.1109/MIC.2009.90\">The Ariadne Infrastructure for Managing and Storing Metadata</a><br>\n<span class=\"pub_authors\">S. Ternier, G. Parra, B. Vandeputte, K. Verbert, J. Klerkx, <a href=\"http://www.cs.kuleuven.ac.be/~erikd/\">E. Duval</a>, <a href=\"index.html\">V. Ordonez</a>, <a href=\"http://ariadne.cti.espol.edu.ec/xavier\">X. Ochoa</a></span>.<br>\n<span class=\"pub_info\"><strong>IEEE Internet Computing 2009 </strong>. Emerging Internet Technologies and Applications for E-learning.</span><br>\n[<a href=\"http://dx.doi.org/10.1109/MIC.2009.90\">link</a>]\n</p>\n</div>\n</li>\n\n</ul>\n\n<span class=\"heading-main\">Current and recent collaborators</span>\n<div style=\"margin-top:8px;margin-bottom:18px\">\n\t<a href=\"https://www.cs.virginia.edu/yanjun/\">Yanjun Qi</a> (University of Virginia), <a href=\"https://research.adobe.com/person/franck-dernoncourt/\">Franck Dernoncourt</a> (Adobe Research), <a href=\"https://research.adobe.com/person/vlad-morariu/\">Vlad Morariu</a> (Adobe Research), <a href=\"http://users.umiacs.umd.edu/~varunm/\">Varun Manjunatha</a> (Adobe Research), <a href=\"https://research.adobe.com/person/rajiv-jain/\">Rajiv Jain</a> (Adobe Research), <a href=\"https://researcher.watson.ibm.com/researcher/view.php?person=us-sfeng\">Song Feng</a> (IBM Research), <a href=\"https://www.spacewu.com/\">Hui Wu</a> (IBM Research), Xiaoxiao Guo (IBM Research),  <a href=\"http://www3.cs.stonybrook.edu/~pkuznetsova/\">Polina Kuznetsova</a> (Facebook), <a href=\"http://vision.is.tohoku.ac.jp/~kyamagu\">Kota Yamaguchi</a> (CyberAgent Inc), <a href=\"http://rayb.info/\">Baishakhi Ray</a> (Columbia University), <a href=\"http://yangfengji.net/\">Yangfeng Ji</a> (University of Virginia), <a href=\"http://markyatskar.com/\">Mark Yatskar</a> (Allen Institute for Artificial Intelligence), <a href=\"http://kwchang.net\">Kai-Wei Chang</a> (University of California Los Angeles), <a href=\"http://jyzhao.net/\">Jieyu Zhao</a> (University of California Los Angeles).\n</div>\n\n<span class=\"heading-main\">Current and Past Funding Support</span>\n<div style=\"margin-top:10px;margin-bottom:14px;clear:both;height:60px\">\n<img src=\"images/sap-logo.svg\" width=\"100\" alt=\"SAP SE\" style=\"float:left;margin:4px 30px 4px 30px\">  <img src=\"images/leidos-logo.svg\" width=\"170\" alt=\"Leidos Inc\" style=\"float:left;margin:8px 30px 5px 30px\"> <img src=\"images/adobe.svg\" width=\"56\" alt=\"Google\" style=\"float:left;margin:0 20px 0 20px\"> <img src=\"images/ibm-logo.png\" width=\"240\" alt=\"IBM Research\" style=\"float:left;margin:5px\"><img src=\"images/google-logo.svg\" width=\"140\" alt=\"Google\" style=\"float:left;margin:12px\">\n</div>\n\n</div> <!-- publications -->\n</div> <!-- main -->\n<div style=\"padding:14px 0px 50px 0px;text-align:center;clear:both\">\nDepartment of Computer Science @ <a href=\"http://www.virginia.edu\">The University of Virginia</a> \u2012 85 Engineer's Way, Rice Hall, Charlottesville, VA 22904-4740\n</div>\n</div> <!-- inner-page -->\n</div> <!-- page -->\n\n<!-- Start of StatCounter Code -->\n<script type=\"text/javascript\">\nvar sc_project=6642097; \nvar sc_invisible=1; \nvar sc_security=\"b7beb148\"; \n</script>\n\n<script type=\"text/javascript\" src=\"http://www.statcounter.com/counter/counter.js\"></script><noscript><div\nclass=\"statcounter\"><a title=\"visit tracker on tumblr\"\nhref=\"http://statcounter.com/tumblr/\" target=\"_blank\"><img\nclass=\"statcounter\"\nsrc=\"http://c.statcounter.com/6642097/0/b7beb148/1/\"\nalt=\"visit tracker on tumblr\" ></a></div></noscript>\n<!-- End of StatCounter Code -->\n\n<!--script src=\"js/bootstrap.min.js\"></script-->\n\n\n</body></html>"