"<html><head>\n<meta charset=\"UTF-8\">\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<title>Hyun Soo Park</title>\n<link href=\"css/simpleGridTemplate.css\" rel=\"stylesheet\" type=\"text/css\">\n</head>\n<body>\n  <div class=\"gallery\">\n    <div class=\"thumbnail\"> \n     <a href=\"#\"><img src=\"hs_photo.jpg\" width=\"90\" align=\"right\"></a>\n       <h4><font size=\"6\">HYUN SOO PARK</font></h4>\n      <p class=\"tag\"><strong>Assistant Professor</strong></p>\n      <p class=\"tag\"><small><a href=\"https://www.cs.umn.edu/\">Computer Science &amp; Engineering</a><br>\n        University of Minnesota, Twin Cities</small></p>\n      <p class=\"tag\"><small>Office 261 / Lab 232 <br>\n\t  <a href=\"https://goo.gl/maps/9kQ6UQHzssR2\">Shepherd Laboratory</a><br>(Gemini-Huntley Robotics Research Lab)</small></p>\n      <p class=\"tag\"><small>hspark at umn.edu <br>\n        +1-612-301-1745 </small></p>\n\t<p class=\"tag\"><small>Office hour: Mon 1-2pm / Wed 2-3pm </small></p>\n\t  <h4>&nbsp;</h4>\n<h4><font size=\"5\">TEAM</font></h4>\n<p class=\"tag\"><font size=\"3\"><strong>I am looking for a postdoctoral fellow.</strong></font></p>\n\n<p class=\"tag\"><small><a href=\"http://www-users.cs.umn.edu/~jsyoon/\">Jae Shin Yoon</a> (PhD)<br>\n\t<a href=\"https://sites.google.com/view/yasaminjafarian/yasaminjafarian\">Yasamin Jafarian</a> (PhD)<br>\n\tZhixuan Yu (PhD)<br>\n\tZhijie Zhu (PhD, Co-advised by <a href=\"https://sites.google.com/view/mcalpineresearchgroup\">Prof. McAlpine</a>)<br>\n\tYuan Yao (PhD, 3M Fellow)<br>\n\tJingfan Guo (PhD)<br>\n\tJayant Sharma (PhD)<br>\n\tPraneet Bala (PhD)<br>\n\tTien Do (PhD, Co-advised by <a href=\"http://mars.cs.umn.edu/\">Prof. Roumeliotis</a>)</small></p>\n\n\t      <p class=\"tag\"><small><strong><font color=\"000000\">To join my team:</font></strong><br>\n\t\t  Stduents: please read my <a href=\"prospective.html\">note</a>. <br>\n\t\t  Postdocs: please fill this <a href=\"https://goo.gl/forms/ZB8r0PDpL3SX6QMp2\">form</a>. <br></small>\n\t\t  </p>\n\n\t<h4>&nbsp;</h4>\t\n   <h4><font size=\"5\">TEACHING</font></h4>\n   <p class=\"tag\"><small><strong><font color=\"000000\">S2020:</font></strong> <a href=\"https://www-users.cs.umn.edu/~hspark/csci5561_S2020/csci5561.html\">Computer Vision (CSci 5561)</a></small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">F2019:</font></strong> <a href=\"https://www-users.cs.umn.edu/~hspark/csci5561_F2019/csci5561.html\">Computer Vision (CSci 5561)</a></small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">S2019:</font></strong> <a href=\"https://www-users.cs.umn.edu/~hspark/csci5561_S2019/csci5561.html\">Computer Vision (CSci 5561)</a></small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">F2018:</font></strong> Elementray Computational Linear Algebra (CSci 2033)</small></p>\t  \n<p class=\"tag\"><small><strong><font color=\"000000\">S2018:</font></strong> <a href=\"http://www-users.cs.umn.edu/~hspark/CSci5980/csci5980_3dvision.html\">Multiview 3D Geometry in Computer Vision (CSci 5980)</a></small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">F2017:</font></strong> Elementray Computational Linear Algebra (CSci 2033)</small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">S2017:</font></strong> <a href=\"http://www-users.cs.umn.edu/~hspark/CSci5980/csci5980_3dvision_S2017.html\">Multiview 3D Geometry in Computer Vision (CSci 5980/8980) </a></small></p>\n<h4>&nbsp;</h4>\t\n   <h4><font size=\"5\">OUTREACH</font></h4>\n\t  \n<p class=\"tag\"><small><a href=\"https://sites.google.com/view/vcai\">UMN Visual Computing and AI seminar (VCAI)</a></small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Tutorial: </font></strong><a href=\"http://domedb.perception.cs.cmu.edu/tutorials/cvpr17/index.html\">Multiview Camera System</a></small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Tutorial: </font></strong><a href=\"FirstPersonVision/cvpr15_tutorial_firstpersonvision.html\">First Person Vision</a></small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Tutorial: </font></strong><a href=\"GroupBehavior/cvpr15_tutorial_group_behavior.html\">Group Behavior Analysis</a></small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Workshop: </font></strong><a href=\"http://www.cmpe.boun.edu.tr/hbu/2014/index.html\">Human Behavior Understanding</a></small></p>\n\n    </div>\n    <div class=\"thumbnail\"> \n      <h4><font size=\"5\">NEWS</font></h4>\n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Feb 2020:</font></strong> \n\t  HUMBI paper is accepted to CVPR 2020.\t </small></p>\n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Feb 2019:</font></strong> \n\t  View synthesis paper with Jae Shin, Kihwan, and Orazio is accepted to CVPR 2020.\t </small></p>\n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Feb 2020:</font></strong> Give a talk on HUMBI at <a href=\"http://www.cvpr2020-ac-meeting.org/workshop.html\">CVPR AC Workshop</a>.</small></p>\n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Feb 2020:</font></strong> Give a talk on Behavioral Imaging at UC Berkeley.</small></p>\n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Feb 2020:</font></strong> Will serve as an AC for ACCV 2020.</small></p>\n  \n\t<p class=\"tag\"><small><strong><font color=\"000000\">Jan 2020:</font></strong> Give a talk on Scaling Up Behavioral Imaging at Toyota Research Institute, Cambridge, MA.</small></p>\n\n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Nov 2019:</font></strong> Give a talk on Multiview Supervision at 3M.</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Oct 2019:</font></strong> Give a talk on Multiview Supervision at Samsung AI Center - NY.</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Sep 2019:</font></strong> Give a talk on Scaling Up Behavioral Imaging at MSU ML seminar.</small></p>\n\n\t\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Sep 2019:</font></strong> \n\t  The Multiview Supervision by Registration paper with Yilun is accepted to WACV 2020.\t </small></p>\t\n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Sep 2019:</font></strong> \n\t  The Multiview Segmentation paper with Yuan is accepted to WACV 2020.\t </small></p>\t\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Jul 2019:</font></strong> \n\t  Will serve as an AC for CVPR 2020 and WACV 2020.</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Jul 2019:</font></strong> \n\t  Receive <a href=\"https://www.nsf.gov/awardsearch/showAward?AWD_ID=1919965&amp;HistoricalAwards=false\">NSF's MRI Award</a> to scale up behavioral imaging system (400 cameras). <img src=\"nsf.gif\" width=\"30\"></small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Jul 2019:</font></strong> \n\t  The MONET paper with Yuan and Yasamin is accepted to ICCV 2019.\t </small></p>\t\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Jun 2019:</font></strong> Receive the UMN DTI Grant with Prof. Zimmermann and Prof. Hayden. <img src=\"umn_logo.jpg\" width=\"45\"></small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Mar 2019:</font></strong> \n\t  Jae Shin's Face paper with Takaaki Shiratori and Shoou-I Yu (Facebook Reality Lab) is accepted to CVPR as an <strong>oral presentation</strong>.\t </small></p>\t\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Feb 2019:</font></strong> \n\t  Receive <a href=\"https://www.nsf.gov/awardsearch/showAward?AWD_ID=1846031&amp;HistoricalAwards=false&amp;fbclid=IwAR07fOD4u_CW5J2pWALK0jTcWcogc2w2qnLV5kBPoe3r5t_70rJNhK_Hwf0\">NSF CAREER Award</a>.\t  <img src=\"nsf.gif\" width=\"30\"></small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Feb 2019:</font></strong> Give a talk at Department Seminar, Aerospace Engineering and Mechanics (UMN).</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Dec 2018:</font></strong> Give a talk on 3D Behavioral Imaging and Beyond at UMN Digital Technology Center (DTC).</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Dec 2018:</font></strong> Give a talk on 3D Behavioral Imaging and Beyond at STATS Chicago.</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Nov 2018:</font></strong> Force from Motion paper is accepted in TPAMI.</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Oct 2018:</font></strong> Give a talk on <a href=\"https://www.cs.umn.edu/activity/talks/colloquia/october-22-2018-1115am\">3D Behavioral Imaging and Beyond</a> at UMN CS Colloquium.</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Sep 2018:</font></strong> Large-scale humans-in-the-wild data collection using 114 multi-camera system and research demonstrations at <a href=\"https://twin-cities.umn.edu/news-events/great-university-minnesota-get-together?utm_source=promotion&amp;utm_medium=email&amp;utm_campaign=internal\">Minnesota State Fair</a>. <img src=\"statefair.jpg\" width=\"290\"></small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">May 2018:</font></strong> Receive <a href=\"https://ovpr.umn.edu/inquiry/post/2018-minnesota-futures-awards-announced\">Minnesota Futures Research Award</a> with Prof. Hayden. <img src=\"umn_logo.jpg\" width=\"45\"></small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Apr 2018:</font></strong> Talk <a href=\"https://www.ima.umn.edu/2017-2018/DSS9.5.17-5.29.18/26712\">\"Human Activity Computing from Inside-out and Outside-in Visual Data\"</a> at UMN IMA (Institute for Mathematics and its Applications).</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Mar 2018:</font></strong> Receive <a href=\"https://nsf.gov/awardsearch/showAward?AWD_ID=1755895&amp;HistoricalAwards=false\">NSF CRII (CISE Research Initiation Initiative) Award</a>. <img src=\"nsf.gif\" width=\"30\"></small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Mar 2018:</font></strong> Jae Shin's paper on Semantic Trajectory gets accepted to CVPR.</small></p>\n\t  \n\t  <p class=\"tag\"><small><strong><font color=\"000000\">Dec 2017:</font></strong> Imitation learning paper gets accepted to AAAI as an oral.</small></p>\n\t  \n      <p class=\"tag\"><small><strong><font color=\"000000\">Sep 2017:</font></strong>  Talk \"First Person Perception for Robotics\" at UMN Center for Cognitive Science.</small></p>\n\n<p class=\"tag\"><small><strong><font color=\"000000\">Sep 2017:</font></strong> Talk \"Learning from First Person Demonstrations\" at nVidia research.</small></p>\n\n<p class=\"tag\"><small><strong><font color=\"000000\">Sep 2017:</font></strong> Talk \"Learning from First Person Demonstrations\" at JD.com research.</small></p>\n\n<p class=\"tag\"><small><strong><font color=\"000000\">Jul 2017:</font></strong> CVPR tutorial on <a href=\"http://domedb.perception.cs.cmu.edu/tutorials/cvpr17/index.html\">\"DIY: A Multiview Camera System\"</a></small>\n<iframe width=\"300\" height=\"165\" src=\"https://www.youtube.com/embed/p1V8zA-ONQg\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n</p>\n\n<p class=\"tag\"><small><strong><font color=\"000000\">Jul 2017:</font></strong>  2 ICCV papers get accepted.</small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Jun 2017:</font></strong> Talk \"Learning from First Person Demonstrations\" at <a href=\"http://vision.soic.indiana.edu/egocentric-workshop-2017/\">Egocentric Vision: From Science to Real-World Applications</a></small>\n</p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Apr 2017:</font></strong> EgoNet paper gets accepted in RSS.</small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Feb 2017:</font></strong> Shan's paper gets accepted to CVPR as a spotlight.</small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Feb 2017:</font></strong> Talk <a href=\"http://www.robotics.gatech.edu/hg/item/586270\">\"Learning from First Person Demonstrations\"</a> at GATECH.</small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Jan 2017:</font></strong> Talk <a href=\"https://www.eecs.umich.edu/eecs/etc/events/showevent.cgi?4165\">\"Learning from First Person Demonstrations\"</a> at UMich.</small></p>\n<p class=\"tag\"><small><strong><font color=\"000000\">Jan 2017:</font></strong> Talk at Honeywell.</small></p>\n\n    </div>\n\t\n    <div class=\"thumbnail2\"> <table width=\"600\" border=\"0\">\n  <tbody>\n\t  <tr>\n      <td><h4><font size=\"5\">SELECTED WORK</font></h4> </td>\n\t  </tr>\n\t  <tr>\n      <td><h4><a href=\"publication.html\"><font size=\"4\">Full Publication List</font></a></h4> </td>\n\t  \n\t  </tr>\n\t  \n\t  \n\t  \n\n\t  \n\t  \n\t <tr>\n\t  <td valign=\"top\">\n\t  <p class=\"tag\"><small>3D behavioral imaging system</small>\n\t  <img src=\"stage.png\" width=\"250\"></p>\n     </td>\n\t  <td valign=\"top\">\n\t  <p class=\"tag\"><a href=\"https://drive.google.com/file/d/1CqU_5eff6Xa3B6hXbppxuczAtLX3Xofm/view?usp=sharing\">\t <small> \n\t  OpenMonkeyStudio</small>\n\t  <img src=\"monkey_stage.png\" width=\"250\"><br>\n\t  <img src=\"monkey3d.gif\" width=\"250\"></a></p>\n     </td>\n\t  </tr>\n\t  \n\t  <tr>\n\t  <td valign=\"top\">\n      <p class=\"tag\"><a href=\"http://humbi.cs.umn.edu/\"><small>HUMBI dataset 1.0</small>\n    <img src=\"humbi_comp.gif\" width=\"250\"></a></p>\t\n     </td>\n      <td valign=\"top\">\n\t  <p class=\"tag\"><a href=\"https://arxiv.org/abs/1806.00104\"><small>Rasterized multiview algebra (CAREER)</small></a>\n\t  <img src=\"rep.png\" width=\"250\"></p> \n      </td>\n\t  </tr>\n\t  \n\t  <tr>\n\t        <td valign=\"top\">\n      <p class=\"tag\"><a href=\"https://www-users.cs.umn.edu/~jsyoon/3dface/\"><small>3D face tracking</small></a>\n    <img src=\"yoon_face.gif\" width=\"250\"></p>\t\n      </td>\n      <td valign=\"top\">\n      <p class=\"tag\"><a href=\"http://www-users.cs.umn.edu/~jsyoon/Semantic_trajectory/\"><small>Semantic trajectory reconstruction</small>\n    <img src=\"Semantic_trajectory.gif\" width=\"250\"></a></p>\t  \n      </td>\n\t  </tr>\n\t  \n\t  <tr>\n\t  <td valign=\"top\">\n\t  <p class=\"tag\"><a href=\"http://domedb.perception.cs.cmu.edu/\"><small>Pantoptic studio</small>\n\t  <img src=\"confetti.gif\" width=\"250\"></a></p>\n     </td>\n      <td valign=\"top\">\n      <p class=\"tag\"><a href=\"ffm.html\"><small>Force from motion</small>\n    <img src=\"ego_phsyics.gif\" width=\"250\"></a></p>\t  \n      </td>\n\t  </tr>\n\t  \n\t   <tr>\n\t <td valign=\"top\">\n      <p class=\"tag\"><a href=\"http://www.cs.cmu.edu/~hyunsoop/social_camera.html\"><small>Social camera</small>\n    <img src=\"socialcamera.gif\" width=\"250\"></a></p>\t  \n      </td>\n\n      <td valign=\"top\">\n      <p class=\"tag\"><a href=\"socialsaliencyprediction.html\"><small>Social saliency prediction</small>\n    <img src=\"social.gif\" width=\"250\"></a></p>\t  \n      </td>\n\t  </tr>\n\t  \n\t   <tr>\n\t   \t  <td valign=\"top\">\n\t  <p class=\"tag\"><a href=\"future_loc.html\"><small>Future localization</small>\n\t  <img src=\"future_loc.gif\" width=\"250\"></a></p>\n     </td>\n\t  <td valign=\"top\">\n\t  <p class=\"tag\"><a href=\"http://www.cs.cmu.edu/~hyunsoop/gaze_concurrence.html\"><small>Joint attention</small>\n\t  <img src=\"ja.gif\" width=\"250\"></a></p>\n     </td>\n\n\t  </tr>\n\t  \n\t  \n   <tr>\n\t   \t  <td valign=\"top\">\n\t  <p class=\"tag\"><a href=\"https://www.disneyresearch.com/publication/motion-capture-from-body-mounted-cameras/\"><small>Mocap with body-mounted cameras</small>\n\t  <img src=\"mocap.gif\" width=\"250\"></a></p>\n     </td>\n\t  <td valign=\"top\">\n\t  <p class=\"tag\"><a href=\"http://www.cs.cmu.edu/~hyunsoop/trajectory_reconstruction.html\"><small>Event reconstruction</small>\n\t  <img src=\"eccv.gif\" width=\"250\"></a></p>\n     </td>\n\n\t  </tr>\n\t  \n  </tbody>\n</table>\n      \n      \n    \n    </div>\n \n  </div>\n\n\n</body></html>"