{"email": ["CS@SC"], "image": ["https://viterbi.usc.edu/directory/images/ae004759d9c885cf2f5f6ffa5590660e.jpg", "https://www.cs.usc.edu/wp-content/uploads/2017/03/Footer-Map.png", "https://www.cs.usc.edu/wp-content/themes/viterbischool_4_0_2/assets/images/USC-Shield.png", "https://www.cs.usc.edu/wp-content/themes/viterbischool_4_0_2/assets/images/USC-Viterbi.png", "https://www.cs.usc.edu/wp-content/themes/viterbischool_4_0_2/assets/images/Small-Use-Shield_BlackOnTrans.png", "https://www.cs.usc.edu/wp-content/uploads/2020/01/Informal_Viterbi_GoldOnBlack-600x111-1.jpg"], "research_blurb": ["<hr/>Research homepage: <a href=\"https://www.korolova.com\" target=\"_blank\">https://www.korolova.com</a><br/> <br/> I am a WiSE Gabilan Assistant Professor of Computer Science at USC. <a href=\"https://www.korolova.com\" target=\"_blank\">My research</a> aims to develop and deploy algorithms and technologies that enable data-driven innovations while preserving privacy and fairness.<br/> <br/> Previously, I was a Privacy Advisor at Snap and a Research Scientist at Google. I received my Ph.D. in Computer Science from Stanford University, where I was a Cisco Systems Stanford Graduate Fellow advised by Prof. Rajeev Motwani and <a href=\"https://web.stanford.edu/~ashishg/\" target=\"_blank\">Prof. Ashish Goel</a>. My <a href=\"https://www.korolova.com/Thesis/aleksandra_korolova_thesis.pdf\" target=\"_blank\">Ph.D. thesis</a> focused on protecting privacy when mining and sharing user data, and has been recognized by 2011-2012 Arthur L. Samuel Thesis Award for the best Ph.D. thesis in the Computer Science department at Stanford. I am also a co-winner of the 2011<a href=\"https://petsymposium.org/award/winners.php\" target=\"_blank\"> PET Award </a> for exposing privacy violations of microtargeted advertising and a runner-up for the 2015 PET Award for RAPPOR, the first commercial deployment of differential privacy.<br/><br/><div class=\"research-piece\"><h4>Research Summary</h4><hr/>Developed differentially private algorithms for common data mining tasks such as <a href=\"https://www.korolova.com/papers/Releasing_search_queries_and_clicks_privately_WWW2009.pdf\" target=\"_blank\">search log release</a> and <a href=\"https://arxiv.org/abs/1407.6981\" target=\"_blank\">malware detection in the local model of privacy</a>, leading to the <a href=\"https://ai.googleblog.com/2014/10/learning-statistics-with-privacy-aided.html\" target=\"_blank\">first commercial deployment of differential privacy</a>.<br/> <br/> Identified privacy shortcomings in <a href=\"https://journalprivacyconfidentiality.org/index.php/jpc/article/view/594/577\" target=\"_blank\">microtargeted advertising</a>, <a href=\"https://www.wired.com/story/apple-differential-privacy-shortcomings/\" target=\"_blank\">Apple's deployment</a> of differential privacy, and <a href=\"http://www.korolova.com/bluetooth/bluetoothprivacy.pdf\" target=\"_blank\">treatment of Bluetooth permissions by mobile OSes</a>, leading to changes in practices and greater transparency.<br/> <br/> <a href=\"https://arxiv.org/abs/1904.02095\" target=\"_blank\">Demonstrated</a> that Facebook's ad delivery optimization algorithms can direct job and housing ads to audiences skewed by race &amp; gender even when advertisers target large, inclusive audiences. Furthermore, <a href=\"https://arxiv.org/abs/1912.04255\" target=\"_blank\">showed</a> that Facebook's ad delivery optimization algorithms limit political advertisers' ability to reach audiences that do not share their political views and can create informational filter bubbles.<br/> <br/> Showed how <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6956583\" target=\"_blank\">automated analyses of users' privacy-related actions</a> can be used to improve product privacy features.<br/><br/><div class=\"awards-piece\">"]}