{"email": ["wya@cs.cornell.edu"], "image": ["https://www.cs.cornell.edu/people/images/GEHRKE.jpg", "https://www.cs.cornell.edu/people/images/GOMES.jpg", "https://www.cs.cornell.edu/people/images/manohar.jpg", "https://www.cs.cornell.edu/people/images/SCHNEIDE.jpg", "https://www.cs.cornell.edu/people/images/morisette01.jpg", "https://www.cs.cornell.edu/people/images/VANRENES.jpg", "https://www.cs.cornell.edu/people/images/teitelbaum01.jpg", "https://www.cs.cornell.edu/people/images/kozen.jpg", "https://www.cs.cornell.edu/people/images/banner.gif", "https://www.cs.cornell.edu/people/images/heinrich.jpg", "https://www.cs.cornell.edu/people/images/LAGOZE.jpg", "https://www.cs.cornell.edu/people/images/burtscher.jpg", "https://www.cs.cornell.edu/people/images/gay01.jpg", "https://www.cs.cornell.edu/people/images/LI1.jpg", "https://www.cs.cornell.edu/people/images/CHEW1.jpg", "https://www.cs.cornell.edu/people/images/KREITZ.jpg", "https://www.cs.cornell.edu/people/images/GREENBER.jpg", "https://www.cs.cornell.edu/people/images/nerode.gif", "https://www.cs.cornell.edu/people/images/vanloan012.jpg", "https://www.cs.cornell.edu/people/images/vavasis01.jpg", "https://www.cs.cornell.edu/people/images/rooth.jpg", "https://www.cs.cornell.edu/people/images/Yona.jpg", "https://www.cs.cornell.edu/people/transparent.gif", "https://www.cs.cornell.edu/people/images/ELBER.jpg", "https://www.cs.cornell.edu/people/images/haas01.jpg", "https://www.cs.cornell.edu/people/images/BAILEY.jpg", "https://www.cs.cornell.edu/people/images/CONSTAB1.jpg", "https://www.cs.cornell.edu/people/images/stodghill.jpg", "https://www.cs.cornell.edu/people/images/ZABIH.jpg", "https://www.cs.cornell.edu/people/images/MYERS.jpg", "https://www.cs.cornell.edu/people/images/speight01.jpg", "https://www.cs.cornell.edu/people/images/COLEMAN.jpg", "https://www.cs.cornell.edu/people/images/sirer.jpg", "https://www.cs.cornell.edu/people/images/DEMERS.jpg", "https://www.cs.cornell.edu/people/images/ARMS.jpg", "https://www.cs.cornell.edu/people/images/CARDIE.jpg", "https://www.cs.cornell.edu/people/images/vandesompel.jpg", "https://www.cs.cornell.edu/people/images/tardos01.jpg", "https://www.cs.cornell.edu/people/images/BIRMAN.jpg", "https://www.cs.cornell.edu/people/images/KEDEM.jpg", "https://www.cs.cornell.edu/people/images/SHMOYS.jpg", "https://www.cs.cornell.edu/people/images/HOPCROFT.jpg", "https://www.cs.cornell.edu/people/images/schwartz01.jpg", "https://www.cs.cornell.edu/people/images/krafft.jpg", "https://www.cs.cornell.edu/people/images/hemami.jpg", "https://www.cs.cornell.edu/people/images/SELMAN.jpg", "https://www.cs.cornell.edu/people/images/HARTMAN1.jpg", "https://www.cs.cornell.edu/people/images/vogels.jpg", "https://www.cs.cornell.edu/people/images/newhalpern.jpg", "https://www.cs.cornell.edu/people/images/pingali.jpg", "https://www.cs.cornell.edu/people/images/KLEINBER.jpg"], "research_blurb": ["y research interests concentrate on web information \n        systems, digital libraries and electronic publishing. These fields integrate \n        methods from many disciplines, so that the work ranges from technical \n        topics, such as distributed computing and information representation, \n        to the economic and social aspects of change. My book Digital Libraries \n        was published by the MIT Press in winter 2000. This year we received a \n        major grant to integrate many separate projects into the NSF's new digital \n        library for science, mathematics, engineering and technology education. \n        This is likely to be the largest and most heterogeneous digital library \n        yet attempted. Cornell's multidisciplinary team combines computer science, \n        librarian and user interfaces design expertise. One of my principal interests \n        is the change in scientific publication as online materials replace printed \n        journals as the primary means of creating, storing, and distributing research \n        information. I have recently completed a period as chair of the ACM Publications \n        Board, am a member of the MIT Press Management Board, and am a member \n        of a strategic planning committee of the American Physical Society. As \n        part of the NSF-funded Prism project, I am working with the Library of \n        Congress to develop methods for long-term preservation of materials on \n        the Web. y research is concerned with reliability and security \n        in modern networked environments. This work has three broad themes. Our \n        main focus is on a new system called \"Spinglass\" (y \n        research interests are high-performance micro-processor architecture, \n        instruction-level parallelism, and compiler optimizations. In particular, \n        I am exploring hardware- and software-based value prediction, data compression, \n        and latency reduction techniques.\n        \u00a0\u00a0\u00a0\u00a0The constantly widening speed gap between CPUs \n        and memory is becoming more and more of a performance-limiting factor. \n        In fact, current high-end microprocessors already spend a substantial \n        amount of time waiting for memory accesses. To speed up program execution, \n        the CPU needs to process useful instructions while waiting for the memory. \n        One way of providing a processor with useful work is to predict what it \n        will have to do next. Many commodity microprocessors already contain branch \n        predictors to boost their performance, and it is likely that more predictors \n        will be needed to meet the continuing demand for ever-faster CPUs. Designing, \n        evaluating, and improving such predictors is an important focus of my \n        research.y \n        primary research areas are Natural Language Processing (NLP) and Machine \n        Learning (ML) where we focus on developing corpus-based techniques for \n        understanding and extracting information from natural language texts. \n        In particular, my group investigates the use of machine learning techniques \n        as tools for guiding natural language system development and for exploring \n        the mechanisms that underlie language understanding. Our work encompasses \n        three related areas: (1) machine learning of natural language, (2) the \n        use of corpus-based NLP techniques to aid information retrieval (IR) and \n        summarization systems, and (3) the design of user-trainable NLP systems \n        that can efficiently and reliably extract the important information from \n        a document.\n        In the past year or so we have made progress on both the natural language \n        processing and machine learning aspects of our research. First, we have \n        extended our approach to partial parsing of natural language texts to \n        operate effectively in a weakly supervised learning framework. The original \n        approach, developed with graduate students Scott Mardis and David Pierce, \n        combines corpus-based grammar induction with a very simple pattern-matching \n        algorithm and an optional constituent verification step. In evaluations \n        on a number of large-scale partial parsing tasks involving on-line text, \n        the approach produces partial parsers that are both fast and accurate. \n        \n        In a joint project with CoGenTex Inc. and the University of Montreal, \n        we have begun to extend existing corpus-based learning algorithms for \n        information extraction to acquire a broader set of extraction patterns. \n        We have implemented a new learning algorithm, Autoslog-XML, that can extract \n        linguistic entities beyond just noun phrases. Autoslog-XML is a semi-supervised \n        algorithm for locating useful extraction patterns from unrestricted text. \n        The learned extraction patterns have been employed to support domain-specific \n        multi-document summarization in the natural disasters domain. We have \n        also begun to investigate the application of the extraction pattern learning \n        algorithm for Korean texts. Graduate students Vincent Ng and Kiri Wagstaff \n        are part of this joint research effort.\n        \u00a0\u00a0\u00a0\u00a0Finally, in machine learning research with Kiri \n        Wagstaff, we are investigating the use of prior knowledge in the form \n        of user-supplied constraints to improve the performance of clustering \n        algorithms.\n        \u00a0\u00a0\u00a0\u00a0In recent work on protein shape, Klara Kedem and \n        I have developed a new kind of \"consensus shape\" for protein \n        families. This is an analog of the consensus string that is sometimes \n        used for multiple alignment of proteins. The idea is based, in part, on \n        our previous work on the Unit-vector Root Mean Square (URMS) distance \n        for protein shapes. The consensus shape is a pseudo-protein with useful \n        properties. It is a pseudo-protein because it fails to have certain characteristics \n        of real proteins. In particular, for the consensus shape, the spacing \n        between successive alpha carbons is variable, with small distances in \n        regions where the members of the protein family exhibit significant variation \n        and large distances (up to the standard spacing of four angstroms) in \n        regions where the family members agree. Despite this nonprotein-like characteristic, \n        the consensus shape does preserve structural information. If all members \n        of a protein family exhibit a geometric relationship between corresponding \n        alpha carbons then that relationship is preserved in the consensus shape. \n        In particular, distances and angles that are consistent across family \n        members are preserved. Thus, the consensus shape provides a compact summary \n        of the significant strucutural information for a family. We are exploring \n        the use of the consensus shape (1) as a tool for improved protein threading \n        for use in protein structure prediction and (2) as a tool for automating \n        the division of proteins into families and subfamilies.\n        \u00a0\u00a0\u00a0\u00a0This work is being used in a large, multi-disciplinary \n        project: developing adaptive software for field-driven simulations. In \n        particular, we focus on computational fracture mechanics and reactive, \n        multiphase fluid flows. Our goal is to develop principles for building \n        software systems that can adapt to changing conditions. These conditions \n        include changes in the desired physics (e.g. we may need to change our \n        physics model when we discover that vibration is significant), changes \n        in the desired algorithms (e.g. we may change our solution technique depending \n        on how quickly we are converging toward a solution), and changes in the \n        computing environment (e.g. additional processors may become available \n        or we may lose processors due to processor failure). Other Cornell researchers \n        working on this project are Keshav Pingali, Steve Vavasis, Paul Stodghill, \n        and Tony Ingraffea (Civil Engineering), along with participants at Mississippi \n        State University, Ohio State University, Clark-Atlanta University, and \n        the College of William & Mary.ur \n        research is concerned with the design and understanding of practical and \n        efficient numerical algorithms for continuous optimization problems. Our \n        primary emphasis is the development of algorithms for large-scale optimization, \n        especially as applied to the area of computational finance.\n        \u00a0\u00a0\u00a0\u00a0The two theorem provers are used in a variety \n        of other projects as well, including the creation of formal courseware \n        by S. Allen, the translation of formal proofs into natural language by \n        Amanda Holland-Minkley, the automatic analysis of the computational complexity \n        of higher-order programs by Ralph Benzinger, and efficient reflection \n        being designed and implemented by Eli Barzilay. We follow the work of \n        Greg Morrisett and his students on new ML compilers and on typed assembly \n        language. We plan to use the LPE to broadly support research on language-based \n        security in the department and at the new Information Assurance Institute, \n        including the work of Dexter Kozen, Andrew Myers, and Fred Schneider.y \n        current research concerns aspects of weakly-consistent data replication \n        in databases and distributed systems. With Ken Birman, Robbert van Renesse, \n        Johannes Gehrke, and others, I am studying randomized \"gossip protocols.\" \n        Such protocols are highly fault-tolerant and, when properly designed, \n        extremely scalable as well. We are studying convergence properties of \n        several flat and hierarchal versions of the basic protocols tailored to \n        specific application requirements.y \n        research is in the field of Computational Molecular Biology. We develop \n        computer algorithms to study sequences, structures, dynamics, and function \n        of proteins and apply these methods to a variety of biological problems. \n        Our techniques are implemented in the systems MOIL and LOOPP, available \n        on the web \n        \u00a0\u00a0\u00a0\u00a0My current research directions include: mean field \n        approaches for global optimization and structure prediction (Locally Enhanced \n        Sampling). Structures are often determined by an optimization of an energy \n        function. I introduced mean field approaches that modify the target function \n        and make it more accessible to global optimization. We have applied these \n        techniques to determine conformations of short peptides and to refine \n        low-resolution structures of proteins. These approaches are implemented \n        into MOIL. \n        \u00a0\u00a0\u00a0\u00a0Another project concerns extending the time scale \n        of simulations. One of the striking observations in dynamics of biological \n        molecules is the extremely large time scale they covered. Initiation by \n        light absorption of biochemical processes is very rapid (femtoseconds), \n        while protein folding is slow (milliseconds to minutes). Current simulation \n        approaches (Molecular Dynamics (MD)) are restricted to nanoseconds (10-9 \n        seconds). I developed a stochastic path integral formulation that provides \n        a numerically stable trajectory for almost any arbitrary time step. We \n        apply the new algorithm to study activation of proteins (the R->T transitions \n        in hemoglobin, microseconds) and to protein folding (folding of C peptide, \n        tens of nanoseconds). The method provides systematic approximations to \n        the dynamics and is more efficient than MD by orders of magnitude. It \n        is available in MOIL.am \n        the director of the Human Computer Interaction Group (HCI Group) and a \n        professor of communication at Cornell University. The HCI Group is a research \n        and development group whose members design and research the use of computer-mediated \n        learning environments. My research interests focus on cognitive and social \n        issues for the design and use of interactive communication technologies. \n        Past research has explored navigation issues, knowledge management, mental \n        models and metaphors, knowledge representations, collaborative work and \n        learning, and system design. \n        \u00a0\u00a0\u00a0\u00a0\u00a0I have received funding for my research \n        and design projects from the National Science Foundation (NSF), the National \n        Endowment for the Humanities (NEH), the Mellon Foundation, Intel, Microsoft, \n        IBM, Getty, and several private donors. I teach courses in interactive \n        multimedia design and research, computer-mediated communication, human-computer \n        interaction, and the social design of communication systems.y \n        primary research interest is in the development of new data mining and \n        database technology. My group is currently involved in three projects: \n        The \n        \u00a0\u00a0\u00a0\u00a0\u00a0In the Himalaya Data Mining Project we develop \n        new data mining functionality, and we work on techniques to make the resulting \n        data mining models more understandable to the user. As an example, consider \n        classification trees, a data mining model that is supported in nearly \n        all commercial data mining suites. In recent research we have shown that \n        a large class of classification tree construction algorithms is biased \n        (including most algorithms used in commercial tools), thus, users could \n        draw incorrect conclusions from the resulting \"incorrect\" classification \n        tree. Our methods can provably eliminate this bias from any existing split \n        selection method. Other recent results include the fastest published algorithm \n        for mining long market baskets, and new methods for mining long sequential \n        patterns.\n        \u00a0\u00a0\u00a0\u00a0\u00a0The widespread deployment of sensors and \n        mobile devices is transforming our physical environment into a computing \n        platform. There is now computing power on every device, and emerging networking \n        techniques ensure that devices are interconnected and accessible from \n        local or wide-area networks. This is a distributed database system of \n        unprecedented scale. In the Cougar Sensor DatabaseSystem, we develop database \n        technology for tasking, mining, and monitoring such a large number of \n        distributed data sources. We have implemented the first generation of \n        the Cougar Device Database System, where we leverage the processing power \n        on the devices to push query processing directly to the data sources. \n        Different query processing strategies allow us to balance resource usage, \n        accuracy, and speed of query answers. Our current research focuses on \n        distributed and fault tolerant query processing and meta-data management.\n        In many applications, for example in intrusion detection, sensor networks, \n        and network management, data arrive in streams, and the large volume of \n        such high-speed data streams makes storage and offline processing of the \n        data infeasible. In the Amazon Stream Processing Project, we are developing \n        query processing techniques for long running queries over infinite data \n        streams. The main difficulty here is the new model of computation: Instead \n        of being able to re-read data many times and to perform expensive offline \n        computation on a static dataset, we need to compute query answers and \n        maintain summary statistics in an online fashion. Our recent results include \n        computation of correlated aggregates and quantiles over data streams.y \n        research interests are centered around the integration of methods from \n        artificial intelligence and operations research for solving hard combinatorial \n        problems. I consider applications in areas ranging from combinatorial \n        design, planning and scheduling, reasoning, multi-agent systems, and machine \n        learning. Recently, I have focused on randomized search techniques. In \n        this work, I study so-called heavy-tailed distributions that characterize \n        complete randomized search methods. A promising way of exploiting heavy-tailed \n        behavior is by combining a suite of search methods into a portfolio, running \n        on a distributed compute cluster. It can be shown that such portfolios \n        dramatically reduce the expected overall computational cost, thereby allowing \n        us to solve large, previously unsolved combinatorial problems. Another \n        recent research direction (joint work with groups at the University of \n        Washington and Microsoft Research) involves the use of machine learning \n        techniques and Bayesian models to develop effective adaptive algorithmic \n        strategies given bounded computational resources. \n        I also established and direct the newly formed Intelligent Information \n        Systems Institute (IISI) at Cornell. The mission of the institute is to \n        foster research in computation and data intensive methods for intelligent \n        decision making systems. See am \n        one of the pioneers in the emerging field of computer graphics, having \n        served as a leading researcher and teacher in the field since 1965. My \n        research is primarily concerned with physically based image synthesis \n        and with applying graphic techniques to a variety of disciplines. My specialties \n        include color science, parallel processing, and realistic image generation. \n        My application work now focuses on medical imaging, architectural design, \n        perception, digital photography, and real-time photorealistic image generation.\n        \"Toward a Psychophysically Based Light Reflection Model for Image \n        Synthesis.\" Computer Graphics Proceedings, Annual Conference Series \n        ACM SIGGRAPH, 55-64 (July, 2000). With Fabio Pellacini, and James A. Ferwerda.y \n        research is in the area of mobile and wireless systems and networks. Selected \n        examples of the projects that are conducted in my Wireless Network Laboratory \n        (WNL) are: ad-hoc networks (routing, medium access control, security, \n        etc.), quality of service, cross-layer protocol design, mobile web access, \n        multicasting, and mobility management.\n        My research is concerned with representing and reasoning about knowledge \n        and uncertainty in multi-agent systems. The work uses tools from logic \n        (particularly modal logic and the idea of possible-worlds semantics), \n        probability theory, distributed systems, game theory, and AI, and I like \n        to think that it contributes to our understanding of each of these areas \n        as well.\n        \u00a0\u00a0\u00a0\u00a0\u00a0Some themes of my current research include: \n        (1) applying ideas of decision theory to constructing algorithms in asynchronous \n        distributed systems, database systems, and wireless systems, (2) providing \n        foundations for useful qualitative notions of decision theory, (3) reasoning \n        about security. The strategic goal \n        of my research is to contribute to the development of a comprehensive \n        theory of computational complexity. Computational complexity, the study \n        of the quantitative laws that govern computation, is an essential part \n        of the science base needed to guide, harness, and exploit the explosively \n        growing computer technology. My current research interests focus on understanding \n        the computational complexity of chaotic systems and the classification \n        of undecidable problems in complexity theory. My research is concerned \n        with the design of active memory and I/O systems for next-generation servers \n        and data-intensive computing. This work has focused on extending the cache \n        coherence mechanism in modern servers to implement active memory operations-computation \n        performed in the memory system on behalf of the microprocessor to speed \n        up overall execution time. Coupled with this work is the exploration of \n        the effect of new networking technologies (i.e. InfiniBand) on next-generation \n        servers and the integration of active memory and I/O techniques with this \n        networking technology. We have also shown that active memory machines \n        and hardware cache-coherent distributed shared-memory (DSM) machines need \n        much the same support, and, in fact, that by building our single-node \n        active memory system we can also support a multiprocessor version of the \n        machine that we call active memory clusters. Active memory clusters can \n        achieve hardware DSM performance at the low cost of clusters.\n        \u00a0\u00a0\u00a0\u00a0\u00a0In my work on Active I/O systems I am developing \n        a smart InfiniBand switch (which can also be used in active memory clusters) \n        that can support either normal or intelligent I/O devices, and offload \n        computation from the microprocessor to minimize latency and reduce bandwidth \n        requirements in the I/O system. This work also involves innovative operating \n        system restructuring, including the filesystem and the network stack. \n        The operating system in active I/O systems must be partitioned between \n        the microprocessor and the active I/O devices. Our own operating system, \n        SplitOS, is joint work between our research group and groups at Rutgers \n        and Princeton.The emerging information \n        superhighway provides an example of the flexibility required of image \n        and video compression and transmission techniques. Varying network capacities, \n        differences in viewing devices, and a broad spectrum of user needs suggest \n        the desirability of coding techniques that can efficiently span large \n        quality and bandwidth ranges. Additionally, coded data must be robust \n        to errors and loss of varying degrees across multiple network segments. \n        For practicality, algorithms must be inexpensive to implement, in either \n        hardware or software. My research interests broadly concern such communication \n        of visual information. Particular topics of interest include multirate \n        video coding and transmission, compression specific to packet networks \n        and other lossy networks, and psychovisual considerations.ince \n        January 1994, I have been the Joseph Silbert Dean of the College of Engineering. \n        Upon completion of my term as dean, which ends on June 30, 2001, I plan \n        to return to research in the Department of Computer Science at Cornell. \n        My research will center on the study of information capture and access. \n        I have also been involved in the theoretical aspects of computing, especially \n        analysis of algorithms, formal languages, automata theory, and graph algorithms. \n        I have coauthored four books on formal languages and algorithms with Jeffrey \n        D. Ullman and Alfred V. Aho. y \n        research area is Computational Geometry with applications to problems \n        in computer vision and bio-information. The attempt to deal with practical \n        problems (like shape comparison) by investigating their geometric nature, \n        yields a better theoretical understanding of the problems and provides \n        sound and efficient algorithms. Among the theoretical problems I work \n        on are problems in geometric optimization, such as covering a set of points \n        by a given number of shapes and facility location. I have investigated \n        the minimum Hausdorff distance as a tool for measuring shape resemblance \n        between images.y research is concerned with algorithms that exploit \n        the combinatorial structure of networks and information.\n        \u00a0\u00a0\u00a0\u00a0\u00a0The information we deal with is taking on \n        an increasingly networked structure; the World Wide Web serves as perhaps \n        the most compelling example of this phenomenon. One direction I have pursued, \n        motivated by this issue, is the development of algorithms that analyze \n        the link structure of the Web to identify high-quality information resources \n        - hubs and authorities relevant to broad topics. A second direction is \n        the development of graph models that can provide insight into the structure \n        of large networks. I have been studying an algorithmic framework in which \n        to frame questions about certain 'small-world' properties of networks; \n        and with Duncan Callaway, John Hopcroft, Mark Newman, and Steve Strogatz, \n        I have recently looked at models of random graphs that evolve over time. \n        A third line of research has been concerned with designing algorithms \n        that facilitate the rapid spread of information in a network; with David \n        Kempe and Al Demers, I have worked on the design of randomized 'gossip' \n        protocols that provide efficient, decentralized mechanisms for such tasks.y research interests include the theory of computational \n        complexity, especially complexity of decision problems in logic and algebra, \n        program logic and semantics, and computational algebra. Recent work includes \n        new polynomial-time algorithms for type inference in type systems with \n        subtypes and recursive types; algorithms solving systems of set constraints \n        as used in program analysis; a unification algorithm for set constraints \n        and a new constraint logic programming language based on set constraints; \n        development of the theory of rational spaces and their relationship to \n        set constraints; an algorithm for decomposition of algebraic functions; \n        a new polynomial-time algorithm for resolution of singularities of plane \n        curves; efficient algorithms for optimal transmission of encoded video \n        data; optimality results for digital interleavers; and expressiveness, \n        complexity and completeness results for Kleene algebras with tests. Recently \n        I have begun to investigate algorithms for efficient code certification \n        and the application of Kleene algebra with tests to the verification of \n        compiler optimizations.serve both as a researcher and an administrator \n        in the Department of Computer Science at Cornell. In my guise as an administrator, \n        I manage the Computing Facilities Support group and worry about a number \n        of issues including computer security, networking, and building web services. \n        Most recently, as part of the Nomad research project (\n        \u00a0\u00a0\u00a0\u00a0On the research side, I am part of the Cornell \n        Digital Libraries Research Group (CDLRG - ). \n        My own particular interests focus on ensuring the availability in the \n        digital world of pre-digital published and manuscript materials, as well \n        as related issues on copyright, the public domain, and public access to \n        older and out-of-print materials.\n        My primary research interest is the application of automated deduction \n        to the design, verification, and optimization of software systems. My \n        current research aims at developing a Logical Programming Environment \n        for the construction of reliable and efficient distributed systems. In \n        collaboration with the Nuprl and Ensemble research groups, I have built \n        semantics-based tools for the automatic optimization of protocol stacks \n        in the Ensemble group communication system. More recently, Robbert van \n        Renesse, Mark Bickford and I have developed a generic switching protocol \n        for the construction of adaptive systems and proved it correct with the \n        Nuprl proof development system. For this purpose, we introduced the concept \n        of meta-properties and used them to characterize communication properties \n        that can be preserved by switching. We also identified switching invariants \n        that an implementation of the switching protocol must satisfy in order \n        to work correctly. The verification efforts revealed a variety of implicit \n        assumptions that are usually made when designing communication systems \n        and uncovered minor design errors that would otherwise have made their \n        way into the implementation.\n        Our group investigates the policies, organization, and architecture of \n        distributed information spaces. The Web, and the massive amount of content \n        that it makes available to us in our daily lives, provides the backdrop \n        for our work. The goal of our research is to understand and prototype \n        the services and organizational structures that we can build on top of \n        this global information base in order to increase its functionality, integrity, \n        and ease of use. We undertake this research with the recognition that \n        any proposed solutions must balance the economy and speed of automated \n        solutions against the often-irreplaceable expertise that comes from human \n        intervention. \n        \u00a0\u00a0\u00a0\u00a0\u00a0Within this context we examine a number \n        of research areas: Architectures for storage of and access to the multiple \n        forms of digital content. Policies and enforcement mechanisms that facilitate \n        the preservation and secure management of distributed content. The role \n        of metadata, in its many forms, in the management of digital content. \n        Protocols for federating information across distributed repositories and \n        services. Architectures and services for interlinking amongst document \n        references and citations.We \n        work in close collaboration with other researchers in the Cornell, national \n        and international library, computer science, and Internet communities. \n        Our research model is highly applied: building standards and systems and \n        supporting the deployment of them to our collaborators in the global information \n        community. This research model has produced Dienst, an architecture and \n        protocol for creating distributed document repositories and services, \n        the Open Archives Initiative Metadata Harvesting Protocol that provides \n        access to metadata in a variety of forms, and theFEDORA digital object \n        model for managing access to highly variable digital content.he ultimate goal of natural language processing \n        is to enable computers to use human language as a communication medium \n        both robustly and gracefully. However, because of the subtleties of human \n        language, this goal cannot be achieved without access to large quantities \n        of high-quality linguistic and domain knowledge. A major focus of my research \n        is the development of \"knowledge-lean\" methods to overcome this \n        knowledge acquisition bottleneck: I am investigating techniques that allow \n        a system to automatically learn the requisite information directly from \n        text.y general research interests include numerical \n        optimization and scientific computation. In addition, I am interested \n        in the application of optimization methods to medical, engineering, and \n        financial problems.\n        My current interests focus on solving nonlinear constrained problems for \n        which the gradient computation is expensive and inexact. These problems \n        arise from many financial application problems.y research is concerned with the design of efficient \n        asynchronous computation structures in VLSI and the use of formal methods \n        to guarantee the correctness of such structures.y \n        research interests are in the design, semantics, and implementation of \n        programming languages. I am particularly interested in exploring how language \n        technology can be used to build reliable, secure, and high-performance \n        systems software. The unifying thread for all my research is the application \n        of advanced semantic constructs in real-world applications.\n        \u00a0\u00a0\u00a0\u00a0\u00a0Recently, I have concentrated on type systems \n        and logics for enforcing security properties in low-level code. One byproduct \n        of this research is the design of a type system called TAL (\n        \u00a0\u00a0\u00a0\u00a0\u00a0Another interest is in language, compiler, \n        and runtime support for application-specific memory management. Though \n        standard garbage collection techniques provide a safe and convenient programming \n        model, many systems applications cannot tolerate the overheads introduced \n        by a general-purpose collector. My research here focuses on a range of \n        topics from fast conservative garbage collectors to advanced type systems \n        for region-based memory management, to generalizations of linear type \n        systems. The goal in all of this work is to provide the programmer with \n        more control over memory management without sacrificing safety. \n        \u00a0\u00a0\u00a0\u00a0\u00a0My other recent interests are in run-time \n        code generation and modal type systems, efficient data representation, \n        and rich forms of polymorphism. Many of these issues are being explored \n        in the context of Cyclone, a next-generation systems language that is \n        being developed jointly between researchers at Cornell and AT&T Laboratories.\n        My principal project is a research monograph with engineer Wolf Kohn on \n        the use of Finsler manifolds we associate with distributed optimal control \n        problems throughout engineering to extract close-to-optimal controls in \n        the form of finite automata. We dubbed this area Hybrid Systems in 1991, \n        and many now work in it. \n        Kohn and I founded a research and development company, Hynomics, some \n        years ago, with venture capital, in Seattle, and it is about to release \n        to a client a prototype 25,000 agent distributed system for supply chain \n        management, entirely based on new mathematical-computer science technology.y research group works on programming languages \n        and compiler technology for program understanding, restructuring, and \n        optimization. Our goal is to develop the algorithms and tools that are \n        required to raise the level of abstraction at which people program computers, \n        freeing them from having to worry about low-level details of machine architectures, \n        memory hierarchies, etc.\n        \u00a0\u00a0\u00a0\u00a0\u00a0These ongoing projects build on our earlier \n        work on restructuring compilation technology. Our group implemented one \n        of the first compilers that generated code for distributed memory machines, \n        starting from sequential shared memory programs. We introduced techniques \n        called runtime resolution and owner-computes rule, which have now become \n        standard in the area. Our work on linear loop transformations for enhancing \n        parallelism and locality has been incorporated by Hewlett-Packard into \n        its entire compiler product line. We also developed fast algorithms for \n        program analysis problems such as computing the control dependence relation, \n        the static single assignment form of a program, and dataflow analyses. \n        Many of these algorithms have been incorporated into commercial and research \n        compilers.\n        \u00a0\u00a0\u00a0\u00a0\u00a0My other interests include applying formal \n        methods to systems problems and networking support for peer-to-peer applications.Over the past several \n        years, in collaboration with several colleagues, I have been developing \n        an approach to research and applications in linguistics and computational \n        linguistics that combines theoretical-linguistic formalisms, knowledge, \n        and problem statements with numerical modeling and parameter estimation \n        techniques. We have developed and implemented a grammatical formalism \n        known as head-lexicalized probabilistic context free grammar and have \n        employed it in large-scale experiments on German and English concerned \n        with learning lexical information from text corpora. The methods have \n        the status of a basic language technology, which can be applied in numerous \n        ways in research and applications. My own interests relate mainly to scientific \n        research in linguistics, particularly syntax, semantics and lexical semantics.\n        My main area of research is in computational mechanics. My recent work \n        focuses on applying mathematical techniques of deterministic uncertainty \n        to enhance methods of structural engineering analysis. I am applying one \n        such technique, called Interval Analysis, which adapts traditional numerical \n        operations by replacing numbers with intervals that model uncertain values. \n        This set-based form of structural analysis uses discrete mathematics to \n        perform types of parametric studies, that traditional techniques cannot. \n        However, the interval approach introduces numerical inaccuracies in solutions \n        that map to infeasible structural behaviors. A major goal of this research \n        involves improving the quality of the interval-based solutions to reduce \n        these inaccuracies to produce a technique suitable for design engineers.The focus of my research \n        is on computation intensive methods in artificial intelligence, in particular \n        fast general reasoning, search, and planning techniques. I also investigate \n        the various sources of complexity in hard computational problems. In this \n        work, I explore connections between computer science, artificial intelligence, \n        and statistical physics. In addition, I study issues in problem representation, \n        including the robustness of encodings, abstraction, compilation, and approximation \n        methods. These issues are critical to the successful application of reasoning \n        and search methods in realistic domains. In terms of applications, I consider \n        challenge problems from planning, knowledge representation, multi-agent \n        systems, and machine learning. Our planning system, Black Box, developed \n        jointly with Henry Kautz of the University of Washington, is one of the \n        fastest general purpose planning systems. Finally, in recent projects, \n        I am exploring connections between machine learning methods and reasoning \n        and planning techniques. In joint work with groups at the University of \n        Washington and Microsoft Research, I study the use of Bayesian machine \n        learning techniques for dynamic adaptive control of computational resources.The primary focus \n        of my research is on the design and analysis of efficient algorithms for \n        discrete optimization problems, and in particular, on approximation algorithms \n        for NP-hard problems.\n        \u00a0\u00a0\u00a0\u00a0\u00a0A third research direction looks at distributed \n        systems at the opposite end of the spectrum; namely, the high-performance \n        clusters that make up web sites. We are developing techniques for formally \n        specifying and reasoning about the interfaces they expose to the rest \n        of the network, as well as techniques for enforcing a security policy \n        uniformly across a web site. \n        My research centers around different aspects of distributed computing. \n        In particular, my three areas of focus are software runtime systems for \n        distributed computing platforms, improving the performance of commodity \n        cluster-based shared memory systems, and providing location-independent \n        data access through the concept of affinity directed mobility.\n        \u00a0\u00a0\u00a0\u00a0\u00a0 My work in software distributed system \n        runtime development has resulted in the dissemination of the Brazos system \n        to over 100 registered users worldwide. Brazos is a high performance parallel \n        programming environment distinguished by its use of multithreading, selective \n        multicast, a software-only implementation of scope consistency, and several \n        adaptive runtime performance tuning mechanisms. Brazos supports both shared \n        memory and message passing programming styles, and provides very efficient \n        mechanisms for thread migration and checkpoint/recovery. Currently, my \n        research on parallel programming runtime systems includes the development \n        a version of the Message Passing Interface (MPI) that provides thread \n        migration between nodes in a cluster for load balancing, fault tolerance, \n        and higher performance.\n        \u00a0\u00a0\u00a0\u00a0\u00a0The core research issues of the project \n        are mobility management (how we move data and threads to support user \n        and device mobility), data management (how we represent, access, update, \n        and protect information), and application management (how we provide system-wide \n        access to application data). In contrast to previous approaches to mobile \n        data management that employ hoarding in anticipation of disconnection, \n        Bifrost anticipates \"connection elsewhere\" instead of disconnection. \n        Our rationale for this \"almost always connected\" approach is \n        as follows: We project that in 3-5 years, the situation will exist in \n        which users will be able to be in an \"always connected\" state, \n        connected almost anytime and anywhere that they choose. Wireless access \n        points (e.g., 802.11, infrared, and Bluetooth) will be common, even ubiquitous, \n        in nearly every home and public place, as they are today in many situations \n        including coffee shops, airports, and office buildings. Additionally, \n        services such as Infared and Bluetooth will allow connection to the Internet \n        in nearly any setting from almost anywhere. In this situation, the problem \n        of how a user can have unilateral access to any piece of remote personal \n        data, regardless of device or location, becomes increasingly important. \n        Thus Bifrost seeks to provide a common data access model, and exploring \n        the design space while providing a rich set of tools for the manipulation \n        and sharing of personal data is a core focus of the proposed research. \n        My research interest \n        is in program transformations and program synthesis for computational \n        science applications.\n        \u00a0\u00a0\u00a0\u00a0\u00a0Another area in which I am working is that \n        of fault-tolerance for scientific applications. Very few scientific applications \n        would be considered \"mission-critical,\" but many do run for \n        very long periods of time (e.g., for weeks or months) or in environments \n        in which failures are likely to occur (e.g., the desktop workstations \n        within a department). We are currently investigating a number of different \n        approaches for providing fault-tolerance for scientific applications, \n        but one thing is already clear: different applications running on different \n        computers call for different fault-tolerance solutions. A programmer would \n        certainly like to have their application run in many different computing \n        environments, but interfacing with a number of fault-tolerant systems \n        is not usually realistic. In order to provide a single interface from \n        the programmer's point of view, we are investigating a number of implementation \n        techniques involving software library and program transformation technology. \n        This work is being done as part of a project on Adaptive Software with \n        researchers from other departments here at Cornell, Mississippi State \n        University, the College of William and Mary, and other institutions.\n        \u00a0\u00a0\u00a0\u00a0\u00a0Apart from my core research agenda, I have \n        worked closely with computational scientists in order to develop novel, \n        high-performance, scientific applications. Apart from being interesting \n        in its own right, this work has given me insight into scientific programming \n        that I have found extremely valuable in my research on program transformations. \n        The most important project that I have been involved with was the Crack \n        Propagation for Teraflop Computers (CPTC) project, whose goal was to develop \n        fracture mechanics software that incorporated a number of recent advances \n        in numerical analysis and computational geometry and which delivered very \n        high performance on teraflop-scale computers. Other researches who worked \n        on this project include, Keshav Pingali, Steve Vavasis, Paul Chew, the \n        Cornell FractureGroup headed by Tony Ingraffea (Civil Engineering), Gao \n        Guong-Rong (ECE, University of Delaware) and Nikos Chrisochoides (CS, \n        College of William and Mary).My research interest \n        focuses on the design and analysis of efficient methods for combinatorial \n        optimization problems and their applications to various fields. I am mostly \n        working on problems that involve graphs or networks. \n        \u00a0\u00a0\u00a0\u00a0\u00a0One general area of my research is designing \n        fast algorithms that provide provably close-to-optimal results for NP-hard \n        problems. Although research on polynomial time approximation algorithms \n        started in the1970s soon after the discovery of NP-completeness, it has \n        truly blossomed only in the past decade. Amazing progress has occurred \n        both in our ability to design approximation algorithms, and in proving \n        limits to approximability. Over the last years I have been working on \n        different approximation algorithms on various basic combinatorial problems. \n        I have worked on algorithms for various cut problems, and clustering type \n        problems. These problems are motivated by applications arising in vision, \n        networking and clustering. My research is concerned \n        with the use of fine-grain dependence graphs for specification, development, \n        and analysis of software and hardware systems. The objective is a new \n        generation of tools that provide precise and complete information about \n        the structure of complex systems. I am working to improve the performance \n        and functionality of generic dependence-graph technology, and I am also \n        exploring the use of the technology in various application domains.\n        During the academic year 2000/2001, I focused on furthering my work in \n        two areas of digital library research that I initiated in 1999: the Open \n        Archives Initiative and open reference linking (OpenURL). \n        As computer hardware becomes more powerful, there is a corresponding growth \n        in the demand for more efficient algorithms to solve large-scale scientific \n        problems. My research is on the design and analysis of such algorithms. \n        Two Ph.D. students, V. Howle and G. Jonsson (both of the Center for Applied \n        Mathematics), completed their Ph.D.s working with me during the past year. \n        Howle's thesis was on algorithms for modeling and simulation of AC electric \n        power networks. Utility companies are interested in modeling the behavior \n        of the network in the presence of a fault (closed circuit breaker). The \n        governing equations, called the \"swing equations,\" are nonlinear \n        differential algebraic equations for the rotor angles of the generators \n        in the system. We developed new, more accurate algorithms for the swing \n        equations by solving a linear algebraic subproblem (complex-weighted least \n        squares) more accurately. Work on geometry in scientific computing continues. \n        Jonsson's thesis considers the problem of robust intersection of parametric \n        patches with rays and planes. This problem arises in geometric modeling \n        and mesh generation. Our results show that the problem can be solved accurately \n        by transforming it to a generalized eigenvalue computation using the theory \n        of resultants and other algebraic techniques.My research explores \n        the impact of scale on reliable distributed systems. The main focus is \n        on the development of new network protocols and middleware, as well as \n        on novel strategies to structure applications and support systems.\n        In the context of the Spinglass project, I am collaborating with Ken Birman \n        and Robbert van Renesse on the development of a new generation of high-scalable \n        reliable network protocols based on the principles of epidemic information \n        dissemination. Although the research has already resulted in protocols \n        for reliable multicast and group membership and failure detection, there \n        are still many open questions such as the application of epidemic techniques \n        to congestion control for many-to-many multicast protocols.\n        \u00a0\u00a0\u00a0\u00a0\u00a0The goal of my research is to explore high-order \n        organization within the space of all proteins and obtain a global view \n        (a \"road map\") of the protein space. We hope that the global \n        view will yield valuable insights about the nature and function of new \n        genes and will lead to the discovery of high-level properties and principles \n        in the protein space.\n        \u00a0\u00a0\u00a0\u00a0\u00a0My study so far has resulted in two large \n        databases that are being used by biologists to study new genes: ProtoMap: \n        this database and its interactive web sites (http://biospace.cornell.eduhttp://biospace.stanford.eduMy research interests \n        lie in computer vision and in medical imaging. I have worked on a variety \n        of problems in early vision, including motion and stereo; many of these \n        problems can be solved very accurately using algorithms based on graph \n        cuts. In the last year I have been doing research on medical imaging in \n        the Radiology Department at Cornell Medical School, where I have focused \n        on improving the quality of MRIs. I have also investigated a number of \n        applications of computer vision, including new methods for content-based \n        access to databases of images, and have also developed some simple computer \n        vision techniques to automate program debugging at Microsoft."]}