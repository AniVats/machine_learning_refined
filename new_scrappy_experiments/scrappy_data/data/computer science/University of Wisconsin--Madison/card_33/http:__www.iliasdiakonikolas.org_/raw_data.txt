{"email": [], "image": ["http://c.statcounter.com/9640586/0/8215de43/1/"], "research_blurb": [" My main research interests are in algorithms and machine learning. \nA major goal of my work is to understand the tradeoff between statistical efficiency, computational efficiency, and robustness \nfor fundamental problems in statistics and machine learning.\nAreas of current interest include high-dimensional robust statistics/learning, nonparametric estimation, and distribution testing. \nI also have strong interests in applied probability, algorithmic game theory, and their connections to machine learning. \n\n\n\n My research has been supported by an NSF CAREER Award, an NSF AITF Award, a DARPA grant, a Sloan Research Fellowship, a Google Faculty Research Award, a Marie Curie Career Integration Grant, \nand an EPSRC grant.\n\n\n\nA short professional biography can be found ", "\n  Learning in the presence of outliers is a fundamental problem in statistics.\n  Until recently, all known efficient unsupervised learning algorithms were very sensitive to outliers in high dimensions.\n  In particular, even for the task of robust mean estimation under natural distributional assumptions,\n  no efficient algorithm was known.\n  Recent work in theoretical computer science gave the first efficient robust estimators for a\n  number of fundamental statistical tasks, including mean and covariance estimation.\n  Since then, there has been a flurry of research activity on algorithmic\n  high-dimensional robust estimation in a range of settings.\n  In this survey article, we introduce the core ideas and algorithmic techniques\n  in the emerging area of algorithmic high-dimensional robust statistics\n  with a focus on robust mean estimation. We also provide an overview\n  of the approaches that have led to computationally efficient robust estimators\n  for a range of broader statistical tasks and discuss new directions and opportunities for future work.\n  \n\nThe area of distribution estimation is well-motivated in its own right, and\nhas seen a recent surge of research activity, in part due to the ubiquity of structured distributions\nin the natural and social sciences. Such structural properties of distributions\nare sometimes direct consequences of the underlying application problem, \nor they are a plausible explanation of the model under investigation.\n\n\n\nIn this chapter, we give a survey of both classical and modern techniques for distribution estimation, \nwith a focus on recent algorithmic ideas developed in theoretical computer science.\nThese ideas have led to computationally and statistically efficient algorithms for learning broad families of models.\nFor the sake of concreteness, we illustrate these ideas with specific examples. \nFinally, we highlight outstanding challenges and research directions for future work.\n", "\n\nWe give a $\\poly(d, 1/\\eps)$ time algorithm for this problem with misclassification error $\\eta+\\eps$. \nWe also provide evidence that improving on the error guarantee of our algorithm\nmight be computationally hard. Prior to our work, no efficient weak (distribution-independent) learner \nwas known in this model, even for the class of disjunctions. The existence of such an algorithm \nfor halfspaces (or even disjunctions) has been posed as an open question in various works, \nstarting with Sloan (1988), Cohen (1997), and was most recently highlighted in Avrim Blum's FOCS 2003 tutorial.\n", " curve, the set of all feasible solutions whose vector of the various\nobjectives is not dominated by any other solution. Typically, we have a small number of objectives and we wish to plot the\ntradeoff curve to get a sense of the design space. Unfortunately, typically the tradeoff curve has exponential size for\ndiscrete optimization problems even for two objectives (and is typically infinite for continuous problems). Hence, a natural\ngoal in this setting is, given an instance of a multiobjective problem, to efficiently obtain a \"good\" approximation to the\nentire solution space with ``few'' solutions. This has been the underlying goal in much of the research in the multiobjective\narea, with many heuristics proposed for this purpose, typically however without any performance guarantees or complexity\nanalysis.\n\n"]}