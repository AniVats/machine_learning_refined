{"email": ["email@justinh.su"], "image": ["images/round.png"], "research_blurb": ["I design methods to <strong>formally verify</strong> that programs are correct, especially programs that use <strong>randomization</strong>. Such programs can be easy to show correct on paper, but surprisingly challenging for computers to analyze. Accordingly, my research blends ideas from two classical areas of computer science: <strong>randomized algorithms</strong> from theoretical computer science (<strong>TCS</strong>) and <strong>formal verification</strong>.\nDrawing inspiration from how humans reason about randomized algorithms, we can build simpler and more automated verification techniques. In the past, I\u2019ve applied this approach to properties like <strong>accuracy</strong>, <strong>incentive compatibility</strong>, Markov chain <strong>mixing</strong>, and various notions of <strong>algorithmic stability</strong>.\nA particular focus of my work has been <a href=\"https://en.wikipedia.org/wiki/Differential_privacy\"><strong>differential privacy</strong></a>, a rigorous definition of privacy that is currently under extensive study. I have investigated a variety of formal methods\u2014such as <a href=\"https://en.wikipedia.org/wiki/Type_system\"><strong>type systems</strong></a> and <a href=\"https://en.wikipedia.org/wiki/Hoare_logic\"><strong>program logics</strong></a>\u2014to verify that programs are differentially private.\nFrom a more traditional algorithms perspective, I am also interested in applying differential privacy to optimization, machine learning, and mechanism design.\n</section>\n<section class=\"level2\" id=\"teaching\">", "Source. Powered by Hakyll, Pandoc, and bibtex2html. \u00a9 Justin Hsu, 2015."]}