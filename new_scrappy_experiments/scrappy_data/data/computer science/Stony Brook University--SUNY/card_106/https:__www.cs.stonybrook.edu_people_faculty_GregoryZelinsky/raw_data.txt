{"email": ["gregory.Zelinsky@stonybrook.edu"], "image": ["https://www.cs.stonybrook.edu/sites/default/files/zelinsky2.jpg", "https://www.cs.stonybrook.edu/sites/all/themes/compsci/images/blue_arrow.gif"], "research_blurb": ["Gregory Zelinsky's goal is to better understand visual cognition by following two interrelated research paths. First, he monitors and analyzes how people move their eyes as they perform various visual search and visual working memory tasks. He does this in order to obtain an on-line and directly observable measure of how a behavior intimately associated with the selection and accumulation of information (i.e., eye movements) changes in space and time during a task. Second, he attempts to describe this oculomotor behavior in the context of image-based neurocomputational models. These models perform the same task and \"see\" the same stimuli as human observers, and output a sequence of simulated eye movements that can be compared to human behavior. These comparisons are then used to generate new hypotheses to further test the representations and processes underlying task performance."]}