{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -410.]\n",
      " [  804.]\n",
      " [ 1984.]\n",
      " [ 1880.]\n",
      " [ 1474.]\n",
      " [  674.]\n",
      " [   nan]\n",
      " [ 1006.]\n",
      " [ 1680.]\n",
      " [  298.]]\n",
      "[[  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [ nan]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "0-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-585c4aef2d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m# run newtons method to minimize squared margin or SVM cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0msquared_margin_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquared_margin_newtons_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# run newtons method to minimize logistic regression or softmax cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-585c4aef2d24>\u001b[0m in \u001b[0;36msquared_margin_newtons_method\u001b[0;34m(X, y, w)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# take Newton step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# update history container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda2/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[0m_assertNoEmpty2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1617\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1618\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda2/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0m_assertNoEmpty2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda2/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36m_assertRankAtLeast2\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             raise LinAlgError('%d-dimensional array given. Array must be '\n\u001b[0;32m--> 202\u001b[0;31m                     'at least two-dimensional' % len(a.shape))\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assertSquareness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 0-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "# This file is associated with the book\n",
    "# \"Machine Learning Refined\", Cambridge University Press, 2016.\n",
    "# by Jeremy Watt, Reza Borhani, and Aggelos Katsaggelos.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# import training data \n",
    "def load_data(csvname):\n",
    "    # load in data\n",
    "    reader = csv.reader(open(csvname, \"rb\"), delimiter=\",\")\n",
    "    d = list(reader)\n",
    "\n",
    "    # import data and reshape appropriately\n",
    "    data = np.array(d).astype(\"float\")\n",
    "    X = data[:,0:-1]\n",
    "    y = data[:,-1]\n",
    "    y.shape = (len(y),1)\n",
    "    \n",
    "    # pad data with ones for more compact gradient computation\n",
    "    o = np.ones((np.shape(X)[0],1))\n",
    "    X = np.concatenate((o,X),axis = 1)\n",
    "    X = X.T\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "###### for squared margin cost #######\n",
    "# function for computing gradient and Hessian for squared margin cost Newton's method\n",
    "def squared_margin_grad_hess(X,y,w):\n",
    "    hess = 0\n",
    "    grad = 0\n",
    "    for p in range(0,len(y)):\n",
    "        # precompute        \n",
    "        x_p = X[:,p]\n",
    "        y_p = y[p]\n",
    "        \n",
    "        # update grad and hessian\n",
    "        grad+= -2*max(0,1 - y_p*np.dot(x_p.T,w))*y_p*x_p\n",
    "        \n",
    "        if 1 - y_p*np.dot(x_p.T,w) > 0:\n",
    "            hess+= 2*np.outer(x_p,x_p)\n",
    "        \n",
    "    grad.shape = (len(grad),1)\n",
    "    return grad,hess\n",
    "\n",
    "# run newton's method\n",
    "def squared_margin_newtons_method(X,y,w):\n",
    "    # begin newton's method loop    \n",
    "    max_its = 20\n",
    "    misclass_history = []\n",
    "    for k in range(max_its):\n",
    "        # compute gradient and Hessian\n",
    "        grad,hess = squared_margin_grad_hess(X,y,w)\n",
    "        print grad\n",
    "        \n",
    "        # take Newton step\n",
    "        temp = np.dot(hess,w) - grad        \n",
    "        w = np.dot(np.linalg.pinv(hess),temp)\n",
    "\n",
    "        # update history container\n",
    "        cost = count_misclasses(X,y,w)\n",
    "        misclass_history.append(cost)\n",
    "    return misclass_history\n",
    "\n",
    "###### for softmax cost ######\n",
    "# function for computing gradient and Hessian for Newton's method\n",
    "def softmax_grad_hess(X,y,w):\n",
    "    hess = 0\n",
    "    grad = 0\n",
    "    for p in range(0,len(y)):\n",
    "        # precompute\n",
    "        x_p = X[:,p]\n",
    "        y_p = y[p]\n",
    "        s = 1/(1 + my_exp(y_p*np.dot(x_p.T,w)))\n",
    "        g = s*(1-s)\n",
    "        \n",
    "        # update grad and hessian\n",
    "        grad+= -s*y_p*x_p\n",
    "        hess+= np.outer(x_p,x_p)*g\n",
    "        \n",
    "    grad.shape = (len(grad),1)\n",
    "    return grad,hess\n",
    "\n",
    "# run newton's method\n",
    "def softmax_newtons_method(X,y,w):\n",
    "    # begin newton's method loop\n",
    "    max_its = 20\n",
    "    w = np.zeros(3,1);        # random initial point\n",
    "    misclass_history = []\n",
    "    \n",
    "    for k in range(max_its):\n",
    "        # compute gradient and Hessian\n",
    "        grad,hess = compute_grad_and_hess(X,y,w)\n",
    "        \n",
    "        # take Newton step\n",
    "        temp = np.dot(hess,w) - grad\n",
    "        w = np.dot(np.linalg.pinv(hess),temp)\n",
    "        \n",
    "        # update container for cost history\n",
    "        cost = count_misclasses(X,y,w)\n",
    "        cost_history.append(cost)\n",
    "    return misclass_history\n",
    "\n",
    "# avoid overflow when using exp - just cutoff after arguments get too large/small\n",
    "def my_exp(u):\n",
    "    s = np.argwhere(u > 100)\n",
    "    t = np.argwhere(u < -100)\n",
    "    u[s] = 0\n",
    "    u[t] = 0\n",
    "    u = np.exp(u)\n",
    "    u[t] = 1\n",
    "    return u\n",
    "\n",
    "# function for counting the number of misclassifications\n",
    "def count_misclasses(X,y,w):\n",
    "    y_pred = np.sign(np.dot(X,y))\n",
    "    num_misclassed = len([i for i, j in zip(y, y_pred) if i == j])\n",
    "    return num_misclassed\n",
    "\n",
    "###### run functions above #######\n",
    "\n",
    "# load data\n",
    "X,y = load_data('breast_cancer_dataset.csv')\n",
    "\n",
    "# initial weights to feed into both algorithms\n",
    "w = np.random.randn(np.shape(X)[0],1);        # random initial point\n",
    "w = np.zeros((np.shape(X)[0],1))\n",
    "\n",
    "# run newtons method to minimize squared margin or SVM cost\n",
    "squared_margin_history = squared_margin_newtons_method(X,y,w)\n",
    "\n",
    "# run newtons method to minimize logistic regression or softmax cost\n",
    "w = np.zeros((np.shape(X)[0],1))\n",
    "softmax_cost_history = softmax_newtons_method(X,y,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 699)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(y.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   1., ...,   1.,   1.,   1.],\n",
       "       [  5.,   5.,   3., ...,   5.,   4.,   4.],\n",
       "       [  1.,   4.,   1., ...,  10.,   8.,   8.],\n",
       "       ..., \n",
       "       [  3.,   3.,   3., ...,   8.,  10.,  10.],\n",
       "       [  1.,   2.,   1., ...,  10.,   6.,   4.],\n",
       "       [  1.,   1.,   1., ...,   2.,   1.,   1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
